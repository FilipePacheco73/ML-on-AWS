{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M27qF7CTrBqc"
   },
   "source": [
    "# CODING TASK #1: UNDERSTAND THE PROBLEM STATEMENT/BUSINESS CASE [REVIEW]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNl52nl3qiyL"
   },
   "source": [
    "- In this project, we will assume that we own an ice cream business that is highly dependant on the outside air temperature. \n",
    "- We will apply simple linear regression to predict the daily revenue in dollars based on outside air temperature. \n",
    "- Dataset:\n",
    "    - Input (X): Outside Air Temperature\n",
    "    - Output (Y): Overall daily revenue generated in dollars \n",
    "- In simple linear regression, we predict the value of one variable Y based on another variable X.\n",
    "- X is called the independent variable and Y is called the dependant variable.\n",
    "- Why simple? Because it examines relationship between two variables only.\n",
    "- Why linear? when the independent variable increases (or decreases), the dependent variable increases (or decreases) in a linear fashion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #1 [OPTIONAL]:**\n",
    "- **What do you expect the relationship between outside air temperature and ice cream sales to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and bike sharing rental usage to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and ski rental usage to look like?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A positive relantioship in case 1 and 2, and a negative relantionship with the case 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKmFmyaGunc7"
   },
   "source": [
    "# CODING TASK #2: IMPORT KEY LIBRARIES/DATASETS AND PREPARE THE DATA FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                              Version\n",
      "------------------------------------ -----------------\n",
      "aiobotocore                          2.4.2\n",
      "aiohttp                              3.8.5\n",
      "aioitertools                         0.11.0\n",
      "aiosignal                            1.3.1\n",
      "alabaster                            0.7.12\n",
      "anaconda-client                      1.7.2\n",
      "anaconda-project                     0.8.3\n",
      "ansi2html                            1.8.0\n",
      "anyio                                3.7.1\n",
      "argh                                 0.26.2\n",
      "argon2-cffi                          23.1.0\n",
      "argon2-cffi-bindings                 21.2.0\n",
      "asn1crypto                           1.3.0\n",
      "astroid                              2.15.6\n",
      "astropy                              4.3.1\n",
      "async-timeout                        4.0.3\n",
      "asynctest                            0.13.0\n",
      "atomicwrites                         1.3.0\n",
      "attrs                                23.1.0\n",
      "autopep8                             1.4.4\n",
      "autovizwidget                        0.20.5\n",
      "awscli                               1.29.26\n",
      "Babel                                2.12.1\n",
      "backcall                             0.1.0\n",
      "backports.shutil-get-terminal-size   1.0.0\n",
      "beautifulsoup4                       4.8.2\n",
      "bitarray                             1.2.1\n",
      "bkcharts                             0.2\n",
      "bleach                               6.0.0\n",
      "bokeh                                1.4.0\n",
      "boto                                 2.49.0\n",
      "boto3                                1.28.26\n",
      "botocore                             1.31.26\n",
      "Bottleneck                           1.3.2\n",
      "brotlipy                             0.7.0\n",
      "certifi                              2023.7.22\n",
      "cffi                                 1.15.0\n",
      "chardet                              3.0.4\n",
      "charset-normalizer                   2.0.4\n",
      "click                                8.1.6\n",
      "cloudpickle                          2.2.1\n",
      "clyent                               1.2.2\n",
      "colorama                             0.4.3\n",
      "conda                                22.9.0\n",
      "conda-package-handling               1.8.1\n",
      "contextlib2                          0.6.0.post1\n",
      "cryptography                         41.0.3\n",
      "cycler                               0.10.0\n",
      "Cython                               0.29.15\n",
      "cytoolz                              0.10.1\n",
      "dash                                 2.12.0\n",
      "dash-core-components                 2.0.0\n",
      "dash-html-components                 2.0.0\n",
      "dash-table                           5.0.0\n",
      "dask                                 2022.2.0\n",
      "decorator                            4.4.1\n",
      "defusedxml                           0.6.0\n",
      "diff-match-patch                     20181111\n",
      "dill                                 0.3.7\n",
      "distributed                          2022.2.0\n",
      "docutils                             0.16\n",
      "dparse                               0.6.3\n",
      "entrypoints                          0.3\n",
      "et-xmlfile                           1.0.1\n",
      "exceptiongroup                       1.1.3\n",
      "fastcache                            1.1.0\n",
      "fastjsonschema                       2.18.0\n",
      "filelock                             3.0.12\n",
      "flake8                               3.7.9\n",
      "Flask                                2.2.5\n",
      "frozenlist                           1.3.3\n",
      "fsspec                               2023.1.0\n",
      "future                               0.18.2\n",
      "gevent                               1.4.0\n",
      "glob2                                0.7\n",
      "gmpy2                                2.0.8\n",
      "google-pasta                         0.2.0\n",
      "greenlet                             0.4.15\n",
      "h5py                                 2.10.0\n",
      "hdijupyterutils                      0.20.5\n",
      "HeapDict                             1.0.1\n",
      "html5lib                             1.0.1\n",
      "hypothesis                           5.5.4\n",
      "idna                                 2.8\n",
      "imageio                              2.6.1\n",
      "imagesize                            1.2.0\n",
      "importlib-metadata                   6.7.0\n",
      "intervaltree                         3.0.2\n",
      "ipykernel                            5.1.4\n",
      "ipython                              7.34.0\n",
      "ipython_genutils                     0.2.0\n",
      "ipywidgets                           7.5.1\n",
      "isort                                4.3.21\n",
      "itsdangerous                         2.1.2\n",
      "jdcal                                1.4.1\n",
      "jedi                                 0.19.0\n",
      "jeepney                              0.4.2\n",
      "Jinja2                               3.1.2\n",
      "jmespath                             1.0.1\n",
      "joblib                               1.3.2\n",
      "json5                                0.9.1\n",
      "jsonschema                           3.2.0\n",
      "jupyter                              1.0.0\n",
      "jupyter_client                       7.4.9\n",
      "jupyter-console                      6.1.0\n",
      "jupyter_core                         4.12.0\n",
      "jupyter-dash                         0.4.2\n",
      "jupyter-server                       1.24.0\n",
      "jupyterlab                           1.2.21\n",
      "jupyterlab-pygments                  0.2.2\n",
      "jupyterlab-server                    1.0.6\n",
      "keyring                              21.1.0\n",
      "kiwisolver                           1.1.0\n",
      "lazy-object-proxy                    1.4.3\n",
      "libarchive-c                         2.8\n",
      "lief                                 0.9.0\n",
      "llvmlite                             0.31.0\n",
      "locket                               0.2.0\n",
      "lxml                                 4.9.3\n",
      "MarkupSafe                           2.1.3\n",
      "matplotlib                           3.1.3\n",
      "matplotlib-inline                    0.1.6\n",
      "mccabe                               0.6.1\n",
      "mistune                              0.8.4\n",
      "mkl-fft                              1.0.15\n",
      "mkl-random                           1.1.0\n",
      "mkl-service                          2.3.0\n",
      "mock                                 4.0.1\n",
      "more-itertools                       8.2.0\n",
      "mpmath                               1.1.0\n",
      "msgpack                              0.6.1\n",
      "multidict                            6.0.4\n",
      "multipledispatch                     0.6.0\n",
      "multiprocess                         0.70.15\n",
      "nbclassic                            1.0.0\n",
      "nbclient                             0.7.4\n",
      "nbconvert                            6.5.4\n",
      "nbformat                             5.8.0\n",
      "nest-asyncio                         1.5.7\n",
      "networkx                             2.4\n",
      "nltk                                 3.8.1\n",
      "nose                                 1.3.7\n",
      "notebook                             6.5.5\n",
      "notebook_shim                        0.2.3\n",
      "numba                                0.48.0\n",
      "numexpr                              2.7.1\n",
      "numpy                                1.21.6\n",
      "numpydoc                             0.9.2\n",
      "olefile                              0.46\n",
      "openpyxl                             3.0.3\n",
      "packaging                            20.1\n",
      "pandas                               1.3.5\n",
      "pandocfilters                        1.4.2\n",
      "parso                                0.8.3\n",
      "partd                                1.1.0\n",
      "path                                 13.1.0\n",
      "pathlib2                             2.3.5\n",
      "pathos                               0.3.1\n",
      "pathtools                            0.1.2\n",
      "patsy                                0.5.1\n",
      "pep8                                 1.7.1\n",
      "pexpect                              4.8.0\n",
      "pickleshare                          0.7.5\n",
      "Pillow                               9.5.0\n",
      "pip                                  23.2.1\n",
      "pkginfo                              1.5.0.1\n",
      "platformdirs                         3.10.0\n",
      "plotly                               5.8.2\n",
      "pluggy                               0.13.1\n",
      "ply                                  3.11\n",
      "pox                                  0.3.3\n",
      "ppft                                 1.7.6.7\n",
      "prometheus-client                    0.7.1\n",
      "prompt-toolkit                       3.0.3\n",
      "protobuf                             4.24.0\n",
      "psutil                               5.6.7\n",
      "ptyprocess                           0.6.0\n",
      "pure-sasl                            0.6.2\n",
      "py                                   1.11.0\n",
      "pyarrow                              12.0.1\n",
      "pyasn1                               0.5.0\n",
      "pycodestyle                          2.5.0\n",
      "pycosat                              0.6.3\n",
      "pycparser                            2.19\n",
      "pycryptodome                         3.18.0\n",
      "pycurl                               7.43.0.5\n",
      "pydocstyle                           4.0.1\n",
      "pyerfa                               2.0.0.3\n",
      "pyflakes                             2.1.1\n",
      "pyfunctional                         1.4.3\n",
      "Pygments                             2.16.1\n",
      "PyHive                               0.6.5\n",
      "pykerberos                           1.2.1\n",
      "pylint                               2.17.5\n",
      "pyodbc                               4.0.0-unsupported\n",
      "pyOpenSSL                            23.2.0\n",
      "pyparsing                            2.4.6\n",
      "pyrsistent                           0.15.7\n",
      "PySocks                              1.7.1\n",
      "pytest                               5.3.5\n",
      "pytest-arraydiff                     0.3\n",
      "pytest-astropy                       0.8.0\n",
      "pytest-astropy-header                0.1.2\n",
      "pytest-doctestplus                   0.5.0\n",
      "pytest-openfiles                     0.4.0\n",
      "pytest-remotedata                    0.3.2\n",
      "python-dateutil                      2.8.2\n",
      "python-jsonrpc-server                0.3.4\n",
      "python-language-server               0.31.7\n",
      "pytz                                 2019.3\n",
      "PyWavelets                           1.1.1\n",
      "pyxdg                                0.26\n",
      "PyYAML                               6.0.1\n",
      "pyzmq                                25.1.1\n",
      "QDarkStyle                           2.8\n",
      "QtAwesome                            0.6.1\n",
      "qtconsole                            4.6.0\n",
      "QtPy                                 1.9.0\n",
      "regex                                2023.8.8\n",
      "requests                             2.31.0\n",
      "requests-kerberos                    0.12.0\n",
      "retrying                             1.3.4\n",
      "rope                                 0.16.0\n",
      "rsa                                  4.9\n",
      "Rtree                                0.9.3\n",
      "ruamel_yaml                          0.15.87\n",
      "s3fs                                 0.4.2\n",
      "s3transfer                           0.6.1\n",
      "sagemaker                            2.177.1\n",
      "sagemaker-data-insights              0.3.3\n",
      "sagemaker-datawrangler               0.4.3\n",
      "sagemaker-scikit-learn-extension     2.5.0\n",
      "sagemaker-studio-analytics-extension 0.0.19\n",
      "sagemaker-studio-sparkmagic-lib      0.1.4\n",
      "sasl                                 0.3a1\n",
      "schema                               0.7.5\n",
      "scikit-image                         0.16.2\n",
      "scikit-learn                         0.22.1\n",
      "scipy                                1.4.1\n",
      "seaborn                              0.10.0\n",
      "SecretStorage                        3.1.2\n",
      "Send2Trash                           1.8.2\n",
      "setuptools                           65.5.1\n",
      "simplegeneric                        0.8.1\n",
      "singledispatch                       3.4.0.3\n",
      "six                                  1.14.0\n",
      "smclarify                            0.5\n",
      "smdebug-rulesconfig                  1.0.1\n",
      "sniffio                              1.3.0\n",
      "snowballstemmer                      2.0.0\n",
      "sortedcollections                    1.1.2\n",
      "sortedcontainers                     2.1.0\n",
      "soupsieve                            1.9.5\n",
      "sparkmagic                           0.20.4\n",
      "Sphinx                               2.4.0\n",
      "sphinxcontrib-applehelp              1.0.1\n",
      "sphinxcontrib-devhelp                1.0.1\n",
      "sphinxcontrib-htmlhelp               1.0.2\n",
      "sphinxcontrib-jsmath                 1.0.1\n",
      "sphinxcontrib-qthelp                 1.0.2\n",
      "sphinxcontrib-serializinghtml        1.1.3\n",
      "sphinxcontrib-websupport             1.2.0\n",
      "spyder                               4.0.1\n",
      "spyder-kernels                       1.8.1\n",
      "SQLAlchemy                           1.3.13\n",
      "statsmodels                          0.11.0\n",
      "sympy                                1.5.1\n",
      "tables                               3.6.1\n",
      "tabulate                             0.9.0\n",
      "tblib                                1.7.0\n",
      "tenacity                             8.2.3\n",
      "terminado                            0.8.3\n",
      "testpath                             0.4.4\n",
      "thrift                               0.13.0\n",
      "thrift-sasl                          0.4.3\n",
      "tinycss2                             1.2.1\n",
      "tomli                                2.0.1\n",
      "tomlkit                              0.12.1\n",
      "toolz                                0.10.0\n",
      "tornado                              6.2\n",
      "tqdm                                 4.42.1\n",
      "traitlets                            5.9.0\n",
      "typed-ast                            1.5.5\n",
      "typing_extensions                    4.7.1\n",
      "ujson                                5.7.0\n",
      "unicodecsv                           0.14.1\n",
      "urllib3                              2.0.4\n",
      "watchdog                             0.10.2\n",
      "wcwidth                              0.1.8\n",
      "webencodings                         0.5.1\n",
      "websocket-client                     1.6.1\n",
      "Werkzeug                             2.2.3\n",
      "wheel                                0.41.1\n",
      "widgetsnbextension                   3.5.1\n",
      "wrapt                                1.11.2\n",
      "wurlitzer                            2.0.0\n",
      "xlrd                                 1.2.0\n",
      "XlsxWriter                           1.2.7\n",
      "xlwt                                 1.3.0\n",
      "yapf                                 0.28.0\n",
      "yarl                                 1.9.2\n",
      "zict                                 1.0.0\n",
      "zipp                                 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# Note that we are using AWS SageMaker 2.72.1\n",
    "# We will be using the new SageMaker 2.x SDK \n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Seaborn in /opt/conda/lib/python3.7/site-packages (0.10.0)\n",
      "Collecting Seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /opt/conda/lib/python3.7/site-packages (from Seaborn) (1.21.6)\n",
      "Requirement already satisfied: pandas>=0.25 in /opt/conda/lib/python3.7/site-packages (from Seaborn) (1.3.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /opt/conda/lib/python3.7/site-packages (from Seaborn) (3.1.3)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from Seaborn) (4.7.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->Seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->Seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->Seaborn) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.6.1,>=3.1->Seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.25->Seaborn) (2019.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib!=3.6.1,>=3.1->Seaborn) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.6.1,>=3.1->Seaborn) (65.5.1)\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: Seaborn\n",
      "  Attempting uninstall: Seaborn\n",
      "    Found existing installation: seaborn 0.10.0\n",
      "    Uninstalling seaborn-0.10.0:\n",
      "      Successfully uninstalled seaborn-0.10.0\n",
      "Successfully installed Seaborn-0.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install seaborn library\n",
    "!pip install --upgrade Seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjIiJdM4u1IE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the data using Pandas \n",
    "icecream_sales_df = pd.read_csv('IceCreamData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "q4_wPDKCu5Uc",
    "outputId": "886d2aaf-0205-4f46-96a7-629d0f367d2f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.566884</td>\n",
       "      <td>534.799028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.005191</td>\n",
       "      <td>625.190122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.790554</td>\n",
       "      <td>660.632289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.595335</td>\n",
       "      <td>487.706960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.503498</td>\n",
       "      <td>316.240194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>22.274899</td>\n",
       "      <td>524.746364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>32.893092</td>\n",
       "      <td>755.818399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>12.588157</td>\n",
       "      <td>306.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>22.362402</td>\n",
       "      <td>566.217304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>28.957736</td>\n",
       "      <td>655.660388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature     Revenue\n",
       "0      24.566884  534.799028\n",
       "1      26.005191  625.190122\n",
       "2      27.790554  660.632289\n",
       "3      20.595335  487.706960\n",
       "4      11.503498  316.240194\n",
       "..           ...         ...\n",
       "495    22.274899  524.746364\n",
       "496    32.893092  755.818399\n",
       "497    12.588157  306.090719\n",
       "498    22.362402  566.217304\n",
       "499    28.957736  655.660388\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the DataFrame\n",
    "icecream_sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.566884</td>\n",
       "      <td>534.799028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.005191</td>\n",
       "      <td>625.190122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.790554</td>\n",
       "      <td>660.632289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.595335</td>\n",
       "      <td>487.706960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.503498</td>\n",
       "      <td>316.240194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature     Revenue\n",
       "0    24.566884  534.799028\n",
       "1    26.005191  625.190122\n",
       "2    27.790554  660.632289\n",
       "3    20.595335  487.706960\n",
       "4    11.503498  316.240194"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icecream_sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>22.274899</td>\n",
       "      <td>524.746364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>32.893092</td>\n",
       "      <td>755.818399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>12.588157</td>\n",
       "      <td>306.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>22.362402</td>\n",
       "      <td>566.217304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>28.957736</td>\n",
       "      <td>655.660388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature     Revenue\n",
       "495    22.274899  524.746364\n",
       "496    32.893092  755.818399\n",
       "497    12.588157  306.090719\n",
       "498    22.362402  566.217304\n",
       "499    28.957736  655.660388"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icecream_sales_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OXZB2F21e4H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate the data into input X and Output y\n",
    "X = icecream_sales_df[['Temperature']]\n",
    "y = icecream_sales_df[['Revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.566884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.005191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.790554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.595335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.503498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>22.274899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>32.893092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>12.588157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>22.362402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>28.957736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature\n",
       "0      24.566884\n",
       "1      26.005191\n",
       "2      27.790554\n",
       "3      20.595335\n",
       "4      11.503498\n",
       "..           ...\n",
       "495    22.274899\n",
       "496    32.893092\n",
       "497    12.588157\n",
       "498    22.362402\n",
       "499    28.957736\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534.799028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>625.190122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660.632289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487.706960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316.240194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>524.746364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>755.818399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>306.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>566.217304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>655.660388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Revenue\n",
       "0    534.799028\n",
       "1    625.190122\n",
       "2    660.632289\n",
       "3    487.706960\n",
       "4    316.240194\n",
       "..          ...\n",
       "495  524.746364\n",
       "496  755.818399\n",
       "497  306.090719\n",
       "498  566.217304\n",
       "499  655.660388\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XpGU63Ne1e9P",
    "outputId": "e16c74ca-dc1c-416c-dc44-7f927bb99bc6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the shape of the input\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OjGj0RALA0qZ",
    "outputId": "26559a6c-880b-45b4-a1e8-3c4b92bea889",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the shape of the output\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIeiK1maA6mm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the datatype to float32\n",
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.566885 ],\n",
       "       [26.005192 ],\n",
       "       [27.790554 ],\n",
       "       [20.595335 ],\n",
       "       [11.503498 ],\n",
       "       [14.352514 ],\n",
       "       [13.70778  ],\n",
       "       [30.833984 ],\n",
       "       [ 0.97687  ],\n",
       "       [31.669464 ],\n",
       "       [11.455254 ],\n",
       "       [ 3.6646695],\n",
       "       [18.811825 ],\n",
       "       [13.624509 ],\n",
       "       [39.53991  ],\n",
       "       [18.48314  ],\n",
       "       [25.935375 ],\n",
       "       [42.51528  ],\n",
       "       [29.589481 ],\n",
       "       [21.775948 ],\n",
       "       [25.457836 ],\n",
       "       [15.214569 ],\n",
       "       [22.619316 ],\n",
       "       [16.25872  ],\n",
       "       [23.881725 ],\n",
       "       [18.9783   ],\n",
       "       [15.661465 ],\n",
       "       [29.185045 ],\n",
       "       [19.02461  ],\n",
       "       [35.12015  ],\n",
       "       [24.183937 ],\n",
       "       [15.23119  ],\n",
       "       [ 8.790953 ],\n",
       "       [18.233229 ],\n",
       "       [35.628925 ],\n",
       "       [37.05754  ],\n",
       "       [22.28455  ],\n",
       "       [17.517075 ],\n",
       "       [31.737919 ],\n",
       "       [17.049738 ],\n",
       "       [23.003489 ],\n",
       "       [ 8.755554 ],\n",
       "       [18.775358 ],\n",
       "       [14.109661 ],\n",
       "       [18.633913 ],\n",
       "       [15.676487 ],\n",
       "       [20.947914 ],\n",
       "       [30.635307 ],\n",
       "       [20.473595 ],\n",
       "       [31.228989 ],\n",
       "       [ 6.3938346],\n",
       "       [27.18581  ],\n",
       "       [28.633732 ],\n",
       "       [27.999222 ],\n",
       "       [10.326389 ],\n",
       "       [27.31281  ],\n",
       "       [33.235672 ],\n",
       "       [36.569115 ],\n",
       "       [12.462937 ],\n",
       "       [14.379697 ],\n",
       "       [16.302555 ],\n",
       "       [11.569644 ],\n",
       "       [33.55142  ],\n",
       "       [ 3.9865232],\n",
       "       [20.511637 ],\n",
       "       [ 6.5425143],\n",
       "       [19.81754  ],\n",
       "       [11.694538 ],\n",
       "       [21.488176 ],\n",
       "       [18.773533 ],\n",
       "       [12.68843  ],\n",
       "       [27.887112 ],\n",
       "       [26.95672  ],\n",
       "       [27.3754   ],\n",
       "       [24.101616 ],\n",
       "       [28.790102 ],\n",
       "       [40.473988 ],\n",
       "       [25.545965 ],\n",
       "       [28.701277 ],\n",
       "       [29.463785 ],\n",
       "       [16.020975 ],\n",
       "       [14.739551 ],\n",
       "       [22.1712   ],\n",
       "       [29.035738 ],\n",
       "       [29.209715 ],\n",
       "       [16.364944 ],\n",
       "       [27.7805   ],\n",
       "       [13.3306055],\n",
       "       [29.305038 ],\n",
       "       [14.384084 ],\n",
       "       [30.427792 ],\n",
       "       [ 9.073838 ],\n",
       "       [23.070616 ],\n",
       "       [ 8.586948 ],\n",
       "       [12.352081 ],\n",
       "       [ 9.01886  ],\n",
       "       [20.265013 ],\n",
       "       [19.363153 ],\n",
       "       [14.685945 ],\n",
       "       [ 9.954357 ],\n",
       "       [19.977467 ],\n",
       "       [32.00417  ],\n",
       "       [14.287196 ],\n",
       "       [17.658503 ],\n",
       "       [26.595055 ],\n",
       "       [17.26218  ],\n",
       "       [23.761436 ],\n",
       "       [15.588061 ],\n",
       "       [28.436567 ],\n",
       "       [27.7274   ],\n",
       "       [25.419302 ],\n",
       "       [18.475035 ],\n",
       "       [24.243113 ],\n",
       "       [31.668486 ],\n",
       "       [17.690031 ],\n",
       "       [31.891468 ],\n",
       "       [25.92517  ],\n",
       "       [29.312012 ],\n",
       "       [11.059096 ],\n",
       "       [25.496624 ],\n",
       "       [22.940317 ],\n",
       "       [12.901773 ],\n",
       "       [28.26283  ],\n",
       "       [30.562662 ],\n",
       "       [12.571514 ],\n",
       "       [19.059286 ],\n",
       "       [15.992347 ],\n",
       "       [26.18797  ],\n",
       "       [31.412628 ],\n",
       "       [32.297333 ],\n",
       "       [21.696783 ],\n",
       "       [20.475023 ],\n",
       "       [19.433268 ],\n",
       "       [20.12955  ],\n",
       "       [ 6.0938973],\n",
       "       [22.84197  ],\n",
       "       [24.585909 ],\n",
       "       [28.547987 ],\n",
       "       [19.77937  ],\n",
       "       [12.450833 ],\n",
       "       [36.70257  ],\n",
       "       [19.62266  ],\n",
       "       [32.40924  ],\n",
       "       [19.267786 ],\n",
       "       [19.728077 ],\n",
       "       [ 8.638076 ],\n",
       "       [29.430578 ],\n",
       "       [19.251654 ],\n",
       "       [24.615238 ],\n",
       "       [12.442651 ],\n",
       "       [24.548557 ],\n",
       "       [12.209683 ],\n",
       "       [12.265884 ],\n",
       "       [19.754707 ],\n",
       "       [23.349033 ],\n",
       "       [21.144047 ],\n",
       "       [18.880356 ],\n",
       "       [28.271765 ],\n",
       "       [16.406021 ],\n",
       "       [28.993736 ],\n",
       "       [10.245058 ],\n",
       "       [11.077843 ],\n",
       "       [25.499683 ],\n",
       "       [27.931349 ],\n",
       "       [28.459543 ],\n",
       "       [13.301796 ],\n",
       "       [25.995993 ],\n",
       "       [32.80503  ],\n",
       "       [32.71638  ],\n",
       "       [32.10708  ],\n",
       "       [24.778675 ],\n",
       "       [15.029112 ],\n",
       "       [23.424646 ],\n",
       "       [35.21724  ],\n",
       "       [16.379574 ],\n",
       "       [20.556679 ],\n",
       "       [21.322392 ],\n",
       "       [26.943638 ],\n",
       "       [22.634735 ],\n",
       "       [33.2509   ],\n",
       "       [ 8.99176  ],\n",
       "       [26.874952 ],\n",
       "       [21.358025 ],\n",
       "       [22.009874 ],\n",
       "       [29.129128 ],\n",
       "       [16.191298 ],\n",
       "       [35.35976  ],\n",
       "       [11.187757 ],\n",
       "       [16.555843 ],\n",
       "       [30.330332 ],\n",
       "       [12.900666 ],\n",
       "       [19.814638 ],\n",
       "       [20.934608 ],\n",
       "       [23.591028 ],\n",
       "       [16.557947 ],\n",
       "       [30.666595 ],\n",
       "       [ 9.8125105],\n",
       "       [31.579988 ],\n",
       "       [25.422165 ],\n",
       "       [25.241148 ],\n",
       "       [26.873587 ],\n",
       "       [21.424559 ],\n",
       "       [23.963879 ],\n",
       "       [10.447126 ],\n",
       "       [ 5.8223324],\n",
       "       [16.145824 ],\n",
       "       [23.959312 ],\n",
       "       [ 9.782381 ],\n",
       "       [23.975931 ],\n",
       "       [10.096644 ],\n",
       "       [22.387604 ],\n",
       "       [27.322323 ],\n",
       "       [20.247345 ],\n",
       "       [23.153002 ],\n",
       "       [15.753951 ],\n",
       "       [27.57296  ],\n",
       "       [18.776829 ],\n",
       "       [22.653135 ],\n",
       "       [17.993021 ],\n",
       "       [13.1124525],\n",
       "       [24.802576 ],\n",
       "       [18.60275  ],\n",
       "       [25.865944 ],\n",
       "       [26.250746 ],\n",
       "       [13.364313 ],\n",
       "       [21.540459 ],\n",
       "       [27.128128 ],\n",
       "       [26.944122 ],\n",
       "       [38.14633  ],\n",
       "       [ 4.236465 ],\n",
       "       [ 9.40348  ],\n",
       "       [20.153345 ],\n",
       "       [19.72133  ],\n",
       "       [19.194952 ],\n",
       "       [19.172045 ],\n",
       "       [36.11656  ],\n",
       "       [23.410862 ],\n",
       "       [29.91931  ],\n",
       "       [32.004364 ],\n",
       "       [29.768223 ],\n",
       "       [11.132706 ],\n",
       "       [23.385145 ],\n",
       "       [27.70506  ],\n",
       "       [15.047923 ],\n",
       "       [ 6.3524594],\n",
       "       [14.26354  ],\n",
       "       [25.422947 ],\n",
       "       [24.727154 ],\n",
       "       [16.300125 ],\n",
       "       [18.148952 ],\n",
       "       [18.57812  ],\n",
       "       [32.33481  ],\n",
       "       [ 7.561125 ],\n",
       "       [31.471224 ],\n",
       "       [28.335363 ],\n",
       "       [17.636936 ],\n",
       "       [21.703953 ],\n",
       "       [18.462906 ],\n",
       "       [32.479794 ],\n",
       "       [17.360731 ],\n",
       "       [21.007046 ],\n",
       "       [23.577114 ],\n",
       "       [30.76274  ],\n",
       "       [22.67856  ],\n",
       "       [28.855192 ],\n",
       "       [ 9.651495 ],\n",
       "       [18.506231 ],\n",
       "       [ 5.338413 ],\n",
       "       [35.458138 ],\n",
       "       [24.778198 ],\n",
       "       [24.62861  ],\n",
       "       [28.491764 ],\n",
       "       [24.949715 ],\n",
       "       [25.44824  ],\n",
       "       [22.24874  ],\n",
       "       [24.761877 ],\n",
       "       [22.448034 ],\n",
       "       [35.033455 ],\n",
       "       [33.74421  ],\n",
       "       [22.526749 ],\n",
       "       [28.464933 ],\n",
       "       [23.497532 ],\n",
       "       [26.078405 ],\n",
       "       [28.86559  ],\n",
       "       [22.146317 ],\n",
       "       [26.337053 ],\n",
       "       [25.00238  ],\n",
       "       [26.45605  ],\n",
       "       [22.189516 ],\n",
       "       [15.521162 ],\n",
       "       [17.65684  ],\n",
       "       [28.729916 ],\n",
       "       [27.529232 ],\n",
       "       [27.188517 ],\n",
       "       [10.403422 ],\n",
       "       [17.588371 ],\n",
       "       [24.521847 ],\n",
       "       [37.998634 ],\n",
       "       [16.954779 ],\n",
       "       [ 7.745286 ],\n",
       "       [ 5.858454 ],\n",
       "       [26.859722 ],\n",
       "       [24.493477 ],\n",
       "       [21.90252  ],\n",
       "       [30.028208 ],\n",
       "       [21.281916 ],\n",
       "       [32.46497  ],\n",
       "       [17.090645 ],\n",
       "       [33.315    ],\n",
       "       [23.412548 ],\n",
       "       [18.977991 ],\n",
       "       [12.270967 ],\n",
       "       [25.191425 ],\n",
       "       [27.068607 ],\n",
       "       [25.72547  ],\n",
       "       [22.311079 ],\n",
       "       [25.11607  ],\n",
       "       [22.152588 ],\n",
       "       [28.298689 ],\n",
       "       [21.712006 ],\n",
       "       [15.1181965],\n",
       "       [25.37411  ],\n",
       "       [18.439981 ],\n",
       "       [22.870562 ],\n",
       "       [14.361424 ],\n",
       "       [ 7.2613482],\n",
       "       [25.227774 ],\n",
       "       [20.971153 ],\n",
       "       [19.775148 ],\n",
       "       [41.924446 ],\n",
       "       [28.649193 ],\n",
       "       [29.241753 ],\n",
       "       [15.843022 ],\n",
       "       [20.898716 ],\n",
       "       [30.45674  ],\n",
       "       [24.818754 ],\n",
       "       [19.849241 ],\n",
       "       [22.118706 ],\n",
       "       [34.061672 ],\n",
       "       [ 9.557276 ],\n",
       "       [25.5512   ],\n",
       "       [19.066591 ],\n",
       "       [23.087664 ],\n",
       "       [ 8.033153 ],\n",
       "       [29.707024 ],\n",
       "       [12.189418 ],\n",
       "       [35.094795 ],\n",
       "       [24.960445 ],\n",
       "       [38.1852   ],\n",
       "       [18.985275 ],\n",
       "       [18.708475 ],\n",
       "       [ 7.223377 ],\n",
       "       [12.704718 ],\n",
       "       [24.528852 ],\n",
       "       [39.76413  ],\n",
       "       [30.247248 ],\n",
       "       [24.472433 ],\n",
       "       [20.24415  ],\n",
       "       [20.226421 ],\n",
       "       [14.896973 ],\n",
       "       [28.787436 ],\n",
       "       [29.704184 ],\n",
       "       [26.369747 ],\n",
       "       [ 6.775206 ],\n",
       "       [23.246717 ],\n",
       "       [24.308296 ],\n",
       "       [25.717962 ],\n",
       "       [21.684425 ],\n",
       "       [26.191668 ],\n",
       "       [21.601892 ],\n",
       "       [18.883718 ],\n",
       "       [ 0.2670277],\n",
       "       [19.617876 ],\n",
       "       [20.1039   ],\n",
       "       [23.98464  ],\n",
       "       [29.251123 ],\n",
       "       [34.8607   ],\n",
       "       [11.177152 ],\n",
       "       [26.126242 ],\n",
       "       [39.859398 ],\n",
       "       [20.411032 ],\n",
       "       [17.871199 ],\n",
       "       [18.346819 ],\n",
       "       [ 9.900293 ],\n",
       "       [25.05628  ],\n",
       "       [12.084601 ],\n",
       "       [36.997086 ],\n",
       "       [14.731824 ],\n",
       "       [ 7.107491 ],\n",
       "       [38.096607 ],\n",
       "       [26.923605 ],\n",
       "       [12.43314  ],\n",
       "       [10.119737 ],\n",
       "       [17.574234 ],\n",
       "       [12.062475 ],\n",
       "       [30.407616 ],\n",
       "       [ 7.335445 ],\n",
       "       [22.632977 ],\n",
       "       [28.046404 ],\n",
       "       [33.51454  ],\n",
       "       [24.240372 ],\n",
       "       [38.628864 ],\n",
       "       [ 0.       ],\n",
       "       [24.349104 ],\n",
       "       [26.16886  ],\n",
       "       [ 5.3075075],\n",
       "       [17.997015 ],\n",
       "       [30.965086 ],\n",
       "       [29.718515 ],\n",
       "       [32.649937 ],\n",
       "       [21.129126 ],\n",
       "       [18.55164  ],\n",
       "       [14.551212 ],\n",
       "       [41.76659  ],\n",
       "       [27.117739 ],\n",
       "       [20.016384 ],\n",
       "       [20.563015 ],\n",
       "       [27.516645 ],\n",
       "       [30.228104 ],\n",
       "       [21.679897 ],\n",
       "       [20.050186 ],\n",
       "       [17.299204 ],\n",
       "       [17.19943  ],\n",
       "       [35.444546 ],\n",
       "       [19.113653 ],\n",
       "       [18.95252  ],\n",
       "       [26.122137 ],\n",
       "       [19.982868 ],\n",
       "       [27.72144  ],\n",
       "       [21.026398 ],\n",
       "       [25.380438 ],\n",
       "       [24.113596 ],\n",
       "       [27.599066 ],\n",
       "       [ 8.756004 ],\n",
       "       [27.541962 ],\n",
       "       [15.916677 ],\n",
       "       [17.188948 ],\n",
       "       [28.79316  ],\n",
       "       [17.132795 ],\n",
       "       [ 8.794303 ],\n",
       "       [31.030333 ],\n",
       "       [19.20297  ],\n",
       "       [27.129412 ],\n",
       "       [30.081089 ],\n",
       "       [45.       ],\n",
       "       [18.90849  ],\n",
       "       [15.1029215],\n",
       "       [21.897432 ],\n",
       "       [29.508194 ],\n",
       "       [19.278671 ],\n",
       "       [29.879972 ],\n",
       "       [21.610643 ],\n",
       "       [24.98852  ],\n",
       "       [31.16003  ],\n",
       "       [34.678047 ],\n",
       "       [20.900576 ],\n",
       "       [37.12707  ],\n",
       "       [26.360521 ],\n",
       "       [35.331207 ],\n",
       "       [24.48491  ],\n",
       "       [38.6682   ],\n",
       "       [28.900192 ],\n",
       "       [12.123014 ],\n",
       "       [11.595102 ],\n",
       "       [17.455162 ],\n",
       "       [20.89662  ],\n",
       "       [40.30377  ],\n",
       "       [26.530218 ],\n",
       "       [39.513153 ],\n",
       "       [22.397978 ],\n",
       "       [ 9.309345 ],\n",
       "       [19.494743 ],\n",
       "       [22.225122 ],\n",
       "       [18.887161 ],\n",
       "       [21.752092 ],\n",
       "       [18.159216 ],\n",
       "       [14.866103 ],\n",
       "       [28.82976  ],\n",
       "       [25.33342  ],\n",
       "       [18.50836  ],\n",
       "       [22.482798 ],\n",
       "       [30.08519  ],\n",
       "       [16.997889 ],\n",
       "       [27.281063 ],\n",
       "       [ 4.865874 ],\n",
       "       [23.407257 ],\n",
       "       [12.301615 ],\n",
       "       [32.63286  ],\n",
       "       [16.703852 ],\n",
       "       [26.964218 ],\n",
       "       [23.824923 ],\n",
       "       [34.472168 ],\n",
       "       [23.056213 ],\n",
       "       [14.931506 ],\n",
       "       [25.112066 ],\n",
       "       [22.274899 ],\n",
       "       [32.893093 ],\n",
       "       [12.588157 ],\n",
       "       [22.362402 ],\n",
       "       [28.957737 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only take the numerical variables and scale them\n",
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 534.799  ],\n",
       "       [ 625.1901 ],\n",
       "       [ 660.63226],\n",
       "       [ 487.70697],\n",
       "       [ 316.2402 ],\n",
       "       [ 367.94073],\n",
       "       [ 308.89453],\n",
       "       [ 696.7166 ],\n",
       "       [  55.39034],\n",
       "       [ 737.80084],\n",
       "       [ 325.9684 ],\n",
       "       [  71.16016],\n",
       "       [ 467.44672],\n",
       "       [ 289.54092],\n",
       "       [ 905.4776 ],\n",
       "       [ 469.90903],\n",
       "       [ 648.21   ],\n",
       "       [ 921.5083 ],\n",
       "       [ 649.56116],\n",
       "       [ 534.62286],\n",
       "       [ 612.15393],\n",
       "       [ 353.32562],\n",
       "       [ 524.23615],\n",
       "       [ 374.23114],\n",
       "       [ 523.1246 ],\n",
       "       [ 473.60434],\n",
       "       [ 402.45532],\n",
       "       [ 679.3178 ],\n",
       "       [ 517.53406],\n",
       "       [ 809.67206],\n",
       "       [ 528.38043],\n",
       "       [ 356.09802],\n",
       "       [ 237.76392],\n",
       "       [ 418.13727],\n",
       "       [ 809.46344],\n",
       "       [ 870.7659 ],\n",
       "       [ 550.2785 ],\n",
       "       [ 405.66144],\n",
       "       [ 740.93567],\n",
       "       [ 501.733  ],\n",
       "       [ 539.688  ],\n",
       "       [ 242.2362 ],\n",
       "       [ 421.6215 ],\n",
       "       [ 358.00284],\n",
       "       [ 467.63107],\n",
       "       [ 396.93564],\n",
       "       [ 500.92508],\n",
       "       [ 651.8615 ],\n",
       "       [ 451.45078],\n",
       "       [ 697.834  ],\n",
       "       [ 190.71094],\n",
       "       [ 621.18976],\n",
       "       [ 666.13684],\n",
       "       [ 628.4532 ],\n",
       "       [ 219.30399],\n",
       "       [ 623.5989 ],\n",
       "       [ 749.3671 ],\n",
       "       [ 827.6848 ],\n",
       "       [ 303.73438],\n",
       "       [ 351.28888],\n",
       "       [ 381.56415],\n",
       "       [ 321.84827],\n",
       "       [ 774.1081 ],\n",
       "       [ 131.65701],\n",
       "       [ 498.75705],\n",
       "       [ 195.73572],\n",
       "       [ 496.0113 ],\n",
       "       [ 284.7728 ],\n",
       "       [ 483.48978],\n",
       "       [ 430.3439 ],\n",
       "       [ 276.78708],\n",
       "       [ 627.2913 ],\n",
       "       [ 643.6486 ],\n",
       "       [ 623.2487 ],\n",
       "       [ 586.1506 ],\n",
       "       [ 653.98676],\n",
       "       [ 918.39124],\n",
       "       [ 591.1734 ],\n",
       "       [ 651.1862 ],\n",
       "       [ 682.75287],\n",
       "       [ 372.9906 ],\n",
       "       [ 381.803  ],\n",
       "       [ 515.4591 ],\n",
       "       [ 685.36237],\n",
       "       [ 654.74744],\n",
       "       [ 406.57925],\n",
       "       [ 643.94434],\n",
       "       [ 344.68875],\n",
       "       [ 642.2273 ],\n",
       "       [ 361.11914],\n",
       "       [ 704.28143],\n",
       "       [ 222.87231],\n",
       "       [ 543.5996 ],\n",
       "       [ 221.2233 ],\n",
       "       [ 337.11902],\n",
       "       [ 212.59174],\n",
       "       [ 474.7494 ],\n",
       "       [ 460.4025 ],\n",
       "       [ 343.3629 ],\n",
       "       [ 283.83432],\n",
       "       [ 468.9751 ],\n",
       "       [ 711.1741 ],\n",
       "       [ 322.59274],\n",
       "       [ 401.433  ],\n",
       "       [ 627.90186],\n",
       "       [ 415.8177 ],\n",
       "       [ 553.4453 ],\n",
       "       [ 362.51523],\n",
       "       [ 643.7883 ],\n",
       "       [ 651.50433],\n",
       "       [ 603.0371 ],\n",
       "       [ 427.21136],\n",
       "       [ 565.875  ],\n",
       "       [ 733.2158 ],\n",
       "       [ 385.67252],\n",
       "       [ 689.9308 ],\n",
       "       [ 572.0813 ],\n",
       "       [ 719.4717 ],\n",
       "       [ 306.74994],\n",
       "       [ 596.2367 ],\n",
       "       [ 540.7981 ],\n",
       "       [ 341.85934],\n",
       "       [ 655.43396],\n",
       "       [ 702.90173],\n",
       "       [ 319.34946],\n",
       "       [ 450.4732 ],\n",
       "       [ 382.07394],\n",
       "       [ 674.15063],\n",
       "       [ 731.5982 ],\n",
       "       [ 751.05457],\n",
       "       [ 496.01193],\n",
       "       [ 417.35483],\n",
       "       [ 448.47134],\n",
       "       [ 477.29504],\n",
       "       [ 158.84981],\n",
       "       [ 516.5486 ],\n",
       "       [ 599.3649 ],\n",
       "       [ 656.63654],\n",
       "       [ 507.3568 ],\n",
       "       [ 279.86615],\n",
       "       [ 841.17145],\n",
       "       [ 483.33307],\n",
       "       [ 739.38727],\n",
       "       [ 486.47498],\n",
       "       [ 456.52435],\n",
       "       [ 241.27855],\n",
       "       [ 618.2358 ],\n",
       "       [ 446.94666],\n",
       "       [ 603.0914 ],\n",
       "       [ 274.0656 ],\n",
       "       [ 531.7425 ],\n",
       "       [ 297.4991 ],\n",
       "       [ 319.4029 ],\n",
       "       [ 493.71033],\n",
       "       [ 586.1388 ],\n",
       "       [ 497.75232],\n",
       "       [ 476.79453],\n",
       "       [ 625.8046 ],\n",
       "       [ 390.40335],\n",
       "       [ 675.8289 ],\n",
       "       [ 273.07333],\n",
       "       [ 280.51846],\n",
       "       [ 583.0845 ],\n",
       "       [ 648.5546 ],\n",
       "       [ 726.23376],\n",
       "       [ 335.81567],\n",
       "       [ 570.5779 ],\n",
       "       [ 685.65466],\n",
       "       [ 775.72284],\n",
       "       [ 773.92474],\n",
       "       [ 540.97754],\n",
       "       [ 366.2477 ],\n",
       "       [ 539.5277 ],\n",
       "       [ 809.7777 ],\n",
       "       [ 376.55447],\n",
       "       [ 477.8417 ],\n",
       "       [ 520.47034],\n",
       "       [ 654.1974 ],\n",
       "       [ 518.2161 ],\n",
       "       [ 782.0126 ],\n",
       "       [ 250.13173],\n",
       "       [ 634.5848 ],\n",
       "       [ 488.1708 ],\n",
       "       [ 520.85345],\n",
       "       [ 652.00543],\n",
       "       [ 383.95624],\n",
       "       [ 796.5177 ],\n",
       "       [ 293.9264 ],\n",
       "       [ 414.42303],\n",
       "       [ 691.958  ],\n",
       "       [ 339.1096 ],\n",
       "       [ 471.70157],\n",
       "       [ 499.45834],\n",
       "       [ 542.6081 ],\n",
       "       [ 401.9248 ],\n",
       "       [ 680.0271 ],\n",
       "       [ 258.2868 ],\n",
       "       [ 715.1247 ],\n",
       "       [ 608.93634],\n",
       "       [ 574.71063],\n",
       "       [ 615.92664],\n",
       "       [ 533.32434],\n",
       "       [ 578.3604 ],\n",
       "       [ 278.30984],\n",
       "       [ 186.47649],\n",
       "       [ 395.27374],\n",
       "       [ 537.11383],\n",
       "       [ 228.90103],\n",
       "       [ 603.233  ],\n",
       "       [ 272.85703],\n",
       "       [ 493.11548],\n",
       "       [ 612.8038 ],\n",
       "       [ 437.25198],\n",
       "       [ 506.49374],\n",
       "       [ 409.49384],\n",
       "       [ 562.7925 ],\n",
       "       [ 402.39847],\n",
       "       [ 532.054  ],\n",
       "       [ 413.91406],\n",
       "       [ 332.15012],\n",
       "       [ 563.3013 ],\n",
       "       [ 472.54935],\n",
       "       [ 596.98425],\n",
       "       [ 596.8891 ],\n",
       "       [ 268.92917],\n",
       "       [ 528.1162 ],\n",
       "       [ 627.6508 ],\n",
       "       [ 618.1721 ],\n",
       "       [ 850.247  ],\n",
       "       [ 118.81215],\n",
       "       [ 278.06277],\n",
       "       [ 449.11285],\n",
       "       [ 448.93045],\n",
       "       [ 463.0656 ],\n",
       "       [ 474.83224],\n",
       "       [ 824.95435],\n",
       "       [ 553.1196 ],\n",
       "       [ 696.6402 ],\n",
       "       [ 675.8071 ],\n",
       "       [ 695.8513 ],\n",
       "       [ 288.15814],\n",
       "       [ 506.43213],\n",
       "       [ 618.4573 ],\n",
       "       [ 367.05237],\n",
       "       [ 191.6233 ],\n",
       "       [ 334.43372],\n",
       "       [ 583.75977],\n",
       "       [ 538.1797 ],\n",
       "       [ 394.1686 ],\n",
       "       [ 473.5681 ],\n",
       "       [ 427.13837],\n",
       "       [ 747.96326],\n",
       "       [ 212.48357],\n",
       "       [ 691.51654],\n",
       "       [ 632.9019 ],\n",
       "       [ 448.54996],\n",
       "       [ 521.6728 ],\n",
       "       [ 437.8287 ],\n",
       "       [ 706.7246 ],\n",
       "       [ 405.2504 ],\n",
       "       [ 503.08426],\n",
       "       [ 570.9909 ],\n",
       "       [ 706.3649 ],\n",
       "       [ 543.98505],\n",
       "       [ 641.0254 ],\n",
       "       [ 274.67892],\n",
       "       [ 420.96646],\n",
       "       [ 145.6253 ],\n",
       "       [ 828.2961 ],\n",
       "       [ 594.8049 ],\n",
       "       [ 603.30536],\n",
       "       [ 651.48676],\n",
       "       [ 607.5422 ],\n",
       "       [ 625.84644],\n",
       "       [ 535.8667 ],\n",
       "       [ 530.7482 ],\n",
       "       [ 535.7089 ],\n",
       "       [ 781.98376],\n",
       "       [ 797.5665 ],\n",
       "       [ 521.2674 ],\n",
       "       [ 607.8392 ],\n",
       "       [ 534.36456],\n",
       "       [ 599.27826],\n",
       "       [ 662.55896],\n",
       "       [ 512.58813],\n",
       "       [ 574.42334],\n",
       "       [ 550.7014 ],\n",
       "       [ 554.743  ],\n",
       "       [ 496.46136],\n",
       "       [ 350.62903],\n",
       "       [ 409.4028 ],\n",
       "       [ 631.31824],\n",
       "       [ 661.4675 ],\n",
       "       [ 642.3498 ],\n",
       "       [ 321.75003],\n",
       "       [ 412.065  ],\n",
       "       [ 538.31287],\n",
       "       [ 857.5266 ],\n",
       "       [ 425.2656 ],\n",
       "       [ 198.12157],\n",
       "       [ 170.23776],\n",
       "       [ 599.11633],\n",
       "       [ 558.6369 ],\n",
       "       [ 550.4413 ],\n",
       "       [ 714.56006],\n",
       "       [ 526.70087],\n",
       "       [ 759.37744],\n",
       "       [ 441.50873],\n",
       "       [ 756.0377 ],\n",
       "       [ 542.8391 ],\n",
       "       [ 454.18927],\n",
       "       [ 335.15686],\n",
       "       [ 575.1769 ],\n",
       "       [ 594.651  ],\n",
       "       [ 621.96924],\n",
       "       [ 520.3924 ],\n",
       "       [ 587.22125],\n",
       "       [ 537.7661 ],\n",
       "       [ 639.538  ],\n",
       "       [ 467.40237],\n",
       "       [ 374.9557 ],\n",
       "       [ 604.62665],\n",
       "       [ 463.4805 ],\n",
       "       [ 550.05524],\n",
       "       [ 315.64658],\n",
       "       [ 223.43501],\n",
       "       [ 563.251  ],\n",
       "       [ 489.31525],\n",
       "       [ 458.8609 ],\n",
       "       [ 965.49304],\n",
       "       [ 689.8517 ],\n",
       "       [ 678.7514 ],\n",
       "       [ 379.56427],\n",
       "       [ 508.72046],\n",
       "       [ 684.8031 ],\n",
       "       [ 598.6762 ],\n",
       "       [ 416.84863],\n",
       "       [ 571.7643 ],\n",
       "       [ 771.78955],\n",
       "       [ 235.36464],\n",
       "       [ 579.3074 ],\n",
       "       [ 406.51608],\n",
       "       [ 536.2082 ],\n",
       "       [ 249.88425],\n",
       "       [ 702.994  ],\n",
       "       [ 335.77042],\n",
       "       [ 807.54126],\n",
       "       [ 564.31055],\n",
       "       [ 856.3033 ],\n",
       "       [ 482.572  ],\n",
       "       [ 436.95132],\n",
       "       [ 216.18346],\n",
       "       [ 295.3397 ],\n",
       "       [ 594.11035],\n",
       "       [ 935.7173 ],\n",
       "       [ 648.4536 ],\n",
       "       [ 596.8768 ],\n",
       "       [ 498.25214],\n",
       "       [ 475.5382 ],\n",
       "       [ 384.6994 ],\n",
       "       [ 633.504  ],\n",
       "       [ 659.8733 ],\n",
       "       [ 609.4175 ],\n",
       "       [ 199.5553 ],\n",
       "       [ 555.24524],\n",
       "       [ 594.31165],\n",
       "       [ 572.53705],\n",
       "       [ 478.5985 ],\n",
       "       [ 563.38165],\n",
       "       [ 545.90393],\n",
       "       [ 444.8268 ],\n",
       "       [  32.54662],\n",
       "       [ 506.22238],\n",
       "       [ 491.4305 ],\n",
       "       [ 559.13586],\n",
       "       [ 697.14746],\n",
       "       [ 798.0597 ],\n",
       "       [ 278.73196],\n",
       "       [ 594.8725 ],\n",
       "       [ 875.01935],\n",
       "       [ 513.8044 ],\n",
       "       [ 440.67783],\n",
       "       [ 410.8609 ],\n",
       "       [ 256.77258],\n",
       "       [ 583.8552 ],\n",
       "       [ 278.41827],\n",
       "       [ 851.3431 ],\n",
       "       [ 322.98398],\n",
       "       [ 221.40025],\n",
       "       [ 819.1176 ],\n",
       "       [ 644.48865],\n",
       "       [ 283.67966],\n",
       "       [ 276.37338],\n",
       "       [ 402.79318],\n",
       "       [ 300.93228],\n",
       "       [ 690.7893 ],\n",
       "       [ 192.342  ],\n",
       "       [ 546.69385],\n",
       "       [ 665.67267],\n",
       "       [ 750.44476],\n",
       "       [ 569.6188 ],\n",
       "       [ 916.6486 ],\n",
       "       [  10.     ],\n",
       "       [ 572.67206],\n",
       "       [ 658.60046],\n",
       "       [ 242.50986],\n",
       "       [ 441.00293],\n",
       "       [ 702.6236 ],\n",
       "       [ 643.09094],\n",
       "       [ 818.1354 ],\n",
       "       [ 493.22662],\n",
       "       [ 443.11362],\n",
       "       [ 323.94467],\n",
       "       [ 969.2916 ],\n",
       "       [ 658.59375],\n",
       "       [ 477.3152 ],\n",
       "       [ 425.01202],\n",
       "       [ 649.72906],\n",
       "       [ 679.71204],\n",
       "       [ 505.74387],\n",
       "       [ 473.49963],\n",
       "       [ 405.91516],\n",
       "       [ 428.85437],\n",
       "       [ 800.2025 ],\n",
       "       [ 445.7724 ],\n",
       "       [ 450.7086 ],\n",
       "       [ 617.1007 ],\n",
       "       [ 541.29364],\n",
       "       [ 654.89496],\n",
       "       [ 521.77545],\n",
       "       [ 603.32465],\n",
       "       [ 588.5275 ],\n",
       "       [ 634.12195],\n",
       "       [ 246.78716],\n",
       "       [ 640.17706],\n",
       "       [ 381.04337],\n",
       "       [ 390.87912],\n",
       "       [ 654.1294 ],\n",
       "       [ 412.08237],\n",
       "       [ 264.1239 ],\n",
       "       [ 684.15845],\n",
       "       [ 459.73535],\n",
       "       [ 615.17535],\n",
       "       [ 698.9718 ],\n",
       "       [1000.     ],\n",
       "       [ 449.8133 ],\n",
       "       [ 322.8888 ],\n",
       "       [ 493.42023],\n",
       "       [ 629.8938 ],\n",
       "       [ 452.6263 ],\n",
       "       [ 683.5448 ],\n",
       "       [ 537.6648 ],\n",
       "       [ 608.63   ],\n",
       "       [ 746.9464 ],\n",
       "       [ 756.9626 ],\n",
       "       [ 491.2306 ],\n",
       "       [ 892.9477 ],\n",
       "       [ 646.26697],\n",
       "       [ 804.26   ],\n",
       "       [ 526.54706],\n",
       "       [ 891.41364],\n",
       "       [ 636.2984 ],\n",
       "       [ 297.02542],\n",
       "       [ 257.07877],\n",
       "       [ 391.7153 ],\n",
       "       [ 494.62744],\n",
       "       [ 926.06714],\n",
       "       [ 612.2437 ],\n",
       "       [ 898.8054 ],\n",
       "       [ 489.5691 ],\n",
       "       [ 291.72305],\n",
       "       [ 429.4357 ],\n",
       "       [ 500.06577],\n",
       "       [ 475.21335],\n",
       "       [ 530.3567 ],\n",
       "       [ 453.7856 ],\n",
       "       [ 296.90652],\n",
       "       [ 682.8086 ],\n",
       "       [ 581.262  ],\n",
       "       [ 432.8198 ],\n",
       "       [ 507.90027],\n",
       "       [ 691.85547],\n",
       "       [ 448.326  ],\n",
       "       [ 612.24194],\n",
       "       [ 188.15134],\n",
       "       [ 501.34534],\n",
       "       [ 333.33426],\n",
       "       [ 793.07904],\n",
       "       [ 379.31824],\n",
       "       [ 581.07404],\n",
       "       [ 584.39996],\n",
       "       [ 809.35254],\n",
       "       [ 552.81934],\n",
       "       [ 377.43094],\n",
       "       [ 571.43427],\n",
       "       [ 524.74634],\n",
       "       [ 755.8184 ],\n",
       "       [ 306.09073],\n",
       "       [ 566.2173 ],\n",
       "       [ 655.6604 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GoReLFfnA6uF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data into training and testing using SkLearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #2 [OPTIONAL]:**\n",
    " - **Split the data into 75% for training and the rest for testing**\n",
    " - **Verify that the split was successful**\n",
    " - **Did you notice any change in the order of the data? why?**\n",
    " - **Add an attribute to disable data shuffling [external research is required]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split the data into training and testing using SkLearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #3: TRAIN A LINEAR LEARNER MODEL USING AWS SAGEMAKER (SDK 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::279288473542:role/service-role/AmazonSageMaker-ExecutionRole-20230912T204102\n"
     ]
    }
   ],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Let's define the S3 bucket and prefix that we want to use in this session\n",
    "bucket = 'ml-dataset-bucket' # bucket need to be created beforehand\n",
    "prefix = 'AWS-Linear-Learner' # prefix is the subfolder within the bucket.\n",
    "\n",
    "# Let's get the execution role for the notebook instance. \n",
    "# This is the IAM role that you created when you created your notebook instance. You pass the role to the training job.\n",
    "# Note that AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume to perform tasks on your behalf (for example, reading training results, called model artifacts, from the S3 bucket and writing training results to Amazon S3). \n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io # The io module allows for dealing with various types of I/O (text I/O, binary I/O and raw I/O). \n",
    "import numpy as np\n",
    "import sagemaker.amazon.common as smac # sagemaker common libary\n",
    "\n",
    "# Code below converts the data in numpy array format to RecordIO format\n",
    "# This is the format required by Sagemaker Linear Learner (one of many available options!)\n",
    "\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0) \n",
    "# When you write to in-memory byte arrays, it increments 1 every time you write to it\n",
    "# Let's reset that back to zero \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://ml-dataset-bucket/AWS-Linear-Learner/train/linear-train-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Code to upload RecordIO data to S3\n",
    " \n",
    "# Key refers to the name of the file    \n",
    "key = 'linear-train-data'\n",
    "\n",
    "# The following code uploads the data in record-io format to S3 bucket to be accessed later for training\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "# Let's print out the training data location in s3\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the target label is a vector\n",
    "y_test = y_test[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to upload RecordIO data to S3\n",
    "\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_test, y_test)\n",
    "buf.seek(0) \n",
    "# When you write to in-memory byte arrays, it increments 1 every time you write to it\n",
    "# Let's reset that back to zero \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://ml-dataset-bucket/AWS-Linear-Learner/test/linear-test-data\n"
     ]
    }
   ],
   "source": [
    "# Key refers to the name of the file    \n",
    "key = 'linear-test-data'\n",
    "\n",
    "# The following code uploads the data in record-io format to S3 bucket to be accessed later for training\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test', key)).upload_fileobj(buf)\n",
    "\n",
    "# Let's print out the testing data location in s3\n",
    "s3_test_data = 's3://{}/{}/test/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts will be uploaded to: s3://ml-dataset-bucket/AWS-Linear-Learner/output\n"
     ]
    }
   ],
   "source": [
    "# create an output placeholder in S3 bucket to store the linear learner output\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this code leverages the new SageMaker SDK 2.0\n",
    "# Check this out for the list of changes from AWS SageMaker SDK 1.0 to 2.0: https://sagemaker.readthedocs.io/en/stable/v2.html\n",
    "\n",
    "# This code is used to get the training container of sagemaker built-in algorithms\n",
    "# all we have to do is to specify the name of the algorithm that we want to use\n",
    "\n",
    "# Let's obtain a reference to the linearLearner container image\n",
    "# You don't have to specify (hardcode) the region, get_image_uri will get the current region name using boto3.Session\n",
    "container = sagemaker.image_uris.retrieve(\"linear-learner\", boto3.Session().region_name)\n",
    "\n",
    "\n",
    "# If you are using an old version of AWS SageMAker SDK 1.0, you need to use get_image_uri\n",
    "# from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "# container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: linear-learner-2023-09-19-22-03-06-263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-19 22:03:06 Starting - Starting the training job...\n",
      "2023-09-19 22:03:30 Starting - Preparing the instances for training.........\n",
      "2023-09-19 22:04:41 Downloading - Downloading input data...\n",
      "2023-09-19 22:05:12 Training - Downloading the training image......\n",
      "2023-09-19 22:06:23 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:39 INFO 140581587461952] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:39 INFO 140581587461952] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '10', 'feature_dim': '1', 'loss': 'absolute_loss', 'mini_batch_size': '5', 'num_models': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:39 INFO 140581587461952] Final configuration: {'mini_batch_size': '5', 'epochs': '10', 'feature_dim': '1', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '64', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:42 WARNING 140581587461952] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:42 INFO 140581587461952] Final configuration: {'mini_batch_size': '5', 'epochs': '10', 'feature_dim': '1', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '64', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:42 WARNING 140581587461952] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:42 INFO 140581587461952] Using default worker.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:42 INFO 140581587461952] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:42.482] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 16, \"num_examples\": 1, \"num_bytes\": 240}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:42 INFO 140581587461952] Create Store: local\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:43.050] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 567, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 INFO 140581587461952] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7fdb2312b390>\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 INFO 140581587461952] Scaling model computed with parameters:\n",
      " {'stdev_label': \u001b[0m\n",
      "\u001b[34m[173.81995]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[8.015975]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[34m[517.41486]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[22.085482]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 INFO 140581587461952] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 INFO 140581587461952] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 INFO 140581587461952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:43 WARNING 140581587461952] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161203.1704519, \"EndTime\": 1695161203.1704857, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 380.0, \"count\": 1, \"min\": 380, \"max\": 380}, \"Total Batches Seen\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:44.709] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 1539, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7100616, \"EndTime\": 1695161204.7101624, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6695248990058899, \"count\": 1, \"min\": 0.6695248990058899, \"max\": 0.6695248990058899}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7102659, \"EndTime\": 1695161204.7102883, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.685358672618866, \"count\": 1, \"min\": 0.685358672618866, \"max\": 0.685358672618866}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7103539, \"EndTime\": 1695161204.7103724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6717400979995728, \"count\": 1, \"min\": 0.6717400979995728, \"max\": 0.6717400979995728}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7104347, \"EndTime\": 1695161204.7104533, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6844241336186727, \"count\": 1, \"min\": 0.6844241336186727, \"max\": 0.6844241336186727}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7105174, \"EndTime\": 1695161204.7105362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4416965711911519, \"count\": 1, \"min\": 0.4416965711911519, \"max\": 0.4416965711911519}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7105968, \"EndTime\": 1695161204.7106166, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41636103884379067, \"count\": 1, \"min\": 0.41636103884379067, \"max\": 0.41636103884379067}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7106729, \"EndTime\": 1695161204.7106903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36261000601450605, \"count\": 1, \"min\": 0.36261000601450605, \"max\": 0.36261000601450605}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7107499, \"EndTime\": 1695161204.7107675, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3749127035140991, \"count\": 1, \"min\": 0.3749127035140991, \"max\": 0.3749127035140991}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.710837, \"EndTime\": 1695161204.7108557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7230188148816427, \"count\": 1, \"min\": 0.7230188148816427, \"max\": 0.7230188148816427}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.710926, \"EndTime\": 1695161204.7109451, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6558328553835551, \"count\": 1, \"min\": 0.6558328553835551, \"max\": 0.6558328553835551}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7110152, \"EndTime\": 1695161204.7110345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6644814019203186, \"count\": 1, \"min\": 0.6644814019203186, \"max\": 0.6644814019203186}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7111077, \"EndTime\": 1695161204.7111268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6476666771570841, \"count\": 1, \"min\": 0.6476666771570841, \"max\": 0.6476666771570841}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7111964, \"EndTime\": 1695161204.7112153, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4127914088567098, \"count\": 1, \"min\": 0.4127914088567098, \"max\": 0.4127914088567098}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7112756, \"EndTime\": 1695161204.7112935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.438076428492864, \"count\": 1, \"min\": 0.438076428492864, \"max\": 0.438076428492864}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7113621, \"EndTime\": 1695161204.7113807, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4026219425996145, \"count\": 1, \"min\": 0.4026219425996145, \"max\": 0.4026219425996145}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7114427, \"EndTime\": 1695161204.7114613, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4823877968788147, \"count\": 1, \"min\": 0.4823877968788147, \"max\": 0.4823877968788147}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.71153, \"EndTime\": 1695161204.711549, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6435237776438395, \"count\": 1, \"min\": 0.6435237776438395, \"max\": 0.6435237776438395}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7116172, \"EndTime\": 1695161204.7116358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6878545304934184, \"count\": 1, \"min\": 0.6878545304934184, \"max\": 0.6878545304934184}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7116961, \"EndTime\": 1695161204.7117145, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6682078425089518, \"count\": 1, \"min\": 0.6682078425089518, \"max\": 0.6682078425089518}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7117739, \"EndTime\": 1695161204.7117918, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6636915292739868, \"count\": 1, \"min\": 0.6636915292739868, \"max\": 0.6636915292739868}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7118518, \"EndTime\": 1695161204.7118692, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6402853309313457, \"count\": 1, \"min\": 0.6402853309313457, \"max\": 0.6402853309313457}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7119286, \"EndTime\": 1695161204.711944, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6331066196759542, \"count\": 1, \"min\": 0.6331066196759542, \"max\": 0.6331066196759542}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7120032, \"EndTime\": 1695161204.712022, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6387809648513794, \"count\": 1, \"min\": 0.6387809648513794, \"max\": 0.6387809648513794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7120802, \"EndTime\": 1695161204.7120981, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6373487325509389, \"count\": 1, \"min\": 0.6373487325509389, \"max\": 0.6373487325509389}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7121568, \"EndTime\": 1695161204.7121747, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8019308102925619, \"count\": 1, \"min\": 0.8019308102925619, \"max\": 0.8019308102925619}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7122407, \"EndTime\": 1695161204.7122567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8061261161168416, \"count\": 1, \"min\": 0.8061261161168416, \"max\": 0.8061261161168416}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7123053, \"EndTime\": 1695161204.7123225, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8049866285324097, \"count\": 1, \"min\": 0.8049866285324097, \"max\": 0.8049866285324097}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7123783, \"EndTime\": 1695161204.7123957, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8049719451268514, \"count\": 1, \"min\": 0.8049719451268514, \"max\": 0.8049719451268514}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7124395, \"EndTime\": 1695161204.712456, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9760840854644776, \"count\": 1, \"min\": 0.9760840854644776, \"max\": 0.9760840854644776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.712523, \"EndTime\": 1695161204.7125416, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9894894695281983, \"count\": 1, \"min\": 0.9894894695281983, \"max\": 0.9894894695281983}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7126012, \"EndTime\": 1695161204.7126176, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.977923565864563, \"count\": 1, \"min\": 0.977923565864563, \"max\": 0.977923565864563}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7126746, \"EndTime\": 1695161204.7126906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9897847766876221, \"count\": 1, \"min\": 0.9897847766876221, \"max\": 0.9897847766876221}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:44 INFO 140581587461952] #quality_metric: host=algo-1, epoch=0, train absolute_loss_objective <loss>=0.6695248990058899\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:44 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=absolute_loss_objective, value=0.36261000601450605\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:44 INFO 140581587461952] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:44 INFO 140581587461952] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:44 INFO 140581587461952] Saved checkpoint to \"/tmp/tmphnmfm1um/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:44 INFO 140581587461952] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161203.170768, \"EndTime\": 1695161204.729018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 755.0, \"count\": 1, \"min\": 755, \"max\": 755}, \"Total Batches Seen\": {\"sum\": 151.0, \"count\": 1, \"min\": 151, \"max\": 151}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:44 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=240.63268153924602 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:46.397] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 1668, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3978317, \"EndTime\": 1695161206.3979278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4087444240252177, \"count\": 1, \"min\": 0.4087444240252177, \"max\": 0.4087444240252177}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.398031, \"EndTime\": 1695161206.398053, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4065677811304728, \"count\": 1, \"min\": 0.4065677811304728, \"max\": 0.4065677811304728}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3981109, \"EndTime\": 1695161206.3981295, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41087014802296956, \"count\": 1, \"min\": 0.41087014802296956, \"max\": 0.41087014802296956}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3981879, \"EndTime\": 1695161206.3982043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4056704435348511, \"count\": 1, \"min\": 0.4056704435348511, \"max\": 0.4056704435348511}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3982651, \"EndTime\": 1695161206.3982828, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21346707542737325, \"count\": 1, \"min\": 0.21346707542737325, \"max\": 0.21346707542737325}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3983357, \"EndTime\": 1695161206.3983536, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16519826292991638, \"count\": 1, \"min\": 0.16519826292991638, \"max\": 0.16519826292991638}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3984082, \"EndTime\": 1695161206.3984275, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1951545165379842, \"count\": 1, \"min\": 0.1951545165379842, \"max\": 0.1951545165379842}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3984857, \"EndTime\": 1695161206.3985023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1961817189057668, \"count\": 1, \"min\": 0.1961817189057668, \"max\": 0.1961817189057668}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.398557, \"EndTime\": 1695161206.398575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4593174673716227, \"count\": 1, \"min\": 0.4593174673716227, \"max\": 0.4593174673716227}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3986373, \"EndTime\": 1695161206.398655, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3812844564119975, \"count\": 1, \"min\": 0.3812844564119975, \"max\": 0.3812844564119975}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.398706, \"EndTime\": 1695161206.3987234, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4052446298599243, \"count\": 1, \"min\": 0.4052446298599243, \"max\": 0.4052446298599243}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3987734, \"EndTime\": 1695161206.3987906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3714968786239624, \"count\": 1, \"min\": 0.3714968786239624, \"max\": 0.3714968786239624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3988495, \"EndTime\": 1695161206.3988664, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19377565574645997, \"count\": 1, \"min\": 0.19377565574645997, \"max\": 0.19377565574645997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3989215, \"EndTime\": 1695161206.3989384, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17989709639549256, \"count\": 1, \"min\": 0.17989709639549256, \"max\": 0.17989709639549256}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3989885, \"EndTime\": 1695161206.3990054, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16988928882280985, \"count\": 1, \"min\": 0.16988928882280985, \"max\": 0.16988928882280985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3990536, \"EndTime\": 1695161206.3990695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1730195529460907, \"count\": 1, \"min\": 0.1730195529460907, \"max\": 0.1730195529460907}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3991196, \"EndTime\": 1695161206.3991356, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4431553339958191, \"count\": 1, \"min\": 0.4431553339958191, \"max\": 0.4431553339958191}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3991823, \"EndTime\": 1695161206.399198, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.46790319204330444, \"count\": 1, \"min\": 0.46790319204330444, \"max\": 0.46790319204330444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3992565, \"EndTime\": 1695161206.3992734, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.46379244422912597, \"count\": 1, \"min\": 0.46379244422912597, \"max\": 0.46379244422912597}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3993225, \"EndTime\": 1695161206.3993385, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4495491622289022, \"count\": 1, \"min\": 0.4495491622289022, \"max\": 0.4495491622289022}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3993983, \"EndTime\": 1695161206.399415, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3906516483624776, \"count\": 1, \"min\": 0.3906516483624776, \"max\": 0.3906516483624776}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.399468, \"EndTime\": 1695161206.3994849, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3718030667304993, \"count\": 1, \"min\": 0.3718030667304993, \"max\": 0.3718030667304993}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3995357, \"EndTime\": 1695161206.3995512, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.39064305591583254, \"count\": 1, \"min\": 0.39064305591583254, \"max\": 0.39064305591583254}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3996115, \"EndTime\": 1695161206.3996284, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34901656373341877, \"count\": 1, \"min\": 0.34901656373341877, \"max\": 0.34901656373341877}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3996835, \"EndTime\": 1695161206.3997004, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8021902551651001, \"count\": 1, \"min\": 0.8021902551651001, \"max\": 0.8021902551651001}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3997493, \"EndTime\": 1695161206.3997655, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8027127803166707, \"count\": 1, \"min\": 0.8027127803166707, \"max\": 0.8027127803166707}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3998172, \"EndTime\": 1695161206.3998342, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8022740379969279, \"count\": 1, \"min\": 0.8022740379969279, \"max\": 0.8022740379969279}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.3998926, \"EndTime\": 1695161206.399909, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8027704753875733, \"count\": 1, \"min\": 0.8027704753875733, \"max\": 0.8027704753875733}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.399957, \"EndTime\": 1695161206.3999724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9192485011418661, \"count\": 1, \"min\": 0.9192485011418661, \"max\": 0.9192485011418661}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.400029, \"EndTime\": 1695161206.4000454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9022492888768514, \"count\": 1, \"min\": 0.9022492888768514, \"max\": 0.9022492888768514}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.4000967, \"EndTime\": 1695161206.400115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9078535884221395, \"count\": 1, \"min\": 0.9078535884221395, \"max\": 0.9078535884221395}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.4001746, \"EndTime\": 1695161206.4001923, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9033755280176798, \"count\": 1, \"min\": 0.9033755280176798, \"max\": 0.9033755280176798}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:46 INFO 140581587461952] #quality_metric: host=algo-1, epoch=1, train absolute_loss_objective <loss>=0.4087444240252177\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:46 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=absolute_loss_objective, value=0.16519826292991638\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:46 INFO 140581587461952] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:46 INFO 140581587461952] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:46 INFO 140581587461952] Saved checkpoint to \"/tmp/tmpnkruynj1/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:46 INFO 140581587461952] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161204.7293983, \"EndTime\": 1695161206.4099028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1130.0, \"count\": 1, \"min\": 1130, \"max\": 1130}, \"Total Batches Seen\": {\"sum\": 226.0, \"count\": 1, \"min\": 226, \"max\": 226}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:46 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=223.12707071810428 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:47.884] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 1473, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8844428, \"EndTime\": 1695161207.884532, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2055224196910858, \"count\": 1, \"min\": 0.2055224196910858, \"max\": 0.2055224196910858}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8846567, \"EndTime\": 1695161207.8846805, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18852128187815348, \"count\": 1, \"min\": 0.18852128187815348, \"max\": 0.18852128187815348}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8847497, \"EndTime\": 1695161207.884768, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.20650503969192505, \"count\": 1, \"min\": 0.20650503969192505, \"max\": 0.20650503969192505}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.884832, \"EndTime\": 1695161207.88485, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18690075699488323, \"count\": 1, \"min\": 0.18690075699488323, \"max\": 0.18690075699488323}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8849733, \"EndTime\": 1695161207.884995, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.22202794289588929, \"count\": 1, \"min\": 0.22202794289588929, \"max\": 0.22202794289588929}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8850572, \"EndTime\": 1695161207.8850749, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2187587931950887, \"count\": 1, \"min\": 0.2187587931950887, \"max\": 0.2187587931950887}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8851418, \"EndTime\": 1695161207.8851576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1930374773343404, \"count\": 1, \"min\": 0.1930374773343404, \"max\": 0.1930374773343404}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.885222, \"EndTime\": 1695161207.8852394, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18389691245555878, \"count\": 1, \"min\": 0.18389691245555878, \"max\": 0.18389691245555878}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8853261, \"EndTime\": 1695161207.885346, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.24228741590181987, \"count\": 1, \"min\": 0.24228741590181987, \"max\": 0.24228741590181987}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8854117, \"EndTime\": 1695161207.8854291, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17310684657096861, \"count\": 1, \"min\": 0.17310684657096861, \"max\": 0.17310684657096861}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8854856, \"EndTime\": 1695161207.8855019, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2037597724199295, \"count\": 1, \"min\": 0.2037597724199295, \"max\": 0.2037597724199295}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8855662, \"EndTime\": 1695161207.8855832, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16756709889570873, \"count\": 1, \"min\": 0.16756709889570873, \"max\": 0.16756709889570873}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.885641, \"EndTime\": 1695161207.8856614, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17468883128960927, \"count\": 1, \"min\": 0.17468883128960927, \"max\": 0.17468883128960927}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8857276, \"EndTime\": 1695161207.8857446, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18247563497225444, \"count\": 1, \"min\": 0.18247563497225444, \"max\": 0.18247563497225444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.885801, \"EndTime\": 1695161207.8858178, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16188424223661424, \"count\": 1, \"min\": 0.16188424223661424, \"max\": 0.16188424223661424}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8858829, \"EndTime\": 1695161207.8858986, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21378967746098837, \"count\": 1, \"min\": 0.21378967746098837, \"max\": 0.21378967746098837}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.885987, \"EndTime\": 1695161207.8860044, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3342796161969503, \"count\": 1, \"min\": 0.3342796161969503, \"max\": 0.3342796161969503}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8860657, \"EndTime\": 1695161207.8860838, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34155780426661175, \"count\": 1, \"min\": 0.34155780426661175, \"max\": 0.34155780426661175}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8861465, \"EndTime\": 1695161207.8861647, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3466506533622742, \"count\": 1, \"min\": 0.3466506533622742, \"max\": 0.3466506533622742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.886226, \"EndTime\": 1695161207.8862426, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.33244171539942424, \"count\": 1, \"min\": 0.33244171539942424, \"max\": 0.33244171539942424}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8862984, \"EndTime\": 1695161207.886315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5089738354682922, \"count\": 1, \"min\": 0.5089738354682922, \"max\": 0.5089738354682922}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8863697, \"EndTime\": 1695161207.8863869, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.45800159056981404, \"count\": 1, \"min\": 0.45800159056981404, \"max\": 0.45800159056981404}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8864696, \"EndTime\": 1695161207.8864877, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5089781360626221, \"count\": 1, \"min\": 0.5089781360626221, \"max\": 0.5089781360626221}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8865535, \"EndTime\": 1695161207.8865693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3261839869817098, \"count\": 1, \"min\": 0.3261839869817098, \"max\": 0.3261839869817098}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8866346, \"EndTime\": 1695161207.8866513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8027403570810954, \"count\": 1, \"min\": 0.8027403570810954, \"max\": 0.8027403570810954}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8867123, \"EndTime\": 1695161207.8867297, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8036798248291016, \"count\": 1, \"min\": 0.8036798248291016, \"max\": 0.8036798248291016}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8867967, \"EndTime\": 1695161207.886814, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8027778164545695, \"count\": 1, \"min\": 0.8027778164545695, \"max\": 0.8027778164545695}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8868709, \"EndTime\": 1695161207.8868883, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8037210499445597, \"count\": 1, \"min\": 0.8037210499445597, \"max\": 0.8037210499445597}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.88694, \"EndTime\": 1695161207.8869557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8841678396860758, \"count\": 1, \"min\": 0.8841678396860758, \"max\": 0.8841678396860758}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8870213, \"EndTime\": 1695161207.8870378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9218730325698853, \"count\": 1, \"min\": 0.9218730325698853, \"max\": 0.9218730325698853}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8871038, \"EndTime\": 1695161207.887121, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8808114732106527, \"count\": 1, \"min\": 0.8808114732106527, \"max\": 0.8808114732106527}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8871775, \"EndTime\": 1695161207.8871927, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9223628851572673, \"count\": 1, \"min\": 0.9223628851572673, \"max\": 0.9223628851572673}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:47 INFO 140581587461952] #quality_metric: host=algo-1, epoch=2, train absolute_loss_objective <loss>=0.2055224196910858\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:47 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=absolute_loss_objective, value=0.16188424223661424\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:47 INFO 140581587461952] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:47 INFO 140581587461952] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:47 INFO 140581587461952] Saved checkpoint to \"/tmp/tmpyv9euo6u/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:47 INFO 140581587461952] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161206.4102068, \"EndTime\": 1695161207.896291, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1505.0, \"count\": 1, \"min\": 1505, \"max\": 1505}, \"Total Batches Seen\": {\"sum\": 301.0, \"count\": 1, \"min\": 301, \"max\": 301}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:47 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=252.3156737194434 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:49.857] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 1960, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8574853, \"EndTime\": 1695161209.8575711, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12687703088919322, \"count\": 1, \"min\": 0.12687703088919322, \"max\": 0.12687703088919322}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8577294, \"EndTime\": 1695161209.8577476, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12195475212732951, \"count\": 1, \"min\": 0.12195475212732951, \"max\": 0.12195475212732951}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.857792, \"EndTime\": 1695161209.8578036, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12702321688334148, \"count\": 1, \"min\": 0.12702321688334148, \"max\": 0.12702321688334148}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8578465, \"EndTime\": 1695161209.8578577, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12161272303263346, \"count\": 1, \"min\": 0.12161272303263346, \"max\": 0.12161272303263346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8578959, \"EndTime\": 1695161209.8579063, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1486327342192332, \"count\": 1, \"min\": 0.1486327342192332, \"max\": 0.1486327342192332}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8579428, \"EndTime\": 1695161209.857953, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18524127920468647, \"count\": 1, \"min\": 0.18524127920468647, \"max\": 0.18524127920468647}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.857991, \"EndTime\": 1695161209.8580015, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18380575768152874, \"count\": 1, \"min\": 0.18380575768152874, \"max\": 0.18380575768152874}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8580437, \"EndTime\": 1695161209.8580544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16017385522524516, \"count\": 1, \"min\": 0.16017385522524516, \"max\": 0.16017385522524516}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8580918, \"EndTime\": 1695161209.8581023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13165474502245586, \"count\": 1, \"min\": 0.13165474502245586, \"max\": 0.13165474502245586}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8581388, \"EndTime\": 1695161209.8581488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12246105551719666, \"count\": 1, \"min\": 0.12246105551719666, \"max\": 0.12246105551719666}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8581889, \"EndTime\": 1695161209.8581994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12609888076782227, \"count\": 1, \"min\": 0.12609888076782227, \"max\": 0.12609888076782227}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8582363, \"EndTime\": 1695161209.8582466, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12158875226974487, \"count\": 1, \"min\": 0.12158875226974487, \"max\": 0.12158875226974487}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8582833, \"EndTime\": 1695161209.8582933, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16894520910580954, \"count\": 1, \"min\": 0.16894520910580954, \"max\": 0.16894520910580954}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8583326, \"EndTime\": 1695161209.8583431, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17351481481393177, \"count\": 1, \"min\": 0.17351481481393177, \"max\": 0.17351481481393177}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8583837, \"EndTime\": 1695161209.8583941, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15448697431882222, \"count\": 1, \"min\": 0.15448697431882222, \"max\": 0.15448697431882222}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8584342, \"EndTime\": 1695161209.8584447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17692763562997182, \"count\": 1, \"min\": 0.17692763562997182, \"max\": 0.17692763562997182}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8584816, \"EndTime\": 1695161209.8584921, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.28613197612762453, \"count\": 1, \"min\": 0.28613197612762453, \"max\": 0.28613197612762453}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8585277, \"EndTime\": 1695161209.858538, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.28496402549743655, \"count\": 1, \"min\": 0.28496402549743655, \"max\": 0.28496402549743655}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8585775, \"EndTime\": 1695161209.8585882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.29428242524464926, \"count\": 1, \"min\": 0.29428242524464926, \"max\": 0.29428242524464926}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8586283, \"EndTime\": 1695161209.8586388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.28041733503341676, \"count\": 1, \"min\": 0.28041733503341676, \"max\": 0.28041733503341676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8586788, \"EndTime\": 1695161209.8586895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41523967615763346, \"count\": 1, \"min\": 0.41523967615763346, \"max\": 0.41523967615763346}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8587263, \"EndTime\": 1695161209.858736, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3829728600184123, \"count\": 1, \"min\": 0.3829728600184123, \"max\": 0.3829728600184123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8587723, \"EndTime\": 1695161209.8587825, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4152364064852397, \"count\": 1, \"min\": 0.4152364064852397, \"max\": 0.4152364064852397}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.858818, \"EndTime\": 1695161209.8588283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3663286026318868, \"count\": 1, \"min\": 0.3663286026318868, \"max\": 0.3663286026318868}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8588672, \"EndTime\": 1695161209.858878, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8033816404342652, \"count\": 1, \"min\": 0.8033816404342652, \"max\": 0.8033816404342652}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8589175, \"EndTime\": 1695161209.8589282, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.802661805788676, \"count\": 1, \"min\": 0.802661805788676, \"max\": 0.802661805788676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8589647, \"EndTime\": 1695161209.858975, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8034127772649129, \"count\": 1, \"min\": 0.8034127772649129, \"max\": 0.8034127772649129}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8590114, \"EndTime\": 1695161209.8590214, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8026832335789998, \"count\": 1, \"min\": 0.8026832335789998, \"max\": 0.8026832335789998}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.859061, \"EndTime\": 1695161209.8590715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8844740254084269, \"count\": 1, \"min\": 0.8844740254084269, \"max\": 0.8844740254084269}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8591123, \"EndTime\": 1695161209.8591225, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9255151144663493, \"count\": 1, \"min\": 0.9255151144663493, \"max\": 0.9255151144663493}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8591592, \"EndTime\": 1695161209.8591695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8674356304804484, \"count\": 1, \"min\": 0.8674356304804484, \"max\": 0.8674356304804484}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.859205, \"EndTime\": 1695161209.8592153, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9258346837361654, \"count\": 1, \"min\": 0.9258346837361654, \"max\": 0.9258346837361654}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:49 INFO 140581587461952] #quality_metric: host=algo-1, epoch=3, train absolute_loss_objective <loss>=0.12687703088919322\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:49 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=absolute_loss_objective, value=0.12158875226974487\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:49 INFO 140581587461952] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:49 INFO 140581587461952] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:49 INFO 140581587461952] Saved checkpoint to \"/tmp/tmp26w_1qtk/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:49 INFO 140581587461952] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161207.8966246, \"EndTime\": 1695161209.8719308, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1880.0, \"count\": 1, \"min\": 1880, \"max\": 1880}, \"Total Batches Seen\": {\"sum\": 376.0, \"count\": 1, \"min\": 376, \"max\": 376}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:49 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=189.82890145700546 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:51.713] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 1840, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7132342, \"EndTime\": 1695161211.713347, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11901693185170492, \"count\": 1, \"min\": 0.11901693185170492, \"max\": 0.11901693185170492}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7134519, \"EndTime\": 1695161211.7134743, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1186293698946635, \"count\": 1, \"min\": 0.1186293698946635, \"max\": 0.1186293698946635}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.71353, \"EndTime\": 1695161211.7135477, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11904874205589294, \"count\": 1, \"min\": 0.11904874205589294, \"max\": 0.11904874205589294}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7136068, \"EndTime\": 1695161211.7136235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12118490131696065, \"count\": 1, \"min\": 0.12118490131696065, \"max\": 0.12118490131696065}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.713683, \"EndTime\": 1695161211.7136993, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15653365763028462, \"count\": 1, \"min\": 0.15653365763028462, \"max\": 0.15653365763028462}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7137542, \"EndTime\": 1695161211.713772, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1811028167804082, \"count\": 1, \"min\": 0.1811028167804082, \"max\": 0.1811028167804082}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.713831, \"EndTime\": 1695161211.7138488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.164026579618454, \"count\": 1, \"min\": 0.164026579618454, \"max\": 0.164026579618454}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.713907, \"EndTime\": 1695161211.713925, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19243732817967732, \"count\": 1, \"min\": 0.19243732817967732, \"max\": 0.19243732817967732}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.713983, \"EndTime\": 1695161211.7140007, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11852219684918722, \"count\": 1, \"min\": 0.11852219684918722, \"max\": 0.11852219684918722}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7140563, \"EndTime\": 1695161211.7140737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12046434410413107, \"count\": 1, \"min\": 0.12046434410413107, \"max\": 0.12046434410413107}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.714133, \"EndTime\": 1695161211.7141511, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11877798310915628, \"count\": 1, \"min\": 0.11877798310915628, \"max\": 0.11877798310915628}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.714208, \"EndTime\": 1695161211.7142265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11988662624359131, \"count\": 1, \"min\": 0.11988662624359131, \"max\": 0.11988662624359131}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7142851, \"EndTime\": 1695161211.7143028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1478909898996353, \"count\": 1, \"min\": 0.1478909898996353, \"max\": 0.1478909898996353}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7143548, \"EndTime\": 1695161211.7143722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1720141657193502, \"count\": 1, \"min\": 0.1720141657193502, \"max\": 0.1720141657193502}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7144213, \"EndTime\": 1695161211.714437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15859591229756673, \"count\": 1, \"min\": 0.15859591229756673, \"max\": 0.15859591229756673}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7144973, \"EndTime\": 1695161211.7145152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17768811535835266, \"count\": 1, \"min\": 0.17768811535835266, \"max\": 0.17768811535835266}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.714574, \"EndTime\": 1695161211.714591, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.26484820381800334, \"count\": 1, \"min\": 0.26484820381800334, \"max\": 0.26484820381800334}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7146523, \"EndTime\": 1695161211.714671, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2650280613899231, \"count\": 1, \"min\": 0.2650280613899231, \"max\": 0.2650280613899231}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.714726, \"EndTime\": 1695161211.7147434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2695284951527913, \"count\": 1, \"min\": 0.2695284951527913, \"max\": 0.2695284951527913}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7148006, \"EndTime\": 1695161211.7148185, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2640169768333435, \"count\": 1, \"min\": 0.2640169768333435, \"max\": 0.2640169768333435}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7148657, \"EndTime\": 1695161211.7148826, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41492491006851195, \"count\": 1, \"min\": 0.41492491006851195, \"max\": 0.41492491006851195}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7149293, \"EndTime\": 1695161211.714946, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.39278956095377604, \"count\": 1, \"min\": 0.39278956095377604, \"max\": 0.39278956095377604}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7149942, \"EndTime\": 1695161211.715011, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41493056853612265, \"count\": 1, \"min\": 0.41493056853612265, \"max\": 0.41493056853612265}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.715058, \"EndTime\": 1695161211.7150748, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.32465871413548786, \"count\": 1, \"min\": 0.32465871413548786, \"max\": 0.32465871413548786}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7151184, \"EndTime\": 1695161211.715134, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8038540096282959, \"count\": 1, \"min\": 0.8038540096282959, \"max\": 0.8038540096282959}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.715186, \"EndTime\": 1695161211.7152028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.80355730342865, \"count\": 1, \"min\": 0.80355730342865, \"max\": 0.80355730342865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7152467, \"EndTime\": 1695161211.715263, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8038773864110311, \"count\": 1, \"min\": 0.8038773864110311, \"max\": 0.8038773864110311}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.715316, \"EndTime\": 1695161211.7153325, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8035859937667846, \"count\": 1, \"min\": 0.8035859937667846, \"max\": 0.8035859937667846}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7154005, \"EndTime\": 1695161211.7154188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8662499221165975, \"count\": 1, \"min\": 0.8662499221165975, \"max\": 0.8662499221165975}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7154791, \"EndTime\": 1695161211.7154977, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9121691385904948, \"count\": 1, \"min\": 0.9121691385904948, \"max\": 0.9121691385904948}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7155542, \"EndTime\": 1695161211.71557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8672795867919922, \"count\": 1, \"min\": 0.8672795867919922, \"max\": 0.8672795867919922}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.7156274, \"EndTime\": 1695161211.7156456, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9123687283198039, \"count\": 1, \"min\": 0.9123687283198039, \"max\": 0.9123687283198039}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:51 INFO 140581587461952] #quality_metric: host=algo-1, epoch=4, train absolute_loss_objective <loss>=0.11901693185170492\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:51 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=absolute_loss_objective, value=0.11852219684918722\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:51 INFO 140581587461952] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:51 INFO 140581587461952] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:51 INFO 140581587461952] Saved checkpoint to \"/tmp/tmp2etd26ez/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:51 INFO 140581587461952] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161209.8722525, \"EndTime\": 1695161211.7247174, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2255.0, \"count\": 1, \"min\": 2255, \"max\": 2255}, \"Total Batches Seen\": {\"sum\": 451.0, \"count\": 1, \"min\": 451, \"max\": 451}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:51 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=202.4177434685999 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:53.146] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 1421, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1467755, \"EndTime\": 1695161213.146869, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12089268239339193, \"count\": 1, \"min\": 0.12089268239339193, \"max\": 0.12089268239339193}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1469696, \"EndTime\": 1695161213.1469903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12082270630200705, \"count\": 1, \"min\": 0.12082270630200705, \"max\": 0.12082270630200705}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1470501, \"EndTime\": 1695161213.1470675, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12099137576421101, \"count\": 1, \"min\": 0.12099137576421101, \"max\": 0.12099137576421101}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.147126, \"EndTime\": 1695161213.1471436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12113557155927022, \"count\": 1, \"min\": 0.12113557155927022, \"max\": 0.12113557155927022}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1471987, \"EndTime\": 1695161213.1472156, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17405273127555848, \"count\": 1, \"min\": 0.17405273127555848, \"max\": 0.17405273127555848}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.147271, \"EndTime\": 1695161213.1472874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17344950044155122, \"count\": 1, \"min\": 0.17344950044155122, \"max\": 0.17344950044155122}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1473434, \"EndTime\": 1695161213.1473615, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15224843537807464, \"count\": 1, \"min\": 0.15224843537807464, \"max\": 0.15224843537807464}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1474135, \"EndTime\": 1695161213.14743, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17204128213723502, \"count\": 1, \"min\": 0.17204128213723502, \"max\": 0.17204128213723502}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1474833, \"EndTime\": 1695161213.1474996, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12032807771364848, \"count\": 1, \"min\": 0.12032807771364848, \"max\": 0.12032807771364848}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1475556, \"EndTime\": 1695161213.1475716, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11915845235188802, \"count\": 1, \"min\": 0.11915845235188802, \"max\": 0.11915845235188802}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1476266, \"EndTime\": 1695161213.1476421, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12065655628840129, \"count\": 1, \"min\": 0.12065655628840129, \"max\": 0.12065655628840129}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.147696, \"EndTime\": 1695161213.1477122, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11867766348520915, \"count\": 1, \"min\": 0.11867766348520915, \"max\": 0.11867766348520915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1477683, \"EndTime\": 1695161213.147784, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15289901145299276, \"count\": 1, \"min\": 0.15289901145299276, \"max\": 0.15289901145299276}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1478384, \"EndTime\": 1695161213.147854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18600750158230464, \"count\": 1, \"min\": 0.18600750158230464, \"max\": 0.18600750158230464}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1479068, \"EndTime\": 1695161213.1479228, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1680762085914612, \"count\": 1, \"min\": 0.1680762085914612, \"max\": 0.1680762085914612}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1479783, \"EndTime\": 1695161213.147994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.22050451151529948, \"count\": 1, \"min\": 0.22050451151529948, \"max\": 0.22050451151529948}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1480486, \"EndTime\": 1695161213.1480634, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2560217346350352, \"count\": 1, \"min\": 0.2560217346350352, \"max\": 0.2560217346350352}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1481147, \"EndTime\": 1695161213.1481318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2585939299265544, \"count\": 1, \"min\": 0.2585939299265544, \"max\": 0.2585939299265544}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1481898, \"EndTime\": 1695161213.1482058, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2585898399353027, \"count\": 1, \"min\": 0.2585898399353027, \"max\": 0.2585898399353027}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1482592, \"EndTime\": 1695161213.148275, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2577385376294454, \"count\": 1, \"min\": 0.2577385376294454, \"max\": 0.2577385376294454}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1483278, \"EndTime\": 1695161213.1483445, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4182379390398661, \"count\": 1, \"min\": 0.4182379390398661, \"max\": 0.4182379390398661}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1484067, \"EndTime\": 1695161213.1484227, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5531662240028381, \"count\": 1, \"min\": 0.5531662240028381, \"max\": 0.5531662240028381}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1484787, \"EndTime\": 1695161213.148494, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41823730897903444, \"count\": 1, \"min\": 0.41823730897903444, \"max\": 0.41823730897903444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1485558, \"EndTime\": 1695161213.1485727, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3364167308807373, \"count\": 1, \"min\": 0.3364167308807373, \"max\": 0.3364167308807373}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1486297, \"EndTime\": 1695161213.1486454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8030005283355713, \"count\": 1, \"min\": 0.8030005283355713, \"max\": 0.8030005283355713}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1487105, \"EndTime\": 1695161213.148727, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8025572439829508, \"count\": 1, \"min\": 0.8025572439829508, \"max\": 0.8025572439829508}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1487818, \"EndTime\": 1695161213.1487985, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8030215218861898, \"count\": 1, \"min\": 0.8030215218861898, \"max\": 0.8030215218861898}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1488576, \"EndTime\": 1695161213.1488752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8025728960037232, \"count\": 1, \"min\": 0.8025728960037232, \"max\": 0.8025728960037232}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.148938, \"EndTime\": 1695161213.1489544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8455608393351237, \"count\": 1, \"min\": 0.8455608393351237, \"max\": 0.8455608393351237}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1490078, \"EndTime\": 1695161213.1490216, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.896911229133606, \"count\": 1, \"min\": 0.896911229133606, \"max\": 0.896911229133606}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1490755, \"EndTime\": 1695161213.1490924, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8636553579966227, \"count\": 1, \"min\": 0.8636553579966227, \"max\": 0.8636553579966227}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1491466, \"EndTime\": 1695161213.1491635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9187466268539428, \"count\": 1, \"min\": 0.9187466268539428, \"max\": 0.9187466268539428}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:53 INFO 140581587461952] #quality_metric: host=algo-1, epoch=5, train absolute_loss_objective <loss>=0.12089268239339193\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:53 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=absolute_loss_objective, value=0.11867766348520915\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:53 INFO 140581587461952] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:53 INFO 140581587461952] Saved checkpoint to \"/tmp/tmpurotlym3/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:53 INFO 140581587461952] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161211.725042, \"EndTime\": 1695161213.1575258, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2630.0, \"count\": 1, \"min\": 2630, \"max\": 2630}, \"Total Batches Seen\": {\"sum\": 526.0, \"count\": 1, \"min\": 526, \"max\": 526}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:53 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=261.75381231710594 records/second\u001b[0m\n",
      "\n",
      "2023-09-19 22:07:08 Uploading - Uploading generated training model\u001b[34m[2023-09-19 22:06:54.825] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 1666, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8250875, \"EndTime\": 1695161214.825176, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1189781494140625, \"count\": 1, \"min\": 0.1189781494140625, \"max\": 0.1189781494140625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8253205, \"EndTime\": 1695161214.8253424, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12039093899726867, \"count\": 1, \"min\": 0.12039093899726867, \"max\": 0.12039093899726867}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8254106, \"EndTime\": 1695161214.8254275, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11982152072588603, \"count\": 1, \"min\": 0.11982152072588603, \"max\": 0.11982152072588603}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.825477, \"EndTime\": 1695161214.825491, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12167908477783203, \"count\": 1, \"min\": 0.12167908477783203, \"max\": 0.12167908477783203}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8255346, \"EndTime\": 1695161214.8255458, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1477656914393107, \"count\": 1, \"min\": 0.1477656914393107, \"max\": 0.1477656914393107}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.825588, \"EndTime\": 1695161214.825599, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21925385824839275, \"count\": 1, \"min\": 0.21925385824839275, \"max\": 0.21925385824839275}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.82564, \"EndTime\": 1695161214.825651, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.20136643640200297, \"count\": 1, \"min\": 0.20136643640200297, \"max\": 0.20136643640200297}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8256884, \"EndTime\": 1695161214.8256984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18808132378260295, \"count\": 1, \"min\": 0.18808132378260295, \"max\": 0.18808132378260295}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8257349, \"EndTime\": 1695161214.825745, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12018980924288432, \"count\": 1, \"min\": 0.12018980924288432, \"max\": 0.12018980924288432}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.825792, \"EndTime\": 1695161214.8258035, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11862046253681183, \"count\": 1, \"min\": 0.11862046253681183, \"max\": 0.11862046253681183}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.825851, \"EndTime\": 1695161214.8258617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12109504787127177, \"count\": 1, \"min\": 0.12109504787127177, \"max\": 0.12109504787127177}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8258984, \"EndTime\": 1695161214.8259087, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11829486409823099, \"count\": 1, \"min\": 0.11829486409823099, \"max\": 0.11829486409823099}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.825949, \"EndTime\": 1695161214.8259597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14156461135546367, \"count\": 1, \"min\": 0.14156461135546367, \"max\": 0.14156461135546367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8259995, \"EndTime\": 1695161214.8260102, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1688975687424342, \"count\": 1, \"min\": 0.1688975687424342, \"max\": 0.1688975687424342}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8260472, \"EndTime\": 1695161214.8260577, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1717442638874054, \"count\": 1, \"min\": 0.1717442638874054, \"max\": 0.1717442638874054}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8261008, \"EndTime\": 1695161214.8261118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2199705820083618, \"count\": 1, \"min\": 0.2199705820083618, \"max\": 0.2199705820083618}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8261492, \"EndTime\": 1695161214.8261595, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25247602128982544, \"count\": 1, \"min\": 0.25247602128982544, \"max\": 0.25247602128982544}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8261957, \"EndTime\": 1695161214.826206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25748277457555135, \"count\": 1, \"min\": 0.25748277457555135, \"max\": 0.25748277457555135}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8262448, \"EndTime\": 1695161214.8262553, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2538212197621663, \"count\": 1, \"min\": 0.2538212197621663, \"max\": 0.2538212197621663}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.826295, \"EndTime\": 1695161214.8263054, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25641791947682696, \"count\": 1, \"min\": 0.25641791947682696, \"max\": 0.25641791947682696}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8263452, \"EndTime\": 1695161214.8263557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.40418879270553587, \"count\": 1, \"min\": 0.40418879270553587, \"max\": 0.40418879270553587}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8263938, \"EndTime\": 1695161214.8264046, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.35781994088490804, \"count\": 1, \"min\": 0.35781994088490804, \"max\": 0.35781994088490804}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8264449, \"EndTime\": 1695161214.8264554, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4041921928723653, \"count\": 1, \"min\": 0.4041921928723653, \"max\": 0.4041921928723653}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8264928, \"EndTime\": 1695161214.8265028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3706569395065308, \"count\": 1, \"min\": 0.3706569395065308, \"max\": 0.3706569395065308}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.826542, \"EndTime\": 1695161214.8265524, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8035025262832641, \"count\": 1, \"min\": 0.8035025262832641, \"max\": 0.8035025262832641}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.826596, \"EndTime\": 1695161214.826607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8034721218744914, \"count\": 1, \"min\": 0.8034721218744914, \"max\": 0.8034721218744914}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.826652, \"EndTime\": 1695161214.8266635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8035218693415324, \"count\": 1, \"min\": 0.8035218693415324, \"max\": 0.8035218693415324}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8267088, \"EndTime\": 1695161214.8267198, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8034975700378418, \"count\": 1, \"min\": 0.8034975700378418, \"max\": 0.8034975700378418}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8267639, \"EndTime\": 1695161214.826775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8487453880310059, \"count\": 1, \"min\": 0.8487453880310059, \"max\": 0.8487453880310059}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8268175, \"EndTime\": 1695161214.826828, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9365966129302978, \"count\": 1, \"min\": 0.9365966129302978, \"max\": 0.9365966129302978}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8268673, \"EndTime\": 1695161214.826878, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8485281686782837, \"count\": 1, \"min\": 0.8485281686782837, \"max\": 0.8485281686782837}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8269188, \"EndTime\": 1695161214.8269293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9270896104176839, \"count\": 1, \"min\": 0.9270896104176839, \"max\": 0.9270896104176839}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:54 INFO 140581587461952] #quality_metric: host=algo-1, epoch=6, train absolute_loss_objective <loss>=0.1189781494140625\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:54 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=absolute_loss_objective, value=0.11829486409823099\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:54 INFO 140581587461952] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:54 INFO 140581587461952] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:54 INFO 140581587461952] Saved checkpoint to \"/tmp/tmpzsxux0pc/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:54 INFO 140581587461952] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161213.1578476, \"EndTime\": 1695161214.8365386, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3005.0, \"count\": 1, \"min\": 3005, \"max\": 3005}, \"Total Batches Seen\": {\"sum\": 601.0, \"count\": 1, \"min\": 601, \"max\": 601}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:54 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=223.36833641242842 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:56.337] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 1500, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3379517, \"EndTime\": 1695161216.3380466, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12120327520370483, \"count\": 1, \"min\": 0.12120327520370483, \"max\": 0.12120327520370483}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3381646, \"EndTime\": 1695161216.3381886, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11847782508532206, \"count\": 1, \"min\": 0.11847782508532206, \"max\": 0.11847782508532206}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3382547, \"EndTime\": 1695161216.338274, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12291835236549377, \"count\": 1, \"min\": 0.12291835236549377, \"max\": 0.12291835236549377}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.338337, \"EndTime\": 1695161216.3383534, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11813109517097473, \"count\": 1, \"min\": 0.11813109517097473, \"max\": 0.11813109517097473}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3384097, \"EndTime\": 1695161216.3384275, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14255631573994954, \"count\": 1, \"min\": 0.14255631573994954, \"max\": 0.14255631573994954}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3384862, \"EndTime\": 1695161216.3385046, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18219809238115947, \"count\": 1, \"min\": 0.18219809238115947, \"max\": 0.18219809238115947}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3385592, \"EndTime\": 1695161216.3385763, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19004919695854186, \"count\": 1, \"min\": 0.19004919695854186, \"max\": 0.19004919695854186}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.338633, \"EndTime\": 1695161216.3386507, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17511793184280394, \"count\": 1, \"min\": 0.17511793184280394, \"max\": 0.17511793184280394}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3387036, \"EndTime\": 1695161216.3387206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12200115124384563, \"count\": 1, \"min\": 0.12200115124384563, \"max\": 0.12200115124384563}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.338778, \"EndTime\": 1695161216.338795, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11835064975420634, \"count\": 1, \"min\": 0.11835064975420634, \"max\": 0.11835064975420634}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3388526, \"EndTime\": 1695161216.3388703, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12226034259796142, \"count\": 1, \"min\": 0.12226034259796142, \"max\": 0.12226034259796142}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3389242, \"EndTime\": 1695161216.3389409, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1210269300142924, \"count\": 1, \"min\": 0.1210269300142924, \"max\": 0.1210269300142924}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3389952, \"EndTime\": 1695161216.3390117, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15327250889937083, \"count\": 1, \"min\": 0.15327250889937083, \"max\": 0.15327250889937083}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3390682, \"EndTime\": 1695161216.3390856, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18051121751467386, \"count\": 1, \"min\": 0.18051121751467386, \"max\": 0.18051121751467386}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3391383, \"EndTime\": 1695161216.3391552, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18239699856440225, \"count\": 1, \"min\": 0.18239699856440225, \"max\": 0.18239699856440225}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3392112, \"EndTime\": 1695161216.339228, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.20711334975560505, \"count\": 1, \"min\": 0.20711334975560505, \"max\": 0.20711334975560505}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3392837, \"EndTime\": 1695161216.3393016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25235703905423484, \"count\": 1, \"min\": 0.25235703905423484, \"max\": 0.25235703905423484}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3393543, \"EndTime\": 1695161216.3393705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2569690999984741, \"count\": 1, \"min\": 0.2569690999984741, \"max\": 0.2569690999984741}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3394256, \"EndTime\": 1695161216.3394423, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25333553314208984, \"count\": 1, \"min\": 0.25333553314208984, \"max\": 0.25333553314208984}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3395004, \"EndTime\": 1695161216.339518, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2575366398493449, \"count\": 1, \"min\": 0.2575366398493449, \"max\": 0.2575366398493449}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3395703, \"EndTime\": 1695161216.3395855, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.40891883420944214, \"count\": 1, \"min\": 0.40891883420944214, \"max\": 0.40891883420944214}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.33964, \"EndTime\": 1695161216.339657, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5247218170166016, \"count\": 1, \"min\": 0.5247218170166016, \"max\": 0.5247218170166016}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3397126, \"EndTime\": 1695161216.33973, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.40891830396652223, \"count\": 1, \"min\": 0.40891830396652223, \"max\": 0.40891830396652223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.339783, \"EndTime\": 1695161216.3397996, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3394817150433858, \"count\": 1, \"min\": 0.3394817150433858, \"max\": 0.3394817150433858}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3398592, \"EndTime\": 1695161216.3398764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8030804573694865, \"count\": 1, \"min\": 0.8030804573694865, \"max\": 0.8030804573694865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3399444, \"EndTime\": 1695161216.3399637, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.802489801088969, \"count\": 1, \"min\": 0.802489801088969, \"max\": 0.802489801088969}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.34003, \"EndTime\": 1695161216.340047, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8030994132359822, \"count\": 1, \"min\": 0.8030994132359822, \"max\": 0.8030994132359822}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3401153, \"EndTime\": 1695161216.340132, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8025059305826823, \"count\": 1, \"min\": 0.8025059305826823, \"max\": 0.8025059305826823}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3401887, \"EndTime\": 1695161216.340205, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8504336137771606, \"count\": 1, \"min\": 0.8504336137771606, \"max\": 0.8504336137771606}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3402662, \"EndTime\": 1695161216.340283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8914439878463745, \"count\": 1, \"min\": 0.8914439878463745, \"max\": 0.8914439878463745}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.340339, \"EndTime\": 1695161216.340353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8453217827479045, \"count\": 1, \"min\": 0.8453217827479045, \"max\": 0.8453217827479045}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3404086, \"EndTime\": 1695161216.3404233, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.924438157081604, \"count\": 1, \"min\": 0.924438157081604, \"max\": 0.924438157081604}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:56 INFO 140581587461952] #quality_metric: host=algo-1, epoch=7, train absolute_loss_objective <loss>=0.12120327520370483\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:56 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=absolute_loss_objective, value=0.11813109517097473\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:56 INFO 140581587461952] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:56 INFO 140581587461952] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:56 INFO 140581587461952] Saved checkpoint to \"/tmp/tmp8zf0a58f/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:56 INFO 140581587461952] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161214.8368714, \"EndTime\": 1695161216.3499873, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3380.0, \"count\": 1, \"min\": 3380, \"max\": 3380}, \"Total Batches Seen\": {\"sum\": 676.0, \"count\": 1, \"min\": 676, \"max\": 676}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:56 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=247.80856369994893 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:57.969] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 1619, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9700494, \"EndTime\": 1695161217.9701352, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12252208574612936, \"count\": 1, \"min\": 0.12252208574612936, \"max\": 0.12252208574612936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9702342, \"EndTime\": 1695161217.9702568, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12112013459205627, \"count\": 1, \"min\": 0.12112013459205627, \"max\": 0.12112013459205627}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9703293, \"EndTime\": 1695161217.9703498, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12286046560605367, \"count\": 1, \"min\": 0.12286046560605367, \"max\": 0.12286046560605367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9703994, \"EndTime\": 1695161217.9704165, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12072897934913636, \"count\": 1, \"min\": 0.12072897934913636, \"max\": 0.12072897934913636}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9704792, \"EndTime\": 1695161217.9704974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1440270343621572, \"count\": 1, \"min\": 0.1440270343621572, \"max\": 0.1440270343621572}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9705534, \"EndTime\": 1695161217.9705687, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16452362227439882, \"count\": 1, \"min\": 0.16452362227439882, \"max\": 0.16452362227439882}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9706159, \"EndTime\": 1695161217.9706316, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13888911040623983, \"count\": 1, \"min\": 0.13888911040623983, \"max\": 0.13888911040623983}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9706836, \"EndTime\": 1695161217.9707003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19716003282864888, \"count\": 1, \"min\": 0.19716003282864888, \"max\": 0.19716003282864888}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9707592, \"EndTime\": 1695161217.9707766, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12310426950454711, \"count\": 1, \"min\": 0.12310426950454711, \"max\": 0.12310426950454711}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.97084, \"EndTime\": 1695161217.970858, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11912857770919799, \"count\": 1, \"min\": 0.11912857770919799, \"max\": 0.11912857770919799}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9709153, \"EndTime\": 1695161217.9709337, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12264838250478109, \"count\": 1, \"min\": 0.12264838250478109, \"max\": 0.12264838250478109}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9709918, \"EndTime\": 1695161217.9710085, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12130970001220703, \"count\": 1, \"min\": 0.12130970001220703, \"max\": 0.12130970001220703}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9710634, \"EndTime\": 1695161217.9710805, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17603763310114542, \"count\": 1, \"min\": 0.17603763310114542, \"max\": 0.17603763310114542}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.97114, \"EndTime\": 1695161217.9711566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18454961276054382, \"count\": 1, \"min\": 0.18454961276054382, \"max\": 0.18454961276054382}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.97122, \"EndTime\": 1695161217.9712384, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14715102195739746, \"count\": 1, \"min\": 0.14715102195739746, \"max\": 0.14715102195739746}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9712856, \"EndTime\": 1695161217.9713027, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1619942620197932, \"count\": 1, \"min\": 0.1619942620197932, \"max\": 0.1619942620197932}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.971353, \"EndTime\": 1695161217.9713705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2510567368666331, \"count\": 1, \"min\": 0.2510567368666331, \"max\": 0.2510567368666331}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.971429, \"EndTime\": 1695161217.971447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25732310708363854, \"count\": 1, \"min\": 0.25732310708363854, \"max\": 0.25732310708363854}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9715033, \"EndTime\": 1695161217.9715188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25129204734166466, \"count\": 1, \"min\": 0.25129204734166466, \"max\": 0.25129204734166466}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.971571, \"EndTime\": 1695161217.9715886, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2562545959154765, \"count\": 1, \"min\": 0.2562545959154765, \"max\": 0.2562545959154765}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.971643, \"EndTime\": 1695161217.9716609, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.42586621475219727, \"count\": 1, \"min\": 0.42586621475219727, \"max\": 0.42586621475219727}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9717152, \"EndTime\": 1695161217.9717324, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34191083590189614, \"count\": 1, \"min\": 0.34191083590189614, \"max\": 0.34191083590189614}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9717798, \"EndTime\": 1695161217.9717968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.42586434904734294, \"count\": 1, \"min\": 0.42586434904734294, \"max\": 0.42586434904734294}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9718463, \"EndTime\": 1695161217.9718628, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.38155638790130614, \"count\": 1, \"min\": 0.38155638790130614, \"max\": 0.38155638790130614}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9719186, \"EndTime\": 1695161217.971936, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8026665153503418, \"count\": 1, \"min\": 0.8026665153503418, \"max\": 0.8026665153503418}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9719887, \"EndTime\": 1695161217.9720073, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8033536777496338, \"count\": 1, \"min\": 0.8033536777496338, \"max\": 0.8033536777496338}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9720643, \"EndTime\": 1695161217.9720817, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8026847270329793, \"count\": 1, \"min\": 0.8026847270329793, \"max\": 0.8026847270329793}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9721363, \"EndTime\": 1695161217.972154, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8033808259963989, \"count\": 1, \"min\": 0.8033808259963989, \"max\": 0.8033808259963989}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9722087, \"EndTime\": 1695161217.9722264, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8415052534739177, \"count\": 1, \"min\": 0.8415052534739177, \"max\": 0.8415052534739177}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9722757, \"EndTime\": 1695161217.9722915, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9344937184651693, \"count\": 1, \"min\": 0.9344937184651693, \"max\": 0.9344937184651693}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.972348, \"EndTime\": 1695161217.9723654, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8395030291875204, \"count\": 1, \"min\": 0.8395030291875204, \"max\": 0.8395030291875204}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9724207, \"EndTime\": 1695161217.9724386, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9237876688639323, \"count\": 1, \"min\": 0.9237876688639323, \"max\": 0.9237876688639323}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:57 INFO 140581587461952] #quality_metric: host=algo-1, epoch=8, train absolute_loss_objective <loss>=0.12252208574612936\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:57 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=absolute_loss_objective, value=0.11912857770919799\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:57 INFO 140581587461952] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:57 INFO 140581587461952] Saved checkpoint to \"/tmp/tmpnlfneizf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:57 INFO 140581587461952] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161216.3503218, \"EndTime\": 1695161217.9811168, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3755.0, \"count\": 1, \"min\": 3755, \"max\": 3755}, \"Total Batches Seen\": {\"sum\": 751.0, \"count\": 1, \"min\": 751, \"max\": 751}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:57 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=229.92640549368429 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:59.524] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 1542, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5245464, \"EndTime\": 1695161219.524642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12232707452774048, \"count\": 1, \"min\": 0.12232707452774048, \"max\": 0.12232707452774048}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5247808, \"EndTime\": 1695161219.5248046, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11909348789850871, \"count\": 1, \"min\": 0.11909348789850871, \"max\": 0.11909348789850871}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.524881, \"EndTime\": 1695161219.524902, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12245365802447002, \"count\": 1, \"min\": 0.12245365802447002, \"max\": 0.12245365802447002}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.524976, \"EndTime\": 1695161219.524994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1188380776643753, \"count\": 1, \"min\": 0.1188380776643753, \"max\": 0.1188380776643753}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5250587, \"EndTime\": 1695161219.5250773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14800734917322794, \"count\": 1, \"min\": 0.14800734917322794, \"max\": 0.14800734917322794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5251422, \"EndTime\": 1695161219.525159, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21516816258430482, \"count\": 1, \"min\": 0.21516816258430482, \"max\": 0.21516816258430482}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5252213, \"EndTime\": 1695161219.525237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.139001113653183, \"count\": 1, \"min\": 0.139001113653183, \"max\": 0.139001113653183}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5253258, \"EndTime\": 1695161219.5253446, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18064685448010762, \"count\": 1, \"min\": 0.18064685448010762, \"max\": 0.18064685448010762}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5254097, \"EndTime\": 1695161219.5254264, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12172923135757446, \"count\": 1, \"min\": 0.12172923135757446, \"max\": 0.12172923135757446}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5254931, \"EndTime\": 1695161219.5255094, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12072613143920899, \"count\": 1, \"min\": 0.12072613143920899, \"max\": 0.12072613143920899}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5255742, \"EndTime\": 1695161219.5255919, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12374271567662556, \"count\": 1, \"min\": 0.12374271567662556, \"max\": 0.12374271567662556}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5256557, \"EndTime\": 1695161219.5256736, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12107263557116191, \"count\": 1, \"min\": 0.12107263557116191, \"max\": 0.12107263557116191}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5257397, \"EndTime\": 1695161219.525757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13975021545092264, \"count\": 1, \"min\": 0.13975021545092264, \"max\": 0.13975021545092264}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.525817, \"EndTime\": 1695161219.525835, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21078532048066456, \"count\": 1, \"min\": 0.21078532048066456, \"max\": 0.21078532048066456}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5258994, \"EndTime\": 1695161219.5259175, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1374009461402893, \"count\": 1, \"min\": 0.1374009461402893, \"max\": 0.1374009461402893}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.525973, \"EndTime\": 1695161219.5259895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17139496501286824, \"count\": 1, \"min\": 0.17139496501286824, \"max\": 0.17139496501286824}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5260553, \"EndTime\": 1695161219.5260742, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.24997050253550213, \"count\": 1, \"min\": 0.24997050253550213, \"max\": 0.24997050253550213}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.526134, \"EndTime\": 1695161219.5261512, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2568448475201925, \"count\": 1, \"min\": 0.2568448475201925, \"max\": 0.2568448475201925}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5262077, \"EndTime\": 1695161219.5262244, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25112247943878174, \"count\": 1, \"min\": 0.25112247943878174, \"max\": 0.25112247943878174}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5262866, \"EndTime\": 1695161219.5263035, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25275812768936157, \"count\": 1, \"min\": 0.25275812768936157, \"max\": 0.25275812768936157}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.52637, \"EndTime\": 1695161219.5263867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3895375137329102, \"count\": 1, \"min\": 0.3895375137329102, \"max\": 0.3895375137329102}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5264428, \"EndTime\": 1695161219.526459, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34714252964655556, \"count\": 1, \"min\": 0.34714252964655556, \"max\": 0.34714252964655556}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5265105, \"EndTime\": 1695161219.5265255, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3895384901364644, \"count\": 1, \"min\": 0.3895384901364644, \"max\": 0.3895384901364644}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5265753, \"EndTime\": 1695161219.5265903, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3571388993263245, \"count\": 1, \"min\": 0.3571388993263245, \"max\": 0.3571388993263245}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5266428, \"EndTime\": 1695161219.5266602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8015574919382731, \"count\": 1, \"min\": 0.8015574919382731, \"max\": 0.8015574919382731}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.526716, \"EndTime\": 1695161219.5267322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.802390017191569, \"count\": 1, \"min\": 0.802390017191569, \"max\": 0.802390017191569}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5267873, \"EndTime\": 1695161219.526803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8015732930501303, \"count\": 1, \"min\": 0.8015732930501303, \"max\": 0.8015732930501303}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5268536, \"EndTime\": 1695161219.5268679, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8024076430002848, \"count\": 1, \"min\": 0.8024076430002848, \"max\": 0.8024076430002848}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.526918, \"EndTime\": 1695161219.5269358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.830755529721578, \"count\": 1, \"min\": 0.830755529721578, \"max\": 0.830755529721578}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5269995, \"EndTime\": 1695161219.527016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9343906288146973, \"count\": 1, \"min\": 0.9343906288146973, \"max\": 0.9343906288146973}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5270681, \"EndTime\": 1695161219.5270848, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8428715260823568, \"count\": 1, \"min\": 0.8428715260823568, \"max\": 0.8428715260823568}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161219.5271351, \"EndTime\": 1695161219.5271504, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.931470817565918, \"count\": 1, \"min\": 0.931470817565918, \"max\": 0.931470817565918}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #quality_metric: host=algo-1, epoch=9, train absolute_loss_objective <loss>=0.12232707452774048\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=absolute_loss_objective, value=0.1188380776643753\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] Saved checkpoint to \"/tmp/tmp8rkqj1r_/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161217.9814894, \"EndTime\": 1695161219.5374305, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4130.0, \"count\": 1, \"min\": 4130, \"max\": 4130}, \"Total Batches Seen\": {\"sum\": 826.0, \"count\": 1, \"min\": 826, \"max\": 826}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #throughput_metric: host=algo-1, train throughput=240.98794910102802 records/second\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 WARNING 140581587461952] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 WARNING 140581587461952] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:59.538] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 0, \"num_examples\": 1, \"num_bytes\": 240}\u001b[0m\n",
      "\u001b[34m[2023-09-19 22:06:59.659] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 117, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #train_score (algo-1) : ('absolute_loss_objective', 20.261555358886717)\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #train_score (algo-1) : ('mse', 675.0024386393229)\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #train_score (algo-1) : ('absolute_loss', 20.261555358886717)\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #train_score (algo-1) : ('rmse', 25.98080904512642)\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #train_score (algo-1) : ('r2', 0.9776588000656129)\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #train_score (algo-1) : ('mae', 20.261555348714193)\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #quality_metric: host=algo-1, train absolute_loss_objective <loss>=20.261555358886717\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #quality_metric: host=algo-1, train mse <loss>=675.0024386393229\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #quality_metric: host=algo-1, train absolute_loss <loss>=20.261555358886717\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #quality_metric: host=algo-1, train rmse <loss>=25.98080904512642\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #quality_metric: host=algo-1, train r2 <loss>=0.9776588000656129\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] #quality_metric: host=algo-1, train mae <loss>=20.261555348714193\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.0001, \"l1\": 0.0, \"lr_scheduler_step\": 100, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 0.0001}\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] Saved checkpoint to \"/tmp/tmp5_snyz0u/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/19/2023 22:06:59 INFO 140581587461952] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695161202.4660053, \"EndTime\": 1695161219.668106, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 703.4435272216797, \"count\": 1, \"min\": 703.4435272216797, \"max\": 703.4435272216797}, \"epochs\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"check_early_stopping.time\": {\"sum\": 9.622573852539062, \"count\": 10, \"min\": 0.21958351135253906, \"max\": 1.4874935150146484}, \"update.time\": {\"sum\": 16327.01563835144, \"count\": 10, \"min\": 1429.3925762176514, \"max\": 1971.400260925293}, \"finalize.time\": {\"sum\": 124.22299385070801, \"count\": 1, \"min\": 124.22299385070801, \"max\": 124.22299385070801}, \"setuptime\": {\"sum\": 2.6984214782714844, \"count\": 1, \"min\": 2.6984214782714844, \"max\": 2.6984214782714844}, \"totaltime\": {\"sum\": 17324.94354248047, \"count\": 1, \"min\": 17324.94354248047, \"max\": 17324.94354248047}}}\u001b[0m\n",
      "\n",
      "2023-09-19 22:07:19 Completed - Training job completed\n",
      "Training seconds: 158\n",
      "Billable seconds: 84\n",
      "Managed Spot Training savings: 46.8%\n"
     ]
    }
   ],
   "source": [
    "# A Spot offers a lower price compared to an on-Demand instance.\n",
    "# Amazon EC2 Spot Instances offer spare compute capacity available in the AWS Cloud at ~90% discounts compared to On-Demand prices. \n",
    "\n",
    "# train_use_spot_instances (bool): Specifies whether to use SageMaker Managed Spot instances for training.\n",
    "# max_run (int): Timeout in seconds for training (default: 24 * 60 * 60). After this amount of time Amazon SageMaker terminates the job regardless of its current status.\n",
    "# max_wait (int): Timeout in seconds waiting for spot training instances (default: None). After this amount of time Amazon SageMaker will stop waiting for Spot instances to become available (default:None).\n",
    "\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session,\n",
    "                                       use_spot_instances = True,\n",
    "                                       max_run = 300,\n",
    "                                       max_wait = 600)\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 1,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 5,\n",
    "                           epochs = 10,\n",
    "                           num_models = 64,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODING TASK #4: DEPLOY AND TEST TRAINED LINEAR LEARNER MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: linear-learner-2023-09-19-22-07-52-423\n",
      "INFO:sagemaker:Creating endpoint-config with name linear-learner-2023-09-19-22-07-52-423\n",
      "INFO:sagemaker:Creating endpoint with name linear-learner-2023-09-19-22-07-52-423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "# Deploying the model to perform inference \n",
    "# serializer: A serializer object is used to encode data for an inference endpoint.\n",
    "# deserializer: A deserializer object is used to decode data from an inference endpoint.\n",
    "\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "\n",
    "linear_regressor = linear.deploy(initial_instance_count = 1,\n",
    "                                 instance_type = 'ml.m4.xlarge',\n",
    "                                 serializer = CSVSerializer(),\n",
    "                                 deserializer = JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use code lines below if you're using AWS SDK 1.0\n",
    "# from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "# linear_regressor.content_type = 'text/csv' # This will need to be enabled for AWS SageMaker SDK 1.0\n",
    "# linear_regressor.serializer = csv_serializer\n",
    "# linear_regressor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction on the test data\n",
    "\n",
    "result = linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 631.7991943359375},\n",
       "  {'score': 248.02915954589844},\n",
       "  {'score': 683.3350830078125},\n",
       "  {'score': 629.2254638671875},\n",
       "  {'score': 515.620361328125},\n",
       "  {'score': 1014.116455078125},\n",
       "  {'score': 471.6635437011719},\n",
       "  {'score': 681.59033203125},\n",
       "  {'score': 496.830810546875},\n",
       "  {'score': 512.0721435546875},\n",
       "  {'score': 863.8345947265625},\n",
       "  {'score': 455.5698547363281},\n",
       "  {'score': 299.22650146484375},\n",
       "  {'score': 573.49951171875},\n",
       "  {'score': 714.262451171875},\n",
       "  {'score': 723.72607421875},\n",
       "  {'score': 674.654052734375},\n",
       "  {'score': 318.4076843261719},\n",
       "  {'score': 518.337158203125},\n",
       "  {'score': 670.547607421875},\n",
       "  {'score': 53.939022064208984},\n",
       "  {'score': 395.7478332519531},\n",
       "  {'score': 356.9566345214844},\n",
       "  {'score': 610.3228759765625},\n",
       "  {'score': 573.951171875},\n",
       "  {'score': 508.0779113769531},\n",
       "  {'score': 539.1158447265625},\n",
       "  {'score': 806.5792236328125},\n",
       "  {'score': 543.409912109375},\n",
       "  {'score': 640.611572265625},\n",
       "  {'score': 727.981201171875},\n",
       "  {'score': 576.564697265625},\n",
       "  {'score': 446.4117431640625},\n",
       "  {'score': 48.207366943359375},\n",
       "  {'score': 666.2423095703125},\n",
       "  {'score': 634.67138671875},\n",
       "  {'score': 173.18167114257812},\n",
       "  {'score': 579.7122802734375},\n",
       "  {'score': 185.44876098632812},\n",
       "  {'score': 630.280029296875},\n",
       "  {'score': 523.704833984375},\n",
       "  {'score': 285.98931884765625},\n",
       "  {'score': 422.876220703125},\n",
       "  {'score': 643.23828125},\n",
       "  {'score': 569.976318359375},\n",
       "  {'score': 307.59906005859375},\n",
       "  {'score': 477.0166015625},\n",
       "  {'score': 580.0626220703125},\n",
       "  {'score': 453.61358642578125},\n",
       "  {'score': 526.3302001953125},\n",
       "  {'score': 462.0172119140625},\n",
       "  {'score': 425.43206787109375},\n",
       "  {'score': 287.16693115234375},\n",
       "  {'score': 360.5439758300781},\n",
       "  {'score': 534.4488525390625},\n",
       "  {'score': 901.7303466796875},\n",
       "  {'score': 726.0606689453125},\n",
       "  {'score': 543.100830078125},\n",
       "  {'score': 779.3291015625},\n",
       "  {'score': 550.1612548828125},\n",
       "  {'score': 639.112548828125},\n",
       "  {'score': 445.4827575683594},\n",
       "  {'score': 550.7132568359375},\n",
       "  {'score': 241.21231079101562},\n",
       "  {'score': 152.65162658691406},\n",
       "  {'score': 699.2371826171875},\n",
       "  {'score': 903.7752685546875},\n",
       "  {'score': 664.2701416015625},\n",
       "  {'score': 513.5587158203125},\n",
       "  {'score': 525.7686767578125},\n",
       "  {'score': 426.7779541015625},\n",
       "  {'score': 478.5775146484375},\n",
       "  {'score': 687.1717529296875},\n",
       "  {'score': 583.744140625},\n",
       "  {'score': 676.0723876953125},\n",
       "  {'score': 550.7493896484375},\n",
       "  {'score': 607.9710693359375},\n",
       "  {'score': 742.2625732421875},\n",
       "  {'score': 624.7418212890625},\n",
       "  {'score': 515.1082763671875},\n",
       "  {'score': 296.545654296875},\n",
       "  {'score': 312.2571716308594},\n",
       "  {'score': 675.8712158203125},\n",
       "  {'score': 772.514892578125},\n",
       "  {'score': 473.52154541015625},\n",
       "  {'score': 589.7125244140625},\n",
       "  {'score': 655.05078125},\n",
       "  {'score': 514.2478637695312},\n",
       "  {'score': 193.634765625},\n",
       "  {'score': 580.93310546875},\n",
       "  {'score': 372.7140808105469},\n",
       "  {'score': 616.0771484375},\n",
       "  {'score': 424.2051696777344},\n",
       "  {'score': 896.91748046875},\n",
       "  {'score': 449.77813720703125},\n",
       "  {'score': 469.2981262207031},\n",
       "  {'score': 583.9744873046875},\n",
       "  {'score': 588.932373046875},\n",
       "  {'score': 677.2296142578125},\n",
       "  {'score': 524.4974365234375},\n",
       "  {'score': 680.6370849609375},\n",
       "  {'score': 562.84228515625},\n",
       "  {'score': 418.73394775390625},\n",
       "  {'score': 663.152099609375},\n",
       "  {'score': 497.5613098144531},\n",
       "  {'score': 295.1258544921875},\n",
       "  {'score': 809.3037109375},\n",
       "  {'score': 454.0713806152344},\n",
       "  {'score': 547.18994140625},\n",
       "  {'score': 626.5533447265625},\n",
       "  {'score': 294.09033203125},\n",
       "  {'score': 656.4158935546875},\n",
       "  {'score': 333.7257080078125},\n",
       "  {'score': 673.4537353515625},\n",
       "  {'score': 506.6497802734375},\n",
       "  {'score': 258.1827087402344},\n",
       "  {'score': 604.9010009765625},\n",
       "  {'score': 311.59930419921875},\n",
       "  {'score': 496.7908935546875},\n",
       "  {'score': 242.97409057617188},\n",
       "  {'score': 761.5992431640625},\n",
       "  {'score': 541.9691162109375},\n",
       "  {'score': 845.1268310546875},\n",
       "  {'score': 461.4372863769531},\n",
       "  {'score': 662.8203125}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result # results are in Json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the result is in json format, we access the scores by iterating through the scores in the predictions\n",
    "\n",
    "predictions = np.array([r['score'] for r in result['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 631.79919434,  248.02915955,  683.33508301,  629.22546387,\n",
       "        515.62036133, 1014.11645508,  471.6635437 ,  681.59033203,\n",
       "        496.83081055,  512.07214355,  863.83459473,  455.56985474,\n",
       "        299.22650146,  573.49951172,  714.26245117,  723.72607422,\n",
       "        674.65405273,  318.40768433,  518.3371582 ,  670.54760742,\n",
       "         53.93902206,  395.74783325,  356.95663452,  610.32287598,\n",
       "        573.95117188,  508.07791138,  539.11584473,  806.57922363,\n",
       "        543.40991211,  640.61157227,  727.98120117,  576.56469727,\n",
       "        446.41174316,   48.20736694,  666.24230957,  634.67138672,\n",
       "        173.18167114,  579.71228027,  185.44876099,  630.2800293 ,\n",
       "        523.70483398,  285.98931885,  422.8762207 ,  643.23828125,\n",
       "        569.97631836,  307.59906006,  477.01660156,  580.06262207,\n",
       "        453.61358643,  526.3302002 ,  462.01721191,  425.43206787,\n",
       "        287.16693115,  360.54397583,  534.44885254,  901.73034668,\n",
       "        726.06066895,  543.10083008,  779.32910156,  550.16125488,\n",
       "        639.11254883,  445.48275757,  550.71325684,  241.21231079,\n",
       "        152.65162659,  699.23718262,  903.77526855,  664.2701416 ,\n",
       "        513.55871582,  525.76867676,  426.7779541 ,  478.57751465,\n",
       "        687.17175293,  583.74414062,  676.0723877 ,  550.74938965,\n",
       "        607.97106934,  742.26257324,  624.74182129,  515.10827637,\n",
       "        296.5456543 ,  312.25717163,  675.87121582,  772.51489258,\n",
       "        473.52154541,  589.71252441,  655.05078125,  514.24786377,\n",
       "        193.63476562,  580.93310547,  372.71408081,  616.07714844,\n",
       "        424.20516968,  896.91748047,  449.77813721,  469.29812622,\n",
       "        583.9744873 ,  588.93237305,  677.22961426,  524.49743652,\n",
       "        680.63708496,  562.84228516,  418.73394775,  663.15209961,\n",
       "        497.56130981,  295.12585449,  809.30371094,  454.07138062,\n",
       "        547.18994141,  626.55334473,  294.09033203,  656.41589355,\n",
       "        333.72570801,  673.45373535,  506.64978027,  258.18270874,\n",
       "        604.90100098,  311.5993042 ,  496.79089355,  242.97409058,\n",
       "        761.59924316,  541.96911621,  845.12683105,  461.43728638,\n",
       "        662.8203125 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VISUALIZE TEST SET RESULTS\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.scatter(X_test, y_test, color = 'blue')\n",
    "plt.plot(X_test, predictions, color = 'red')\n",
    "plt.xlabel('Temperature [DegC]')\n",
    "plt.ylabel('Revenue [$]')\n",
    "plt.title('Temperature vs. Revenue (Testing Dataset)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #4 [OPTIONAL]:**\n",
    "- **Use the trained AWS SageMaker Linear Learner model, obtain the revenue when the outside air temperature is 35 degC and 10 degC?**\n",
    "- **Compare the results to the ones optained using SkLearn!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'score': 262.85382080078125}]}\n",
      "{'predictions': [{'score': 799.469970703125}]}\n"
     ]
    }
   ],
   "source": [
    "temperature = [[10]]\n",
    "revenue = linear_regressor.predict(temperature)\n",
    "print(revenue)\n",
    "\n",
    "temperature = [[35]] \n",
    "revenue = linear_regressor.predict(temperature)\n",
    "print(revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 799.469970703125}, {'score': 262.85382080078125}]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making prediction on the new data\n",
    "\n",
    "result = linear_regressor.predict([[35],[10]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: linear-learner-2023-09-19-22-07-52-423\n",
      "INFO:sagemaker:Deleting endpoint with name: linear-learner-2023-09-19-22-07-52-423\n"
     ]
    }
   ],
   "source": [
    "# Delete the end-point\n",
    "linear_regressor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GREAT JOB! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICE OPPORTUNITY SOLUTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #1 SOLUTION:**\n",
    "- **What do you expect the relationship between outside air temperature and ice cream sales to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and bike sharing rental usage to look like?**\n",
    "- **What do you expect the relationship between outside air temperature and ski rental usage to look like?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A positive correlation is expected for case 1 & 2 since as temperature increases, we expect ice cream sales and bike sharing rental usage to increase as well. \n",
    "- A positive correlation implies a positive relationship between X and Y: as X increases, Y increases.\n",
    "- A Negative correlation expected for case 3 (ski rental usage) since as temperature decreases, ski rental usage tend to increase (to a point when it's too cold and demand should stabilize or even drop)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #2 SOLUTION:**\n",
    " - **Split the data into 75% for training and the rest for testing**\n",
    " - **Verify that the split was successful**\n",
    " - **Did you notice any change in the order of the data? why?**\n",
    " - **Add an attribute to disable data shuffling [external research is required]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing using SkLearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.566885 ],\n",
       "       [26.005192 ],\n",
       "       [27.790554 ],\n",
       "       [20.595335 ],\n",
       "       [11.503498 ],\n",
       "       [14.352514 ],\n",
       "       [13.70778  ],\n",
       "       [30.833984 ],\n",
       "       [ 0.97687  ],\n",
       "       [31.669464 ],\n",
       "       [11.455254 ],\n",
       "       [ 3.6646695],\n",
       "       [18.811825 ],\n",
       "       [13.624509 ],\n",
       "       [39.53991  ],\n",
       "       [18.48314  ],\n",
       "       [25.935375 ],\n",
       "       [42.51528  ],\n",
       "       [29.589481 ],\n",
       "       [21.775948 ],\n",
       "       [25.457836 ],\n",
       "       [15.214569 ],\n",
       "       [22.619316 ],\n",
       "       [16.25872  ],\n",
       "       [23.881725 ],\n",
       "       [18.9783   ],\n",
       "       [15.661465 ],\n",
       "       [29.185045 ],\n",
       "       [19.02461  ],\n",
       "       [35.12015  ],\n",
       "       [24.183937 ],\n",
       "       [15.23119  ],\n",
       "       [ 8.790953 ],\n",
       "       [18.233229 ],\n",
       "       [35.628925 ],\n",
       "       [37.05754  ],\n",
       "       [22.28455  ],\n",
       "       [17.517075 ],\n",
       "       [31.737919 ],\n",
       "       [17.049738 ],\n",
       "       [23.003489 ],\n",
       "       [ 8.755554 ],\n",
       "       [18.775358 ],\n",
       "       [14.109661 ],\n",
       "       [18.633913 ],\n",
       "       [15.676487 ],\n",
       "       [20.947914 ],\n",
       "       [30.635307 ],\n",
       "       [20.473595 ],\n",
       "       [31.228989 ],\n",
       "       [ 6.3938346],\n",
       "       [27.18581  ],\n",
       "       [28.633732 ],\n",
       "       [27.999222 ],\n",
       "       [10.326389 ],\n",
       "       [27.31281  ],\n",
       "       [33.235672 ],\n",
       "       [36.569115 ],\n",
       "       [12.462937 ],\n",
       "       [14.379697 ],\n",
       "       [16.302555 ],\n",
       "       [11.569644 ],\n",
       "       [33.55142  ],\n",
       "       [ 3.9865232],\n",
       "       [20.511637 ],\n",
       "       [ 6.5425143],\n",
       "       [19.81754  ],\n",
       "       [11.694538 ],\n",
       "       [21.488176 ],\n",
       "       [18.773533 ],\n",
       "       [12.68843  ],\n",
       "       [27.887112 ],\n",
       "       [26.95672  ],\n",
       "       [27.3754   ],\n",
       "       [24.101616 ],\n",
       "       [28.790102 ],\n",
       "       [40.473988 ],\n",
       "       [25.545965 ],\n",
       "       [28.701277 ],\n",
       "       [29.463785 ],\n",
       "       [16.020975 ],\n",
       "       [14.739551 ],\n",
       "       [22.1712   ],\n",
       "       [29.035738 ],\n",
       "       [29.209715 ],\n",
       "       [16.364944 ],\n",
       "       [27.7805   ],\n",
       "       [13.3306055],\n",
       "       [29.305038 ],\n",
       "       [14.384084 ],\n",
       "       [30.427792 ],\n",
       "       [ 9.073838 ],\n",
       "       [23.070616 ],\n",
       "       [ 8.586948 ],\n",
       "       [12.352081 ],\n",
       "       [ 9.01886  ],\n",
       "       [20.265013 ],\n",
       "       [19.363153 ],\n",
       "       [14.685945 ],\n",
       "       [ 9.954357 ],\n",
       "       [19.977467 ],\n",
       "       [32.00417  ],\n",
       "       [14.287196 ],\n",
       "       [17.658503 ],\n",
       "       [26.595055 ],\n",
       "       [17.26218  ],\n",
       "       [23.761436 ],\n",
       "       [15.588061 ],\n",
       "       [28.436567 ],\n",
       "       [27.7274   ],\n",
       "       [25.419302 ],\n",
       "       [18.475035 ],\n",
       "       [24.243113 ],\n",
       "       [31.668486 ],\n",
       "       [17.690031 ],\n",
       "       [31.891468 ],\n",
       "       [25.92517  ],\n",
       "       [29.312012 ],\n",
       "       [11.059096 ],\n",
       "       [25.496624 ],\n",
       "       [22.940317 ],\n",
       "       [12.901773 ],\n",
       "       [28.26283  ],\n",
       "       [30.562662 ],\n",
       "       [12.571514 ],\n",
       "       [19.059286 ],\n",
       "       [15.992347 ],\n",
       "       [26.18797  ],\n",
       "       [31.412628 ],\n",
       "       [32.297333 ],\n",
       "       [21.696783 ],\n",
       "       [20.475023 ],\n",
       "       [19.433268 ],\n",
       "       [20.12955  ],\n",
       "       [ 6.0938973],\n",
       "       [22.84197  ],\n",
       "       [24.585909 ],\n",
       "       [28.547987 ],\n",
       "       [19.77937  ],\n",
       "       [12.450833 ],\n",
       "       [36.70257  ],\n",
       "       [19.62266  ],\n",
       "       [32.40924  ],\n",
       "       [19.267786 ],\n",
       "       [19.728077 ],\n",
       "       [ 8.638076 ],\n",
       "       [29.430578 ],\n",
       "       [19.251654 ],\n",
       "       [24.615238 ],\n",
       "       [12.442651 ],\n",
       "       [24.548557 ],\n",
       "       [12.209683 ],\n",
       "       [12.265884 ],\n",
       "       [19.754707 ],\n",
       "       [23.349033 ],\n",
       "       [21.144047 ],\n",
       "       [18.880356 ],\n",
       "       [28.271765 ],\n",
       "       [16.406021 ],\n",
       "       [28.993736 ],\n",
       "       [10.245058 ],\n",
       "       [11.077843 ],\n",
       "       [25.499683 ],\n",
       "       [27.931349 ],\n",
       "       [28.459543 ],\n",
       "       [13.301796 ],\n",
       "       [25.995993 ],\n",
       "       [32.80503  ],\n",
       "       [32.71638  ],\n",
       "       [32.10708  ],\n",
       "       [24.778675 ],\n",
       "       [15.029112 ],\n",
       "       [23.424646 ],\n",
       "       [35.21724  ],\n",
       "       [16.379574 ],\n",
       "       [20.556679 ],\n",
       "       [21.322392 ],\n",
       "       [26.943638 ],\n",
       "       [22.634735 ],\n",
       "       [33.2509   ],\n",
       "       [ 8.99176  ],\n",
       "       [26.874952 ],\n",
       "       [21.358025 ],\n",
       "       [22.009874 ],\n",
       "       [29.129128 ],\n",
       "       [16.191298 ],\n",
       "       [35.35976  ],\n",
       "       [11.187757 ],\n",
       "       [16.555843 ],\n",
       "       [30.330332 ],\n",
       "       [12.900666 ],\n",
       "       [19.814638 ],\n",
       "       [20.934608 ],\n",
       "       [23.591028 ],\n",
       "       [16.557947 ],\n",
       "       [30.666595 ],\n",
       "       [ 9.8125105],\n",
       "       [31.579988 ],\n",
       "       [25.422165 ],\n",
       "       [25.241148 ],\n",
       "       [26.873587 ],\n",
       "       [21.424559 ],\n",
       "       [23.963879 ],\n",
       "       [10.447126 ],\n",
       "       [ 5.8223324],\n",
       "       [16.145824 ],\n",
       "       [23.959312 ],\n",
       "       [ 9.782381 ],\n",
       "       [23.975931 ],\n",
       "       [10.096644 ],\n",
       "       [22.387604 ],\n",
       "       [27.322323 ],\n",
       "       [20.247345 ],\n",
       "       [23.153002 ],\n",
       "       [15.753951 ],\n",
       "       [27.57296  ],\n",
       "       [18.776829 ],\n",
       "       [22.653135 ],\n",
       "       [17.993021 ],\n",
       "       [13.1124525],\n",
       "       [24.802576 ],\n",
       "       [18.60275  ],\n",
       "       [25.865944 ],\n",
       "       [26.250746 ],\n",
       "       [13.364313 ],\n",
       "       [21.540459 ],\n",
       "       [27.128128 ],\n",
       "       [26.944122 ],\n",
       "       [38.14633  ],\n",
       "       [ 4.236465 ],\n",
       "       [ 9.40348  ],\n",
       "       [20.153345 ],\n",
       "       [19.72133  ],\n",
       "       [19.194952 ],\n",
       "       [19.172045 ],\n",
       "       [36.11656  ],\n",
       "       [23.410862 ],\n",
       "       [29.91931  ],\n",
       "       [32.004364 ],\n",
       "       [29.768223 ],\n",
       "       [11.132706 ],\n",
       "       [23.385145 ],\n",
       "       [27.70506  ],\n",
       "       [15.047923 ],\n",
       "       [ 6.3524594],\n",
       "       [14.26354  ],\n",
       "       [25.422947 ],\n",
       "       [24.727154 ],\n",
       "       [16.300125 ],\n",
       "       [18.148952 ],\n",
       "       [18.57812  ],\n",
       "       [32.33481  ],\n",
       "       [ 7.561125 ],\n",
       "       [31.471224 ],\n",
       "       [28.335363 ],\n",
       "       [17.636936 ],\n",
       "       [21.703953 ],\n",
       "       [18.462906 ],\n",
       "       [32.479794 ],\n",
       "       [17.360731 ],\n",
       "       [21.007046 ],\n",
       "       [23.577114 ],\n",
       "       [30.76274  ],\n",
       "       [22.67856  ],\n",
       "       [28.855192 ],\n",
       "       [ 9.651495 ],\n",
       "       [18.506231 ],\n",
       "       [ 5.338413 ],\n",
       "       [35.458138 ],\n",
       "       [24.778198 ],\n",
       "       [24.62861  ],\n",
       "       [28.491764 ],\n",
       "       [24.949715 ],\n",
       "       [25.44824  ],\n",
       "       [22.24874  ],\n",
       "       [24.761877 ],\n",
       "       [22.448034 ],\n",
       "       [35.033455 ],\n",
       "       [33.74421  ],\n",
       "       [22.526749 ],\n",
       "       [28.464933 ],\n",
       "       [23.497532 ],\n",
       "       [26.078405 ],\n",
       "       [28.86559  ],\n",
       "       [22.146317 ],\n",
       "       [26.337053 ],\n",
       "       [25.00238  ],\n",
       "       [26.45605  ],\n",
       "       [22.189516 ],\n",
       "       [15.521162 ],\n",
       "       [17.65684  ],\n",
       "       [28.729916 ],\n",
       "       [27.529232 ],\n",
       "       [27.188517 ],\n",
       "       [10.403422 ],\n",
       "       [17.588371 ],\n",
       "       [24.521847 ],\n",
       "       [37.998634 ],\n",
       "       [16.954779 ],\n",
       "       [ 7.745286 ],\n",
       "       [ 5.858454 ],\n",
       "       [26.859722 ],\n",
       "       [24.493477 ],\n",
       "       [21.90252  ],\n",
       "       [30.028208 ],\n",
       "       [21.281916 ],\n",
       "       [32.46497  ],\n",
       "       [17.090645 ],\n",
       "       [33.315    ],\n",
       "       [23.412548 ],\n",
       "       [18.977991 ],\n",
       "       [12.270967 ],\n",
       "       [25.191425 ],\n",
       "       [27.068607 ],\n",
       "       [25.72547  ],\n",
       "       [22.311079 ],\n",
       "       [25.11607  ],\n",
       "       [22.152588 ],\n",
       "       [28.298689 ],\n",
       "       [21.712006 ],\n",
       "       [15.1181965],\n",
       "       [25.37411  ],\n",
       "       [18.439981 ],\n",
       "       [22.870562 ],\n",
       "       [14.361424 ],\n",
       "       [ 7.2613482],\n",
       "       [25.227774 ],\n",
       "       [20.971153 ],\n",
       "       [19.775148 ],\n",
       "       [41.924446 ],\n",
       "       [28.649193 ],\n",
       "       [29.241753 ],\n",
       "       [15.843022 ],\n",
       "       [20.898716 ],\n",
       "       [30.45674  ],\n",
       "       [24.818754 ],\n",
       "       [19.849241 ],\n",
       "       [22.118706 ],\n",
       "       [34.061672 ],\n",
       "       [ 9.557276 ],\n",
       "       [25.5512   ],\n",
       "       [19.066591 ],\n",
       "       [23.087664 ],\n",
       "       [ 8.033153 ],\n",
       "       [29.707024 ],\n",
       "       [12.189418 ],\n",
       "       [35.094795 ],\n",
       "       [24.960445 ],\n",
       "       [38.1852   ],\n",
       "       [18.985275 ],\n",
       "       [18.708475 ],\n",
       "       [ 7.223377 ],\n",
       "       [12.704718 ],\n",
       "       [24.528852 ],\n",
       "       [39.76413  ],\n",
       "       [30.247248 ],\n",
       "       [24.472433 ],\n",
       "       [20.24415  ],\n",
       "       [20.226421 ],\n",
       "       [14.896973 ],\n",
       "       [28.787436 ],\n",
       "       [29.704184 ],\n",
       "       [26.369747 ],\n",
       "       [ 6.775206 ],\n",
       "       [23.246717 ],\n",
       "       [24.308296 ],\n",
       "       [25.717962 ],\n",
       "       [21.684425 ],\n",
       "       [26.191668 ],\n",
       "       [21.601892 ],\n",
       "       [18.883718 ],\n",
       "       [ 0.2670277],\n",
       "       [19.617876 ],\n",
       "       [20.1039   ],\n",
       "       [23.98464  ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #3 SOLUTION:**\n",
    "- **Try to train the model with more epochs and additional number of models**\n",
    "- **Can you try to reduce the cost of the billable seconds?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: linear-learner-2023-09-18-23-39-11-177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 23:39:11 Starting - Starting the training job...\n",
      "2023-09-18 23:39:36 Starting - Preparing the instances for training.........\n",
      "2023-09-18 23:40:43 Downloading - Downloading input data...\n",
      "2023-09-18 23:41:13 Training - Downloading the training image......\n",
      "2023-09-18 23:42:24 Training - Training image download completed. Training in progress...\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:46 INFO 140167794624320] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:46 INFO 140167794624320] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '10', 'feature_dim': '1', 'loss': 'absolute_loss', 'mini_batch_size': '5', 'num_models': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:46 INFO 140167794624320] Final configuration: {'mini_batch_size': '5', 'epochs': '10', 'feature_dim': '1', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '64', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:49 WARNING 140167794624320] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:49 INFO 140167794624320] Final configuration: {'mini_batch_size': '5', 'epochs': '10', 'feature_dim': '1', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': '64', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:49 WARNING 140167794624320] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:49 INFO 140167794624320] Using default worker.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:49 INFO 140167794624320] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:42:49.546] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 16, \"num_examples\": 1, \"num_bytes\": 240}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:49 INFO 140167794624320] Create Store: local\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:42:50.080] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 533, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 INFO 140167794624320] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f7acac0b490>\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 INFO 140167794624320] Scaling model computed with parameters:\n",
      " {'stdev_label': \u001b[0m\n",
      "\u001b[34m[173.61322]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[8.042963]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[34m[517.3835]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[22.066607]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 INFO 140167794624320] nvidia-smi: took 0.038 seconds to run.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 INFO 140167794624320] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 INFO 140167794624320] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:50 WARNING 140167794624320] Setting num_models to 32.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080570.2065167, \"EndTime\": 1695080570.2065516, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 380.0, \"count\": 1, \"min\": 380, \"max\": 380}, \"Total Batches Seen\": {\"sum\": 76.0, \"count\": 1, \"min\": 76, \"max\": 76}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:42:51.859] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 1652, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.859136, \"EndTime\": 1695080571.859243, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6509688940048218, \"count\": 1, \"min\": 0.6509688940048218, \"max\": 0.6509688940048218}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.859361, \"EndTime\": 1695080571.8593845, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6664303735097249, \"count\": 1, \"min\": 0.6664303735097249, \"max\": 0.6664303735097249}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.85944, \"EndTime\": 1695080571.8594577, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6531246490478516, \"count\": 1, \"min\": 0.6531246490478516, \"max\": 0.6531246490478516}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.859521, \"EndTime\": 1695080571.8595366, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6655194946924845, \"count\": 1, \"min\": 0.6655194946924845, \"max\": 0.6655194946924845}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8595889, \"EndTime\": 1695080571.8596056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25106031612555185, \"count\": 1, \"min\": 0.25106031612555185, \"max\": 0.25106031612555185}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8596585, \"EndTime\": 1695080571.859676, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2693931328058243, \"count\": 1, \"min\": 0.2693931328058243, \"max\": 0.2693931328058243}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8597307, \"EndTime\": 1695080571.8597462, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.26621400022506714, \"count\": 1, \"min\": 0.26621400022506714, \"max\": 0.26621400022506714}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8597994, \"EndTime\": 1695080571.8598177, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.24130224891503652, \"count\": 1, \"min\": 0.24130224891503652, \"max\": 0.24130224891503652}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.859885, \"EndTime\": 1695080571.859901, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7007217871348063, \"count\": 1, \"min\": 0.7007217871348063, \"max\": 0.7007217871348063}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.859968, \"EndTime\": 1695080571.8599854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.637849197546641, \"count\": 1, \"min\": 0.637849197546641, \"max\": 0.637849197546641}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.860042, \"EndTime\": 1695080571.8600607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6464179533322653, \"count\": 1, \"min\": 0.6464179533322653, \"max\": 0.6464179533322653}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.860118, \"EndTime\": 1695080571.860135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6307664103507996, \"count\": 1, \"min\": 0.6307664103507996, \"max\": 0.6307664103507996}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8601863, \"EndTime\": 1695080571.8602047, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.23246408303578694, \"count\": 1, \"min\": 0.23246408303578694, \"max\": 0.23246408303578694}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8602738, \"EndTime\": 1695080571.8602936, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.23742980058987936, \"count\": 1, \"min\": 0.23742980058987936, \"max\": 0.23742980058987936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.860363, \"EndTime\": 1695080571.8603797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.23445403333504994, \"count\": 1, \"min\": 0.23445403333504994, \"max\": 0.23445403333504994}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8604352, \"EndTime\": 1695080571.8604553, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2564009329477946, \"count\": 1, \"min\": 0.2564009329477946, \"max\": 0.2564009329477946}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8605206, \"EndTime\": 1695080571.8605378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6258865777651469, \"count\": 1, \"min\": 0.6258865777651469, \"max\": 0.6258865777651469}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8605983, \"EndTime\": 1695080571.8606164, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6678950668970743, \"count\": 1, \"min\": 0.6678950668970743, \"max\": 0.6678950668970743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8606699, \"EndTime\": 1695080571.860686, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6493023131688436, \"count\": 1, \"min\": 0.6493023131688436, \"max\": 0.6493023131688436}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8607557, \"EndTime\": 1695080571.860773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6445168108940125, \"count\": 1, \"min\": 0.6445168108940125, \"max\": 0.6445168108940125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8608415, \"EndTime\": 1695080571.8608592, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4689012455940247, \"count\": 1, \"min\": 0.4689012455940247, \"max\": 0.4689012455940247}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8609252, \"EndTime\": 1695080571.8609421, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.462826048374176, \"count\": 1, \"min\": 0.462826048374176, \"max\": 0.462826048374176}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8610022, \"EndTime\": 1695080571.861019, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41244243176778156, \"count\": 1, \"min\": 0.41244243176778156, \"max\": 0.41244243176778156}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8610885, \"EndTime\": 1695080571.8611045, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4634470130602519, \"count\": 1, \"min\": 0.4634470130602519, \"max\": 0.4634470130602519}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8611724, \"EndTime\": 1695080571.8611867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7852068332036336, \"count\": 1, \"min\": 0.7852068332036336, \"max\": 0.7852068332036336}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8612528, \"EndTime\": 1695080571.8612716, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7877886209487915, \"count\": 1, \"min\": 0.7877886209487915, \"max\": 0.7877886209487915}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8614032, \"EndTime\": 1695080571.8614259, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7871928068796794, \"count\": 1, \"min\": 0.7871928068796794, \"max\": 0.7871928068796794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8615012, \"EndTime\": 1695080571.8615165, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7873610277175903, \"count\": 1, \"min\": 0.7873610277175903, \"max\": 0.7873610277175903}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8616285, \"EndTime\": 1695080571.8616438, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9512971089680989, \"count\": 1, \"min\": 0.9512971089680989, \"max\": 0.9512971089680989}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.861763, \"EndTime\": 1695080571.8617861, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9600206731160482, \"count\": 1, \"min\": 0.9600206731160482, \"max\": 0.9600206731160482}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.861905, \"EndTime\": 1695080571.8619268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9506316795349121, \"count\": 1, \"min\": 0.9506316795349121, \"max\": 0.9506316795349121}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8620257, \"EndTime\": 1695080571.8620434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9595907497406005, \"count\": 1, \"min\": 0.9595907497406005, \"max\": 0.9595907497406005}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:51 INFO 140167794624320] #quality_metric: host=algo-1, epoch=0, train absolute_loss_objective <loss>=0.6509688940048218\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:51 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=absolute_loss_objective, value=0.23246408303578694\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:51 INFO 140167794624320] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:51 INFO 140167794624320] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:51 INFO 140167794624320] Saved checkpoint to \"/tmp/tmpag3l_6g9/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:51 INFO 140167794624320] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080570.2068694, \"EndTime\": 1695080571.8732464, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 755.0, \"count\": 1, \"min\": 755, \"max\": 755}, \"Total Batches Seen\": {\"sum\": 151.0, \"count\": 1, \"min\": 151, \"max\": 151}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:51 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=225.01630901287552 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:42:53.611] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 1737, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.611243, \"EndTime\": 1695080573.6113043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3970876194636027, \"count\": 1, \"min\": 0.3970876194636027, \"max\": 0.3970876194636027}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.611402, \"EndTime\": 1695080573.611417, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3957712027231852, \"count\": 1, \"min\": 0.3957712027231852, \"max\": 0.3957712027231852}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6114557, \"EndTime\": 1695080573.61147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.39917953952153523, \"count\": 1, \"min\": 0.39917953952153523, \"max\": 0.39917953952153523}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.611516, \"EndTime\": 1695080573.6115308, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.39489129606882734, \"count\": 1, \"min\": 0.39489129606882734, \"max\": 0.39489129606882734}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.611582, \"EndTime\": 1695080573.611596, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16914183966318766, \"count\": 1, \"min\": 0.16914183966318766, \"max\": 0.16914183966318766}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6116338, \"EndTime\": 1695080573.611648, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1820784805615743, \"count\": 1, \"min\": 0.1820784805615743, \"max\": 0.1820784805615743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6117003, \"EndTime\": 1695080573.6117158, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2672479901313782, \"count\": 1, \"min\": 0.2672479901313782, \"max\": 0.2672479901313782}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6117682, \"EndTime\": 1695080573.611779, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16672926394144694, \"count\": 1, \"min\": 0.16672926394144694, \"max\": 0.16672926394144694}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6118097, \"EndTime\": 1695080573.6118178, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.44718842538197834, \"count\": 1, \"min\": 0.44718842538197834, \"max\": 0.44718842538197834}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6118574, \"EndTime\": 1695080573.6118727, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3695877256393433, \"count\": 1, \"min\": 0.3695877256393433, \"max\": 0.3695877256393433}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6119223, \"EndTime\": 1695080573.6119387, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.393174157778422, \"count\": 1, \"min\": 0.393174157778422, \"max\": 0.393174157778422}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6119866, \"EndTime\": 1695080573.6119964, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3632568101882935, \"count\": 1, \"min\": 0.3632568101882935, \"max\": 0.3632568101882935}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6120267, \"EndTime\": 1695080573.6120346, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19688665970166525, \"count\": 1, \"min\": 0.19688665970166525, \"max\": 0.19688665970166525}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6120594, \"EndTime\": 1695080573.6120722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2156444327433904, \"count\": 1, \"min\": 0.2156444327433904, \"max\": 0.2156444327433904}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6121216, \"EndTime\": 1695080573.6121373, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1923308809598287, \"count\": 1, \"min\": 0.1923308809598287, \"max\": 0.1923308809598287}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.61219, \"EndTime\": 1695080573.6122055, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.20277187577883402, \"count\": 1, \"min\": 0.20277187577883402, \"max\": 0.20277187577883402}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6122406, \"EndTime\": 1695080573.6122494, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.43347583421071373, \"count\": 1, \"min\": 0.43347583421071373, \"max\": 0.43347583421071373}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.612277, \"EndTime\": 1695080573.6122844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.45770654241243997, \"count\": 1, \"min\": 0.45770654241243997, \"max\": 0.45770654241243997}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6123202, \"EndTime\": 1695080573.612335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.45247578144073486, \"count\": 1, \"min\": 0.45247578144073486, \"max\": 0.45247578144073486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6123846, \"EndTime\": 1695080573.6124005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.43927435064315795, \"count\": 1, \"min\": 0.43927435064315795, \"max\": 0.43927435064315795}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6124496, \"EndTime\": 1695080573.6124659, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34984410190582277, \"count\": 1, \"min\": 0.34984410190582277, \"max\": 0.34984410190582277}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6125152, \"EndTime\": 1695080573.6125252, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4196762296358744, \"count\": 1, \"min\": 0.4196762296358744, \"max\": 0.4196762296358744}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6125515, \"EndTime\": 1695080573.6125607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3252551201979319, \"count\": 1, \"min\": 0.3252551201979319, \"max\": 0.3252551201979319}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.612608, \"EndTime\": 1695080573.6126242, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41438416425387065, \"count\": 1, \"min\": 0.41438416425387065, \"max\": 0.41438416425387065}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6126752, \"EndTime\": 1695080573.6126914, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.784637414296468, \"count\": 1, \"min\": 0.784637414296468, \"max\": 0.784637414296468}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6127279, \"EndTime\": 1695080573.6127362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7852761233647665, \"count\": 1, \"min\": 0.7852761233647665, \"max\": 0.7852761233647665}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6127608, \"EndTime\": 1695080573.6127684, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7848742885589599, \"count\": 1, \"min\": 0.7848742885589599, \"max\": 0.7848742885589599}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6128144, \"EndTime\": 1695080573.6128302, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.785239278793335, \"count\": 1, \"min\": 0.785239278793335, \"max\": 0.785239278793335}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6128817, \"EndTime\": 1695080573.6128979, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.883848224957784, \"count\": 1, \"min\": 0.883848224957784, \"max\": 0.883848224957784}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6129398, \"EndTime\": 1695080573.612955, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.901439821879069, \"count\": 1, \"min\": 0.901439821879069, \"max\": 0.901439821879069}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6130009, \"EndTime\": 1695080573.6130161, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8841809088389079, \"count\": 1, \"min\": 0.8841809088389079, \"max\": 0.8841809088389079}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.6130672, \"EndTime\": 1695080573.613083, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9018732083638509, \"count\": 1, \"min\": 0.9018732083638509, \"max\": 0.9018732083638509}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:53 INFO 140167794624320] #quality_metric: host=algo-1, epoch=1, train absolute_loss_objective <loss>=0.3970876194636027\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:53 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=absolute_loss_objective, value=0.16672926394144694\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:53 INFO 140167794624320] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:53 INFO 140167794624320] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:53 INFO 140167794624320] Saved checkpoint to \"/tmp/tmppy_5exij/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:53 INFO 140167794624320] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080571.8735957, \"EndTime\": 1695080573.6273367, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1130.0, \"count\": 1, \"min\": 1130, \"max\": 1130}, \"Total Batches Seen\": {\"sum\": 226.0, \"count\": 1, \"min\": 226, \"max\": 226}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:53 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=213.79849469039289 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:42:55.756] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 2128, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7563162, \"EndTime\": 1695080575.7564135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1960919187068939, \"count\": 1, \"min\": 0.1960919187068939, \"max\": 0.1960919187068939}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7565258, \"EndTime\": 1695080575.756549, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17639704251289368, \"count\": 1, \"min\": 0.17639704251289368, \"max\": 0.17639704251289368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7566059, \"EndTime\": 1695080575.7566214, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19647007211049397, \"count\": 1, \"min\": 0.19647007211049397, \"max\": 0.19647007211049397}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.756674, \"EndTime\": 1695080575.7566912, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17474212622642518, \"count\": 1, \"min\": 0.17474212622642518, \"max\": 0.17474212622642518}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7567472, \"EndTime\": 1695080575.7567644, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15843252992630005, \"count\": 1, \"min\": 0.15843252992630005, \"max\": 0.15843252992630005}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.756819, \"EndTime\": 1695080575.7568357, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21271302429835, \"count\": 1, \"min\": 0.21271302429835, \"max\": 0.21271302429835}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7568898, \"EndTime\": 1695080575.7569063, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14782170557975768, \"count\": 1, \"min\": 0.14782170557975768, \"max\": 0.14782170557975768}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7569616, \"EndTime\": 1695080575.7569768, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.197900763909022, \"count\": 1, \"min\": 0.197900763909022, \"max\": 0.197900763909022}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7570324, \"EndTime\": 1695080575.7570488, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2343416252930959, \"count\": 1, \"min\": 0.2343416252930959, \"max\": 0.2343416252930959}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7571003, \"EndTime\": 1695080575.757118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16195984959602355, \"count\": 1, \"min\": 0.16195984959602355, \"max\": 0.16195984959602355}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.75717, \"EndTime\": 1695080575.757186, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19382163445154826, \"count\": 1, \"min\": 0.19382163445154826, \"max\": 0.19382163445154826}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7572374, \"EndTime\": 1695080575.7572548, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16047211400667827, \"count\": 1, \"min\": 0.16047211400667827, \"max\": 0.16047211400667827}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7573082, \"EndTime\": 1695080575.7573242, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.20030646475156147, \"count\": 1, \"min\": 0.20030646475156147, \"max\": 0.20030646475156147}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7573822, \"EndTime\": 1695080575.7573977, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1943833155632019, \"count\": 1, \"min\": 0.1943833155632019, \"max\": 0.1943833155632019}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7574506, \"EndTime\": 1695080575.7574675, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.148629945119222, \"count\": 1, \"min\": 0.148629945119222, \"max\": 0.148629945119222}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.757519, \"EndTime\": 1695080575.7575347, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18096631256739298, \"count\": 1, \"min\": 0.18096631256739298, \"max\": 0.18096631256739298}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.757586, \"EndTime\": 1695080575.757602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.32772838123639425, \"count\": 1, \"min\": 0.32772838123639425, \"max\": 0.32772838123639425}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7576551, \"EndTime\": 1695080575.75767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3350732857386271, \"count\": 1, \"min\": 0.3350732857386271, \"max\": 0.3350732857386271}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7577245, \"EndTime\": 1695080575.7577405, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34002730067571, \"count\": 1, \"min\": 0.34002730067571, \"max\": 0.34002730067571}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7577906, \"EndTime\": 1695080575.7578077, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3247788379987081, \"count\": 1, \"min\": 0.3247788379987081, \"max\": 0.3247788379987081}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.757858, \"EndTime\": 1695080575.757874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3908854664166768, \"count\": 1, \"min\": 0.3908854664166768, \"max\": 0.3908854664166768}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7579243, \"EndTime\": 1695080575.7579412, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4070631608963013, \"count\": 1, \"min\": 0.4070631608963013, \"max\": 0.4070631608963013}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7579937, \"EndTime\": 1695080575.7580092, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.38088017106056216, \"count\": 1, \"min\": 0.38088017106056216, \"max\": 0.38088017106056216}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.758063, \"EndTime\": 1695080575.7580798, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.39740342330932615, \"count\": 1, \"min\": 0.39740342330932615, \"max\": 0.39740342330932615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7581308, \"EndTime\": 1695080575.7581472, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7846006650924683, \"count\": 1, \"min\": 0.7846006650924683, \"max\": 0.7846006650924683}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.758198, \"EndTime\": 1695080575.7582152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7851509094238281, \"count\": 1, \"min\": 0.7851509094238281, \"max\": 0.7851509094238281}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.758265, \"EndTime\": 1695080575.7582812, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7845307493209839, \"count\": 1, \"min\": 0.7845307493209839, \"max\": 0.7845307493209839}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7583337, \"EndTime\": 1695080575.7583487, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7857561791737875, \"count\": 1, \"min\": 0.7857561791737875, \"max\": 0.7857561791737875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7584035, \"EndTime\": 1695080575.758419, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8704640302658081, \"count\": 1, \"min\": 0.8704640302658081, \"max\": 0.8704640302658081}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.758471, \"EndTime\": 1695080575.7584865, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9092884963353475, \"count\": 1, \"min\": 0.9092884963353475, \"max\": 0.9092884963353475}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7585409, \"EndTime\": 1695080575.7585568, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8702287591298421, \"count\": 1, \"min\": 0.8702287591298421, \"max\": 0.8702287591298421}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7586107, \"EndTime\": 1695080575.758626, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9091688035329183, \"count\": 1, \"min\": 0.9091688035329183, \"max\": 0.9091688035329183}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:55 INFO 140167794624320] #quality_metric: host=algo-1, epoch=2, train absolute_loss_objective <loss>=0.1960919187068939\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:55 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=absolute_loss_objective, value=0.14782170557975768\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:55 INFO 140167794624320] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:55 INFO 140167794624320] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:55 INFO 140167794624320] Saved checkpoint to \"/tmp/tmpm2o0ibgw/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:55 INFO 140167794624320] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080573.627829, \"EndTime\": 1695080575.7727244, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1505.0, \"count\": 1, \"min\": 1505, \"max\": 1505}, \"Total Batches Seen\": {\"sum\": 301.0, \"count\": 1, \"min\": 301, \"max\": 301}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:55 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=174.8146643173753 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:42:57.445] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 1672, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4455829, \"EndTime\": 1695080577.4456394, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11979578963915508, \"count\": 1, \"min\": 0.11979578963915508, \"max\": 0.11979578963915508}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4457366, \"EndTime\": 1695080577.4457524, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11794610889752706, \"count\": 1, \"min\": 0.11794610889752706, \"max\": 0.11794610889752706}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4457924, \"EndTime\": 1695080577.4458108, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.119242555975914, \"count\": 1, \"min\": 0.119242555975914, \"max\": 0.119242555975914}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4458575, \"EndTime\": 1695080577.445871, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1194941456715266, \"count\": 1, \"min\": 0.1194941456715266, \"max\": 0.1194941456715266}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4459293, \"EndTime\": 1695080577.4459462, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.22975076603889466, \"count\": 1, \"min\": 0.22975076603889466, \"max\": 0.22975076603889466}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4460018, \"EndTime\": 1695080577.4460201, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15816665569941202, \"count\": 1, \"min\": 0.15816665569941202, \"max\": 0.15816665569941202}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4460864, \"EndTime\": 1695080577.4461036, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2293453144232432, \"count\": 1, \"min\": 0.2293453144232432, \"max\": 0.2293453144232432}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.446162, \"EndTime\": 1695080577.4461794, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2055488737821579, \"count\": 1, \"min\": 0.2055488737821579, \"max\": 0.2055488737821579}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4462454, \"EndTime\": 1695080577.4462647, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12519320440292359, \"count\": 1, \"min\": 0.12519320440292359, \"max\": 0.12519320440292359}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4463332, \"EndTime\": 1695080577.446354, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11874677463372549, \"count\": 1, \"min\": 0.11874677463372549, \"max\": 0.11874677463372549}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4464207, \"EndTime\": 1695080577.446439, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12034403765201569, \"count\": 1, \"min\": 0.12034403765201569, \"max\": 0.12034403765201569}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4465015, \"EndTime\": 1695080577.4465165, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11880179099241893, \"count\": 1, \"min\": 0.11880179099241893, \"max\": 0.11880179099241893}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4465828, \"EndTime\": 1695080577.4465995, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18037360858917237, \"count\": 1, \"min\": 0.18037360858917237, \"max\": 0.18037360858917237}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.446658, \"EndTime\": 1695080577.4466746, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21744090421994527, \"count\": 1, \"min\": 0.21744090421994527, \"max\": 0.21744090421994527}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.446726, \"EndTime\": 1695080577.4467428, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16723125418027243, \"count\": 1, \"min\": 0.16723125418027243, \"max\": 0.16723125418027243}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.44681, \"EndTime\": 1695080577.4468288, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17201458756128946, \"count\": 1, \"min\": 0.17201458756128946, \"max\": 0.17201458756128946}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4469123, \"EndTime\": 1695080577.44693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.28324645360310874, \"count\": 1, \"min\": 0.28324645360310874, \"max\": 0.28324645360310874}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4469924, \"EndTime\": 1695080577.4470098, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2844519364833832, \"count\": 1, \"min\": 0.2844519364833832, \"max\": 0.2844519364833832}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4470763, \"EndTime\": 1695080577.4470944, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2877041807174683, \"count\": 1, \"min\": 0.2877041807174683, \"max\": 0.2877041807174683}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4471526, \"EndTime\": 1695080577.44717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2803758250872294, \"count\": 1, \"min\": 0.2803758250872294, \"max\": 0.2803758250872294}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4472382, \"EndTime\": 1695080577.4472558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.34083789110183715, \"count\": 1, \"min\": 0.34083789110183715, \"max\": 0.34083789110183715}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.447313, \"EndTime\": 1695080577.4473295, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.43264733362197877, \"count\": 1, \"min\": 0.43264733362197877, \"max\": 0.43264733362197877}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4473956, \"EndTime\": 1695080577.447416, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3768194530010223, \"count\": 1, \"min\": 0.3768194530010223, \"max\": 0.3768194530010223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.447475, \"EndTime\": 1695080577.4474916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41615046993891397, \"count\": 1, \"min\": 0.41615046993891397, \"max\": 0.41615046993891397}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4475563, \"EndTime\": 1695080577.447574, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7847361962000529, \"count\": 1, \"min\": 0.7847361962000529, \"max\": 0.7847361962000529}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4476373, \"EndTime\": 1695080577.4476557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7852680854797364, \"count\": 1, \"min\": 0.7852680854797364, \"max\": 0.7852680854797364}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4477117, \"EndTime\": 1695080577.4477286, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7847316246032715, \"count\": 1, \"min\": 0.7847316246032715, \"max\": 0.7847316246032715}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.447782, \"EndTime\": 1695080577.447797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7852619934082031, \"count\": 1, \"min\": 0.7852619934082031, \"max\": 0.7852619934082031}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.447862, \"EndTime\": 1695080577.4478776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8541999677022298, \"count\": 1, \"min\": 0.8541999677022298, \"max\": 0.8541999677022298}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4479344, \"EndTime\": 1695080577.4479494, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8918021268844605, \"count\": 1, \"min\": 0.8918021268844605, \"max\": 0.8918021268844605}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.447997, \"EndTime\": 1695080577.4480107, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8540079822540283, \"count\": 1, \"min\": 0.8540079822540283, \"max\": 0.8540079822540283}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4480522, \"EndTime\": 1695080577.448068, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8920068661371867, \"count\": 1, \"min\": 0.8920068661371867, \"max\": 0.8920068661371867}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:57 INFO 140167794624320] #quality_metric: host=algo-1, epoch=3, train absolute_loss_objective <loss>=0.11979578963915508\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:57 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=absolute_loss_objective, value=0.11794610889752706\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:57 INFO 140167794624320] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:57 INFO 140167794624320] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:57 INFO 140167794624320] Saved checkpoint to \"/tmp/tmplsqirr8z/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:57 INFO 140167794624320] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080575.7732024, \"EndTime\": 1695080577.4579577, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 1880.0, \"count\": 1, \"min\": 1880, \"max\": 1880}, \"Total Batches Seen\": {\"sum\": 376.0, \"count\": 1, \"min\": 376, \"max\": 376}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:57 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=222.56365120849918 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:42:58.995] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 1537, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9957676, \"EndTime\": 1695080578.9958496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11779596638679504, \"count\": 1, \"min\": 0.11779596638679504, \"max\": 0.11779596638679504}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9959404, \"EndTime\": 1695080578.9959612, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11921387116114299, \"count\": 1, \"min\": 0.11921387116114299, \"max\": 0.11921387116114299}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.996001, \"EndTime\": 1695080578.9960108, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1181178077061971, \"count\": 1, \"min\": 0.1181178077061971, \"max\": 0.1181178077061971}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.996055, \"EndTime\": 1695080578.9960706, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11746408442656199, \"count\": 1, \"min\": 0.11746408442656199, \"max\": 0.11746408442656199}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9961061, \"EndTime\": 1695080578.9961152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16102280275026956, \"count\": 1, \"min\": 0.16102280275026956, \"max\": 0.16102280275026956}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.996141, \"EndTime\": 1695080578.996149, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16370780348777772, \"count\": 1, \"min\": 0.16370780348777772, \"max\": 0.16370780348777772}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9961965, \"EndTime\": 1695080578.9962118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15084337210655213, \"count\": 1, \"min\": 0.15084337210655213, \"max\": 0.15084337210655213}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9962616, \"EndTime\": 1695080578.9962764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1510458172162374, \"count\": 1, \"min\": 0.1510458172162374, \"max\": 0.1510458172162374}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9963276, \"EndTime\": 1695080578.996344, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11746081042289734, \"count\": 1, \"min\": 0.11746081042289734, \"max\": 0.11746081042289734}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9964008, \"EndTime\": 1695080578.9964168, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11915449686845143, \"count\": 1, \"min\": 0.11915449686845143, \"max\": 0.11915449686845143}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9964602, \"EndTime\": 1695080578.9964695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11819093871116639, \"count\": 1, \"min\": 0.11819093871116639, \"max\": 0.11819093871116639}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.996496, \"EndTime\": 1695080578.9965034, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11785051965713501, \"count\": 1, \"min\": 0.11785051965713501, \"max\": 0.11785051965713501}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.99654, \"EndTime\": 1695080578.996554, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15854120910167693, \"count\": 1, \"min\": 0.15854120910167693, \"max\": 0.15854120910167693}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.996606, \"EndTime\": 1695080578.996621, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15766541786988575, \"count\": 1, \"min\": 0.15766541786988575, \"max\": 0.15766541786988575}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9966767, \"EndTime\": 1695080578.9966936, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19347343921661378, \"count\": 1, \"min\": 0.19347343921661378, \"max\": 0.19347343921661378}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9967499, \"EndTime\": 1695080578.9967647, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15812294904390972, \"count\": 1, \"min\": 0.15812294904390972, \"max\": 0.15812294904390972}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9968178, \"EndTime\": 1695080578.996834, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.26579546904563905, \"count\": 1, \"min\": 0.26579546904563905, \"max\": 0.26579546904563905}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9968975, \"EndTime\": 1695080578.9969146, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2663523673216502, \"count\": 1, \"min\": 0.2663523673216502, \"max\": 0.2663523673216502}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9969792, \"EndTime\": 1695080578.9969966, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.27041042908032736, \"count\": 1, \"min\": 0.27041042908032736, \"max\": 0.27041042908032736}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9970503, \"EndTime\": 1695080578.997067, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2631103088061015, \"count\": 1, \"min\": 0.2631103088061015, \"max\": 0.2631103088061015}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9971218, \"EndTime\": 1695080578.997138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3324384021759033, \"count\": 1, \"min\": 0.3324384021759033, \"max\": 0.3324384021759033}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9971914, \"EndTime\": 1695080578.9972076, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3651968340873718, \"count\": 1, \"min\": 0.3651968340873718, \"max\": 0.3651968340873718}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9972746, \"EndTime\": 1695080578.9972947, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3563454686800639, \"count\": 1, \"min\": 0.3563454686800639, \"max\": 0.3563454686800639}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9973576, \"EndTime\": 1695080578.9973757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.43242427269617717, \"count\": 1, \"min\": 0.43242427269617717, \"max\": 0.43242427269617717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.99744, \"EndTime\": 1695080578.9974585, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7840827986399332, \"count\": 1, \"min\": 0.7840827986399332, \"max\": 0.7840827986399332}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9975204, \"EndTime\": 1695080578.997538, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7852704448699951, \"count\": 1, \"min\": 0.7852704448699951, \"max\": 0.7852704448699951}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9975922, \"EndTime\": 1695080578.9976094, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7840802634557088, \"count\": 1, \"min\": 0.7840802634557088, \"max\": 0.7840802634557088}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9976661, \"EndTime\": 1695080578.9976816, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7856916561126709, \"count\": 1, \"min\": 0.7856916561126709, \"max\": 0.7856916561126709}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9977534, \"EndTime\": 1695080578.997771, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8525408776601155, \"count\": 1, \"min\": 0.8525408776601155, \"max\": 0.8525408776601155}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.997837, \"EndTime\": 1695080578.997854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8752229770024618, \"count\": 1, \"min\": 0.8752229770024618, \"max\": 0.8752229770024618}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.9979198, \"EndTime\": 1695080578.997937, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8524006312688192, \"count\": 1, \"min\": 0.8524006312688192, \"max\": 0.8524006312688192}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080578.998065, \"EndTime\": 1695080578.9980836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8753620894749959, \"count\": 1, \"min\": 0.8753620894749959, \"max\": 0.8753620894749959}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:58 INFO 140167794624320] #quality_metric: host=algo-1, epoch=4, train absolute_loss_objective <loss>=0.11779596638679504\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:59 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=absolute_loss_objective, value=0.11746081042289734\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:59 INFO 140167794624320] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:59 INFO 140167794624320] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:59 INFO 140167794624320] Saved checkpoint to \"/tmp/tmpmc4h46jn/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:59 INFO 140167794624320] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080577.4582999, \"EndTime\": 1695080579.0078764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2255.0, \"count\": 1, \"min\": 2255, \"max\": 2255}, \"Total Batches Seen\": {\"sum\": 451.0, \"count\": 1, \"min\": 451, \"max\": 451}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:42:59 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=241.97591262268108 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:43:00.517] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 1508, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5174532, \"EndTime\": 1695080580.5175393, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11753944218158723, \"count\": 1, \"min\": 0.11753944218158723, \"max\": 0.11753944218158723}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5176425, \"EndTime\": 1695080580.5176592, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11724440085887909, \"count\": 1, \"min\": 0.11724440085887909, \"max\": 0.11724440085887909}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5177143, \"EndTime\": 1695080580.5177271, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.117094136317571, \"count\": 1, \"min\": 0.117094136317571, \"max\": 0.117094136317571}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5177755, \"EndTime\": 1695080580.5177896, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1183646407922109, \"count\": 1, \"min\": 0.1183646407922109, \"max\": 0.1183646407922109}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5178416, \"EndTime\": 1695080580.5178554, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1965087866783142, \"count\": 1, \"min\": 0.1965087866783142, \"max\": 0.1965087866783142}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5179079, \"EndTime\": 1695080580.5179198, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25563519128163653, \"count\": 1, \"min\": 0.25563519128163653, \"max\": 0.25563519128163653}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5179605, \"EndTime\": 1695080580.5179713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1816790136496226, \"count\": 1, \"min\": 0.1816790136496226, \"max\": 0.1816790136496226}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5180182, \"EndTime\": 1695080580.51803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18051089612642923, \"count\": 1, \"min\": 0.18051089612642923, \"max\": 0.18051089612642923}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5180724, \"EndTime\": 1695080580.5180836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11871148987611135, \"count\": 1, \"min\": 0.11871148987611135, \"max\": 0.11871148987611135}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5181308, \"EndTime\": 1695080580.5181422, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11861417158444723, \"count\": 1, \"min\": 0.11861417158444723, \"max\": 0.11861417158444723}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5181906, \"EndTime\": 1695080580.518202, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11736728497346242, \"count\": 1, \"min\": 0.11736728497346242, \"max\": 0.11736728497346242}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5182412, \"EndTime\": 1695080580.5182524, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11858645180861155, \"count\": 1, \"min\": 0.11858645180861155, \"max\": 0.11858645180861155}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5182977, \"EndTime\": 1695080580.518309, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15496130045255024, \"count\": 1, \"min\": 0.15496130045255024, \"max\": 0.15496130045255024}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.518352, \"EndTime\": 1695080580.5183637, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1730582768122355, \"count\": 1, \"min\": 0.1730582768122355, \"max\": 0.1730582768122355}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5184102, \"EndTime\": 1695080580.5184216, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17148681783676148, \"count\": 1, \"min\": 0.17148681783676148, \"max\": 0.17148681783676148}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5184684, \"EndTime\": 1695080580.5184793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14592126631736754, \"count\": 1, \"min\": 0.14592126631736754, \"max\": 0.14592126631736754}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5185177, \"EndTime\": 1695080580.518528, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.26016633677482603, \"count\": 1, \"min\": 0.26016633677482603, \"max\": 0.26016633677482603}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5185742, \"EndTime\": 1695080580.5185862, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2600076990922292, \"count\": 1, \"min\": 0.2600076990922292, \"max\": 0.2600076990922292}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.518633, \"EndTime\": 1695080580.5186434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.26118538848559064, \"count\": 1, \"min\": 0.26118538848559064, \"max\": 0.26118538848559064}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.518682, \"EndTime\": 1695080580.518692, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25787500858306883, \"count\": 1, \"min\": 0.25787500858306883, \"max\": 0.25787500858306883}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.518738, \"EndTime\": 1695080580.5187492, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3327399604320526, \"count\": 1, \"min\": 0.3327399604320526, \"max\": 0.3327399604320526}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5187907, \"EndTime\": 1695080580.5188012, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.35564573780695596, \"count\": 1, \"min\": 0.35564573780695596, \"max\": 0.35564573780695596}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5188491, \"EndTime\": 1695080580.5188606, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3461221443017324, \"count\": 1, \"min\": 0.3461221443017324, \"max\": 0.3461221443017324}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.518934, \"EndTime\": 1695080580.5189476, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5183333191871643, \"count\": 1, \"min\": 0.5183333191871643, \"max\": 0.5183333191871643}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.518991, \"EndTime\": 1695080580.519002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7841832726796468, \"count\": 1, \"min\": 0.7841832726796468, \"max\": 0.7841832726796468}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5190396, \"EndTime\": 1695080580.5190494, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7859349168141683, \"count\": 1, \"min\": 0.7859349168141683, \"max\": 0.7859349168141683}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5190911, \"EndTime\": 1695080580.5191019, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7841533981959025, \"count\": 1, \"min\": 0.7841533981959025, \"max\": 0.7841533981959025}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5191495, \"EndTime\": 1695080580.5191615, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7849978405634562, \"count\": 1, \"min\": 0.7849978405634562, \"max\": 0.7849978405634562}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5192027, \"EndTime\": 1695080580.5192137, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8379427601496379, \"count\": 1, \"min\": 0.8379427601496379, \"max\": 0.8379427601496379}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.519255, \"EndTime\": 1695080580.5192666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8691716451644897, \"count\": 1, \"min\": 0.8691716451644897, \"max\": 0.8691716451644897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5193093, \"EndTime\": 1695080580.5193236, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8377881291707356, \"count\": 1, \"min\": 0.8377881291707356, \"max\": 0.8377881291707356}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.5193715, \"EndTime\": 1695080580.5193853, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8693296712239583, \"count\": 1, \"min\": 0.8693296712239583, \"max\": 0.8693296712239583}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:00 INFO 140167794624320] #quality_metric: host=algo-1, epoch=5, train absolute_loss_objective <loss>=0.11753944218158723\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:00 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=absolute_loss_objective, value=0.117094136317571\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:00 INFO 140167794624320] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:00 INFO 140167794624320] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:00 INFO 140167794624320] Saved checkpoint to \"/tmp/tmphn82ytm2/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:00 INFO 140167794624320] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080579.0082216, \"EndTime\": 1695080580.5294867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2630.0, \"count\": 1, \"min\": 2630, \"max\": 2630}, \"Total Batches Seen\": {\"sum\": 526.0, \"count\": 1, \"min\": 526, \"max\": 526}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:00 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=246.47995253636168 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:43:02.236] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 1706, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2369106, \"EndTime\": 1695080582.2370677, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11652490989367167, \"count\": 1, \"min\": 0.11652490989367167, \"max\": 0.11652490989367167}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2371845, \"EndTime\": 1695080582.237206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.118214271068573, \"count\": 1, \"min\": 0.118214271068573, \"max\": 0.118214271068573}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2372773, \"EndTime\": 1695080582.2372954, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11855606452624003, \"count\": 1, \"min\": 0.11855606452624003, \"max\": 0.11855606452624003}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.237369, \"EndTime\": 1695080582.2373886, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11866093305746714, \"count\": 1, \"min\": 0.11866093305746714, \"max\": 0.11866093305746714}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.237462, \"EndTime\": 1695080582.237481, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1387416382233302, \"count\": 1, \"min\": 0.1387416382233302, \"max\": 0.1387416382233302}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2375517, \"EndTime\": 1695080582.2375703, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1492835555076599, \"count\": 1, \"min\": 0.1492835555076599, \"max\": 0.1492835555076599}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2376437, \"EndTime\": 1695080582.2376623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17808379538853963, \"count\": 1, \"min\": 0.17808379538853963, \"max\": 0.17808379538853963}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2377326, \"EndTime\": 1695080582.2377505, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17611635863780975, \"count\": 1, \"min\": 0.17611635863780975, \"max\": 0.17611635863780975}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2378232, \"EndTime\": 1695080582.2378411, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11715447580814362, \"count\": 1, \"min\": 0.11715447580814362, \"max\": 0.11715447580814362}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2379112, \"EndTime\": 1695080582.237929, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11881362318992615, \"count\": 1, \"min\": 0.11881362318992615, \"max\": 0.11881362318992615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2380006, \"EndTime\": 1695080582.2380185, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11769750527540843, \"count\": 1, \"min\": 0.11769750527540843, \"max\": 0.11769750527540843}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.238088, \"EndTime\": 1695080582.2381053, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11785873679320018, \"count\": 1, \"min\": 0.11785873679320018, \"max\": 0.11785873679320018}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2381766, \"EndTime\": 1695080582.238195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15706736254692077, \"count\": 1, \"min\": 0.15706736254692077, \"max\": 0.15706736254692077}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2382655, \"EndTime\": 1695080582.238284, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16464490310351054, \"count\": 1, \"min\": 0.16464490310351054, \"max\": 0.16464490310351054}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.238353, \"EndTime\": 1695080582.2383718, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15917377984523773, \"count\": 1, \"min\": 0.15917377984523773, \"max\": 0.15917377984523773}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2384424, \"EndTime\": 1695080582.2384613, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16888948059082032, \"count\": 1, \"min\": 0.16888948059082032, \"max\": 0.16888948059082032}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.238533, \"EndTime\": 1695080582.2385516, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2589463396867116, \"count\": 1, \"min\": 0.2589463396867116, \"max\": 0.2589463396867116}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2386186, \"EndTime\": 1695080582.2386367, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25711242739359536, \"count\": 1, \"min\": 0.25711242739359536, \"max\": 0.25711242739359536}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.238711, \"EndTime\": 1695080582.2387283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25948608605066936, \"count\": 1, \"min\": 0.25948608605066936, \"max\": 0.25948608605066936}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2387962, \"EndTime\": 1695080582.2388139, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2583989164829254, \"count\": 1, \"min\": 0.2583989164829254, \"max\": 0.2583989164829254}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.238881, \"EndTime\": 1695080582.2389283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.33092392841974894, \"count\": 1, \"min\": 0.33092392841974894, \"max\": 0.33092392841974894}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2389967, \"EndTime\": 1695080582.239014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3796177711486816, \"count\": 1, \"min\": 0.3796177711486816, \"max\": 0.3796177711486816}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2390847, \"EndTime\": 1695080582.2391016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3192310881614685, \"count\": 1, \"min\": 0.3192310881614685, \"max\": 0.3192310881614685}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2391663, \"EndTime\": 1695080582.239184, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3662591727574666, \"count\": 1, \"min\": 0.3662591727574666, \"max\": 0.3662591727574666}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2392423, \"EndTime\": 1695080582.2392597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.784044314066569, \"count\": 1, \"min\": 0.784044314066569, \"max\": 0.784044314066569}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2393246, \"EndTime\": 1695080582.239343, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7850542640686036, \"count\": 1, \"min\": 0.7850542640686036, \"max\": 0.7850542640686036}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2393997, \"EndTime\": 1695080582.239417, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7840201025009155, \"count\": 1, \"min\": 0.7840201025009155, \"max\": 0.7840201025009155}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2394817, \"EndTime\": 1695080582.2394993, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7853747005462647, \"count\": 1, \"min\": 0.7853747005462647, \"max\": 0.7853747005462647}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2395692, \"EndTime\": 1695080582.2395859, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8450000069936117, \"count\": 1, \"min\": 0.8450000069936117, \"max\": 0.8450000069936117}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2396452, \"EndTime\": 1695080582.2396634, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.879552985827128, \"count\": 1, \"min\": 0.879552985827128, \"max\": 0.879552985827128}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.239722, \"EndTime\": 1695080582.2397382, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8448987067540487, \"count\": 1, \"min\": 0.8448987067540487, \"max\": 0.8448987067540487}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.2397969, \"EndTime\": 1695080582.2398129, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8797039012908936, \"count\": 1, \"min\": 0.8797039012908936, \"max\": 0.8797039012908936}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:02 INFO 140167794624320] #quality_metric: host=algo-1, epoch=6, train absolute_loss_objective <loss>=0.11652490989367167\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:02 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=absolute_loss_objective, value=0.11652490989367167\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:02 INFO 140167794624320] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:02 INFO 140167794624320] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:02 INFO 140167794624320] Saved checkpoint to \"/tmp/tmp8j3971c2/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:02 INFO 140167794624320] #progress_metric: host=algo-1, completed 70.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080580.529808, \"EndTime\": 1695080582.2509787, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3005.0, \"count\": 1, \"min\": 3005, \"max\": 3005}, \"Total Batches Seen\": {\"sum\": 601.0, \"count\": 1, \"min\": 601, \"max\": 601}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:02 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=217.8576439671138 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:43:04.123] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 1871, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1233428, \"EndTime\": 1695080584.1236575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11714739489555359, \"count\": 1, \"min\": 0.11714739489555359, \"max\": 0.11714739489555359}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1237602, \"EndTime\": 1695080584.1237762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11822304912408194, \"count\": 1, \"min\": 0.11822304912408194, \"max\": 0.11822304912408194}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1238482, \"EndTime\": 1695080584.123867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11953753733634949, \"count\": 1, \"min\": 0.11953753733634949, \"max\": 0.11953753733634949}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.123938, \"EndTime\": 1695080584.1239574, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.118650222102801, \"count\": 1, \"min\": 0.118650222102801, \"max\": 0.118650222102801}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1240244, \"EndTime\": 1695080584.124043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1713209370772044, \"count\": 1, \"min\": 0.1713209370772044, \"max\": 0.1713209370772044}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1241071, \"EndTime\": 1695080584.1241233, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18915607110659283, \"count\": 1, \"min\": 0.18915607110659283, \"max\": 0.18915607110659283}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.124189, \"EndTime\": 1695080584.1242056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14186507546901703, \"count\": 1, \"min\": 0.14186507546901703, \"max\": 0.14186507546901703}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1242733, \"EndTime\": 1695080584.1242905, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1558189966281255, \"count\": 1, \"min\": 0.1558189966281255, \"max\": 0.1558189966281255}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.124344, \"EndTime\": 1695080584.12436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1172120185693105, \"count\": 1, \"min\": 0.1172120185693105, \"max\": 0.1172120185693105}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1244261, \"EndTime\": 1695080584.1244428, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11865871095657349, \"count\": 1, \"min\": 0.11865871095657349, \"max\": 0.11865871095657349}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1245067, \"EndTime\": 1695080584.1245215, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11852234204610189, \"count\": 1, \"min\": 0.11852234204610189, \"max\": 0.11852234204610189}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.124585, \"EndTime\": 1695080584.1246023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11906272168954213, \"count\": 1, \"min\": 0.11906272168954213, \"max\": 0.11906272168954213}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1246681, \"EndTime\": 1695080584.1246846, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.160561593969663, \"count\": 1, \"min\": 0.160561593969663, \"max\": 0.160561593969663}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1247513, \"EndTime\": 1695080584.1247685, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18502627491950988, \"count\": 1, \"min\": 0.18502627491950988, \"max\": 0.18502627491950988}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1248245, \"EndTime\": 1695080584.1248405, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13699653895696004, \"count\": 1, \"min\": 0.13699653895696004, \"max\": 0.13699653895696004}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1249056, \"EndTime\": 1695080584.1249237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17216504534085592, \"count\": 1, \"min\": 0.17216504534085592, \"max\": 0.17216504534085592}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1249797, \"EndTime\": 1695080584.124996, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2575234112739563, \"count\": 1, \"min\": 0.2575234112739563, \"max\": 0.2575234112739563}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1250594, \"EndTime\": 1695080584.1250768, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2580602284272512, \"count\": 1, \"min\": 0.2580602284272512, \"max\": 0.2580602284272512}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.125144, \"EndTime\": 1695080584.1251602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2578354589144389, \"count\": 1, \"min\": 0.2578354589144389, \"max\": 0.2578354589144389}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1252162, \"EndTime\": 1695080584.1252325, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2610840788682302, \"count\": 1, \"min\": 0.2610840788682302, \"max\": 0.2610840788682302}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.125298, \"EndTime\": 1695080584.1253169, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.31433688561121625, \"count\": 1, \"min\": 0.31433688561121625, \"max\": 0.31433688561121625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.125382, \"EndTime\": 1695080584.1253994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.35869404021898904, \"count\": 1, \"min\": 0.35869404021898904, \"max\": 0.35869404021898904}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.125452, \"EndTime\": 1695080584.125468, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36597751164436343, \"count\": 1, \"min\": 0.36597751164436343, \"max\": 0.36597751164436343}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1255336, \"EndTime\": 1695080584.12555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4011555361747742, \"count\": 1, \"min\": 0.4011555361747742, \"max\": 0.4011555361747742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1256151, \"EndTime\": 1695080584.1256335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7836555741628011, \"count\": 1, \"min\": 0.7836555741628011, \"max\": 0.7836555741628011}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1256893, \"EndTime\": 1695080584.1257055, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7851527709960937, \"count\": 1, \"min\": 0.7851527709960937, \"max\": 0.7851527709960937}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1257703, \"EndTime\": 1695080584.1257868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7836272392272949, \"count\": 1, \"min\": 0.7836272392272949, \"max\": 0.7836272392272949}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1258538, \"EndTime\": 1695080584.125871, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7849263909657797, \"count\": 1, \"min\": 0.7849263909657797, \"max\": 0.7849263909657797}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1259353, \"EndTime\": 1695080584.1259515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8278245385487875, \"count\": 1, \"min\": 0.8278245385487875, \"max\": 0.8278245385487875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.126016, \"EndTime\": 1695080584.1260328, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8664420560201009, \"count\": 1, \"min\": 0.8664420560201009, \"max\": 0.8664420560201009}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1260881, \"EndTime\": 1695080584.1261044, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8277560777664185, \"count\": 1, \"min\": 0.8277560777664185, \"max\": 0.8277560777664185}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.126171, \"EndTime\": 1695080584.126188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8666036968231201, \"count\": 1, \"min\": 0.8666036968231201, \"max\": 0.8666036968231201}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:04 INFO 140167794624320] #quality_metric: host=algo-1, epoch=7, train absolute_loss_objective <loss>=0.11714739489555359\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:04 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=absolute_loss_objective, value=0.11714739489555359\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:04 INFO 140167794624320] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:04 INFO 140167794624320] Saved checkpoint to \"/tmp/tmpksn0_nuf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:04 INFO 140167794624320] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080582.251258, \"EndTime\": 1695080584.1372368, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3380.0, \"count\": 1, \"min\": 3380, \"max\": 3380}, \"Total Batches Seen\": {\"sum\": 676.0, \"count\": 1, \"min\": 676, \"max\": 676}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:04 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=198.81974540529302 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:43:05.916] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 1779, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9168677, \"EndTime\": 1695080585.9169557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1173834167321523, \"count\": 1, \"min\": 0.1173834167321523, \"max\": 0.1173834167321523}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9170513, \"EndTime\": 1695080585.9170713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11855612166722615, \"count\": 1, \"min\": 0.11855612166722615, \"max\": 0.11855612166722615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9171412, \"EndTime\": 1695080585.9171593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11713575152556102, \"count\": 1, \"min\": 0.11713575152556102, \"max\": 0.11713575152556102}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9172144, \"EndTime\": 1695080585.9172297, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11789193681875865, \"count\": 1, \"min\": 0.11789193681875865, \"max\": 0.11789193681875865}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9172955, \"EndTime\": 1695080585.9173129, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13695275215307873, \"count\": 1, \"min\": 0.13695275215307873, \"max\": 0.13695275215307873}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9173646, \"EndTime\": 1695080585.917379, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17284958291053773, \"count\": 1, \"min\": 0.17284958291053773, \"max\": 0.17284958291053773}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9174316, \"EndTime\": 1695080585.9174473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13633289210001628, \"count\": 1, \"min\": 0.13633289210001628, \"max\": 0.13633289210001628}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9175, \"EndTime\": 1695080585.9175131, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.23456135197480518, \"count\": 1, \"min\": 0.23456135197480518, \"max\": 0.23456135197480518}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9175653, \"EndTime\": 1695080585.9175794, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11604182648658752, \"count\": 1, \"min\": 0.11604182648658752, \"max\": 0.11604182648658752}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9176335, \"EndTime\": 1695080585.917647, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11849369931221009, \"count\": 1, \"min\": 0.11849369931221009, \"max\": 0.11849369931221009}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.917698, \"EndTime\": 1695080585.917711, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.117041264295578, \"count\": 1, \"min\": 0.117041264295578, \"max\": 0.117041264295578}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9177625, \"EndTime\": 1695080585.917777, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11825874658425649, \"count\": 1, \"min\": 0.11825874658425649, \"max\": 0.11825874658425649}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.917831, \"EndTime\": 1695080585.917849, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14693922519683839, \"count\": 1, \"min\": 0.14693922519683839, \"max\": 0.14693922519683839}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9178994, \"EndTime\": 1695080585.917914, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17558859022458395, \"count\": 1, \"min\": 0.17558859022458395, \"max\": 0.17558859022458395}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9179695, \"EndTime\": 1695080585.9179835, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1696296694278717, \"count\": 1, \"min\": 0.1696296694278717, \"max\": 0.1696296694278717}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9180336, \"EndTime\": 1695080585.9180465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21593762159347535, \"count\": 1, \"min\": 0.21593762159347535, \"max\": 0.21593762159347535}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9180996, \"EndTime\": 1695080585.918114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25785343503952024, \"count\": 1, \"min\": 0.25785343503952024, \"max\": 0.25785343503952024}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9181578, \"EndTime\": 1695080585.9181745, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25644426520665486, \"count\": 1, \"min\": 0.25644426520665486, \"max\": 0.25644426520665486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9182246, \"EndTime\": 1695080585.918237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25802279011408485, \"count\": 1, \"min\": 0.25802279011408485, \"max\": 0.25802279011408485}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.918297, \"EndTime\": 1695080585.9183133, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25960484782854715, \"count\": 1, \"min\": 0.25960484782854715, \"max\": 0.25960484782854715}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9183648, \"EndTime\": 1695080585.9183793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3073925252755483, \"count\": 1, \"min\": 0.3073925252755483, \"max\": 0.3073925252755483}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9184308, \"EndTime\": 1695080585.9184458, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4211872765223185, \"count\": 1, \"min\": 0.4211872765223185, \"max\": 0.4211872765223185}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9184983, \"EndTime\": 1695080585.918515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3472178322474162, \"count\": 1, \"min\": 0.3472178322474162, \"max\": 0.3472178322474162}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9185717, \"EndTime\": 1695080585.9185882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.42227495765686035, \"count\": 1, \"min\": 0.42227495765686035, \"max\": 0.42227495765686035}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9186375, \"EndTime\": 1695080585.9186528, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7837116279602051, \"count\": 1, \"min\": 0.7837116279602051, \"max\": 0.7837116279602051}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9187062, \"EndTime\": 1695080585.9187226, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7851549666722616, \"count\": 1, \"min\": 0.7851549666722616, \"max\": 0.7851549666722616}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9187853, \"EndTime\": 1695080585.9188004, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7836705509821574, \"count\": 1, \"min\": 0.7836705509821574, \"max\": 0.7836705509821574}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9188514, \"EndTime\": 1695080585.91887, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7852730102539063, \"count\": 1, \"min\": 0.7852730102539063, \"max\": 0.7852730102539063}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9189541, \"EndTime\": 1695080585.9189737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8214065993626912, \"count\": 1, \"min\": 0.8214065993626912, \"max\": 0.8214065993626912}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9190307, \"EndTime\": 1695080585.919045, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.9049149176279704, \"count\": 1, \"min\": 0.9049149176279704, \"max\": 0.9049149176279704}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9190993, \"EndTime\": 1695080585.9191146, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8213445037206014, \"count\": 1, \"min\": 0.8213445037206014, \"max\": 0.8213445037206014}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9191663, \"EndTime\": 1695080585.9191823, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.878589869817098, \"count\": 1, \"min\": 0.878589869817098, \"max\": 0.878589869817098}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:05 INFO 140167794624320] #quality_metric: host=algo-1, epoch=8, train absolute_loss_objective <loss>=0.1173834167321523\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:05 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=absolute_loss_objective, value=0.11604182648658752\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:05 INFO 140167794624320] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:05 INFO 140167794624320] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:05 INFO 140167794624320] Saved checkpoint to \"/tmp/tmprsrm79e5/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:05 INFO 140167794624320] #progress_metric: host=algo-1, completed 90.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080584.1375651, \"EndTime\": 1695080585.9287262, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 3755.0, \"count\": 1, \"min\": 3755, \"max\": 3755}, \"Total Batches Seen\": {\"sum\": 751.0, \"count\": 1, \"min\": 751, \"max\": 751}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:05 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=209.34332252187215 records/second\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:43:07.535] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 1606, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5360465, \"EndTime\": 1695080587.5361295, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11886067616939544, \"count\": 1, \"min\": 0.11886067616939544, \"max\": 0.11886067616939544}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5362236, \"EndTime\": 1695080587.5362394, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1185228232940038, \"count\": 1, \"min\": 0.1185228232940038, \"max\": 0.1185228232940038}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5362833, \"EndTime\": 1695080587.5362945, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11881463046868643, \"count\": 1, \"min\": 0.11881463046868643, \"max\": 0.11881463046868643}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5363336, \"EndTime\": 1695080587.536344, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11817922687530517, \"count\": 1, \"min\": 0.11817922687530517, \"max\": 0.11817922687530517}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5363817, \"EndTime\": 1695080587.5363922, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14718956184387208, \"count\": 1, \"min\": 0.14718956184387208, \"max\": 0.14718956184387208}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5364318, \"EndTime\": 1695080587.536443, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18994137461980184, \"count\": 1, \"min\": 0.18994137461980184, \"max\": 0.18994137461980184}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.536483, \"EndTime\": 1695080587.5364938, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13558301003774006, \"count\": 1, \"min\": 0.13558301003774006, \"max\": 0.13558301003774006}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.536534, \"EndTime\": 1695080587.5365448, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1912779328028361, \"count\": 1, \"min\": 0.1912779328028361, \"max\": 0.1912779328028361}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5365813, \"EndTime\": 1695080587.5365918, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11758583569526672, \"count\": 1, \"min\": 0.11758583569526672, \"max\": 0.11758583569526672}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5366316, \"EndTime\": 1695080587.536642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11920502189795176, \"count\": 1, \"min\": 0.11920502189795176, \"max\": 0.11920502189795176}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.536679, \"EndTime\": 1695080587.536689, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11870091021060944, \"count\": 1, \"min\": 0.11870091021060944, \"max\": 0.11870091021060944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5367286, \"EndTime\": 1695080587.536739, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11852265620231628, \"count\": 1, \"min\": 0.11852265620231628, \"max\": 0.11852265620231628}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5367765, \"EndTime\": 1695080587.5367868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13373219589392343, \"count\": 1, \"min\": 0.13373219589392343, \"max\": 0.13373219589392343}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5368261, \"EndTime\": 1695080587.5368366, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.16442623821894328, \"count\": 1, \"min\": 0.16442623821894328, \"max\": 0.16442623821894328}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5368736, \"EndTime\": 1695080587.5368838, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14744394278526307, \"count\": 1, \"min\": 0.14744394278526307, \"max\": 0.14744394278526307}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.53692, \"EndTime\": 1695080587.5369306, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1837852820555369, \"count\": 1, \"min\": 0.1837852820555369, \"max\": 0.1837852820555369}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.536966, \"EndTime\": 1695080587.5369763, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2570258304278056, \"count\": 1, \"min\": 0.2570258304278056, \"max\": 0.2570258304278056}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5370123, \"EndTime\": 1695080587.537022, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2578171977996826, \"count\": 1, \"min\": 0.2578171977996826, \"max\": 0.2578171977996826}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5370727, \"EndTime\": 1695080587.5370853, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2571273978551229, \"count\": 1, \"min\": 0.2571273978551229, \"max\": 0.2571273978551229}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5371275, \"EndTime\": 1695080587.5371382, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2621930939356486, \"count\": 1, \"min\": 0.2621930939356486, \"max\": 0.2621930939356486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5371785, \"EndTime\": 1695080587.5371895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.41072119760513304, \"count\": 1, \"min\": 0.41072119760513304, \"max\": 0.41072119760513304}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.537237, \"EndTime\": 1695080587.5372484, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.42446294816335045, \"count\": 1, \"min\": 0.42446294816335045, \"max\": 0.42446294816335045}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5372958, \"EndTime\": 1695080587.5373075, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.33554776112238566, \"count\": 1, \"min\": 0.33554776112238566, \"max\": 0.33554776112238566}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5373485, \"EndTime\": 1695080587.5373595, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4322477569580078, \"count\": 1, \"min\": 0.4322477569580078, \"max\": 0.4322477569580078}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.537399, \"EndTime\": 1695080587.5374095, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.78353972752889, \"count\": 1, \"min\": 0.78353972752889, \"max\": 0.78353972752889}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5374508, \"EndTime\": 1695080587.5374615, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.785795708656311, \"count\": 1, \"min\": 0.785795708656311, \"max\": 0.785795708656311}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5374978, \"EndTime\": 1695080587.537508, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7834921738306682, \"count\": 1, \"min\": 0.7834921738306682, \"max\": 0.7834921738306682}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.537544, \"EndTime\": 1695080587.5375545, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.7848415209452311, \"count\": 1, \"min\": 0.7848415209452311, \"max\": 0.7848415209452311}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.537594, \"EndTime\": 1695080587.5376048, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8262925742467244, \"count\": 1, \"min\": 0.8262925742467244, \"max\": 0.8262925742467244}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5376444, \"EndTime\": 1695080587.5376546, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8833655544916789, \"count\": 1, \"min\": 0.8833655544916789, \"max\": 0.8833655544916789}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5377002, \"EndTime\": 1695080587.5377114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.826224258740743, \"count\": 1, \"min\": 0.826224258740743, \"max\": 0.826224258740743}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080587.5377522, \"EndTime\": 1695080587.5377626, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.8697449735005697, \"count\": 1, \"min\": 0.8697449735005697, \"max\": 0.8697449735005697}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #quality_metric: host=algo-1, epoch=9, train absolute_loss_objective <loss>=0.11886067616939544\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=absolute_loss_objective, value=0.11758583569526672\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] Saved checkpoint to \"/tmp/tmp2o00umk9/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080585.9290633, \"EndTime\": 1695080587.5467408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 4130.0, \"count\": 1, \"min\": 4130, \"max\": 4130}, \"Total Batches Seen\": {\"sum\": 826.0, \"count\": 1, \"min\": 826, \"max\": 826}, \"Max Records Seen Between Resets\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Max Batches Seen Between Resets\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 375.0, \"count\": 1, \"min\": 375, \"max\": 375}, \"Number of Batches Since Last Reset\": {\"sum\": 75.0, \"count\": 1, \"min\": 75, \"max\": 75}}}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #throughput_metric: host=algo-1, train throughput=231.79209943547187 records/second\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 WARNING 140167794624320] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 WARNING 140167794624320] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:43:07.547] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 0, \"num_examples\": 1, \"num_bytes\": 240}\u001b[0m\n",
      "\u001b[34m[2023-09-18 23:43:07.687] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 136, \"num_examples\": 75, \"num_bytes\": 18000}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #train_score (algo-1) : ('absolute_loss_objective', 20.212510864257812)\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #train_score (algo-1) : ('mse', 684.6689292399088)\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #train_score (algo-1) : ('absolute_loss', 20.212510864257812)\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #train_score (algo-1) : ('rmse', 26.16617911044539)\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #train_score (algo-1) : ('r2', 0.977284871077508)\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #train_score (algo-1) : ('mae', 20.212510854085288)\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #quality_metric: host=algo-1, train absolute_loss_objective <loss>=20.212510864257812\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #quality_metric: host=algo-1, train mse <loss>=684.6689292399088\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #quality_metric: host=algo-1, train absolute_loss <loss>=20.212510864257812\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #quality_metric: host=algo-1, train rmse <loss>=26.16617911044539\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #quality_metric: host=algo-1, train r2 <loss>=0.977284871077508\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] #quality_metric: host=algo-1, train mae <loss>=20.212510854085288\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.01, \"l1\": 0.0, \"lr_scheduler_step\": 10, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] Saved checkpoint to \"/tmp/tmpggqwfqbi/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[09/18/2023 23:43:07 INFO 140167794624320] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1695080569.5294607, \"EndTime\": 1695080587.6963387, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 676.037073135376, \"count\": 1, \"min\": 676.037073135376, \"max\": 676.037073135376}, \"epochs\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"check_early_stopping.time\": {\"sum\": 11.440753936767578, \"count\": 10, \"min\": 0.22482872009277344, \"max\": 1.8112659454345703}, \"update.time\": {\"sum\": 17301.57160758972, \"count\": 10, \"min\": 1518.134593963623, \"max\": 2140.3324604034424}, \"finalize.time\": {\"sum\": 143.0361270904541, \"count\": 1, \"min\": 143.0361270904541, \"max\": 143.0361270904541}, \"setuptime\": {\"sum\": 2.6345252990722656, \"count\": 1, \"min\": 2.6345252990722656, \"max\": 2.6345252990722656}, \"totaltime\": {\"sum\": 18293.39838027954, \"count\": 1, \"min\": 18293.39838027954, \"max\": 18293.39838027954}}}\u001b[0m\n",
      "\n",
      "2023-09-18 23:43:25 Uploading - Uploading generated training model\n",
      "2023-09-18 23:43:25 Completed - Training job completed\n",
      "Training seconds: 162\n",
      "Billable seconds: 162\n"
     ]
    }
   ],
   "source": [
    "# More epochs and additional number of models\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 1,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 5,\n",
    "                           epochs = 10,\n",
    "                           num_models = 64,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: linear-learner-2023-09-18-23-43-54-725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 23:43:54 Starting - Starting the training job.."
     ]
    }
   ],
   "source": [
    "# A Spot offers a lower price compared to an on-Demand instance.\n",
    "# Amazon EC2 Spot Instances offer spare compute capacity available in the AWS Cloud at ~90% discounts compared to On-Demand prices. \n",
    "\n",
    "# train_use_spot_instances (bool): Specifies whether to use SageMaker Managed Spot instances for training.\n",
    "# max_run (int): Timeout in seconds for training (default: 24 * 60 * 60). After this amount of time Amazon SageMaker terminates the job regardless of its current status.\n",
    "# max_wait (int): Timeout in seconds waiting for spot training instances (default: None). After this amount of time Amazon SageMaker will stop waiting for Spot instances to become available (default:None).\n",
    "\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       instance_count = 1, \n",
    "                                       instance_type = 'ml.m4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session,\n",
    "                                       use_spot_instances = True,\n",
    "                                       max_run = 300,\n",
    "                                       max_wait = 600)\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 1,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 5,\n",
    "                           epochs = 5,\n",
    "                           num_models = 32,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRACTICE OPPORTUNITY #4 SOLUTION:**\n",
    "- **Use the trained AWS SageMaker Linear Learner model, obtain the revenue when the outside air temperature is 35 degC and 10 degC?**\n",
    "- **Compare the results to the ones optained using SkLearn!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = [[10]]\n",
    "revenue = linear_regressor.predict(temperature)\n",
    "print(revenue)\n",
    "\n",
    "temperature = [[35]] \n",
    "revenue = linear_regressor.predict(temperature)\n",
    "print(revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the end-point\n",
    "linear_regressor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "collapsed_sections": [],
   "name": "Graduate_Admission_Prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
